@incollection{Goodman:1993te,
address = {Berlin, Heidelberg},
author = {Kramer, Michael S},
booktitle = {Clinical Epidemiology and Biostatistics},
organization = {Division of Biostatistics, Oncology Center, Johns Hopkins University School of Medicine, Baltimore, MD.},
pages = {137--145},
publisher = {Springer Berlin Heidelberg},
title = {{Hypothesis Testing and P Values}},
year = {1988}
}
@article{Hilden:1978vb,
author = {Hilden, J and Habbema, J D and Bjerregaard, B},
journal = {Methods of information in medicine},
month = {oct},
number = {4},
pages = {238--246},
title = {{The measurement of performance in probabilistic diagnosis. III. Methods based on continuous functions of the diagnostic probabilities.}},
volume = {17},
year = {1978}
}
@article{Berger:2004fq,
author = {Berger, Vance W and Weinstein, Sherri},
journal = {Controlled Clinical Trials},
month = {oct},
number = {5},
pages = {515--524},
title = {{Ensuring the comparability of comparison groups: is randomization enough?}},
volume = {25},
year = {2004}
}
@article{gao2008sample,
author = {Gao, Ping and Ware, James H and Mehta, Cyrus},
journal = {Journal of Biopharmaceutical Statistics},
number = {6},
pages = {1184--1196},
publisher = {Taylor {\&} Francis},
title = {{Sample size re-estimation for adaptive sequential design in clinical trials}},
volume = {18},
year = {2008}
}
@article{Chipman:2016bp,
abstract = {The integrated discrimination improvement (IDI) is commonly used to compare two risk prediction models; it summarizes the extent a new model increases risk in events and decreases risk in non-events. The IDI averages risks across events and non-events and is therefore susceptible to Simpson's paradox. In some settings, adding a predictive covariate to a well calibrated model results in an overall negative (positive) IDI. However, if stratified by that same covariate, the strata-specific IDIs are positive (negative). Meanwhile, the calibration (observed to expected ratio and Hosmer-Lemeshow Goodness of Fit Test), area under the receiver operating characteristic curve, and Brier score improve overall and by stratum. We ran extensive simulations to investigate the impact of an imbalanced covariate upon metrics (IDI, area under the receiver operating characteristic curve, Brier score, and R(2)), provide an analytic explanation for the paradox in the IDI, and use an investigative metric, a Weighted IDI, to better understand the paradox. In simulations, all instances of the paradox occurred under stratum-specific mis-calibration, yet there were mis-calibrated settings in which the paradox did not occur. The paradox is illustrated on Cancer Genomics Network data by calculating predictions based on two versions of BRCAPRO, a Mendelian risk prediction model for breast and ovarian cancer. In both simulations and the Cancer Genomics Network data, overall model calibration did not guarantee stratum-level calibration. We conclude that the IDI should only assess model performance among a clinically relevant subset when stratum-level calibration is strictly met and recommend calculating additional metrics to confirm the direction and conclusions of the IDI. Copyright (c) 2016 John Wiley {\&} Sons, Ltd.},
author = {Chipman, J and Braun, D},
doi = {10.1002/sim.6862},
issn = {1097-0258 (Electronic)},
journal = {Statistics in medicine},
keywords = {Area Under Curve,BRCA1,Biological,Breast Neoplasms,Computer Simulation,Decision Support Techniques,Female,Genes,Humans,Mendelian Randomization Analysis,Models,Ovarian Neoplasms,ROC Curve,Risk Assessment,Statistical,genetics,methods},
language = {eng},
month = {dec},
number = {28},
pages = {4468--4481},
pmid = {29160558},
title = {{Simpson's paradox in the integrated discrimination improvement}},
volume = {36},
year = {2016}
}
@article{Imai:2004gd,
author = {Imai, Kosuke and van Dyk, David A},
journal = {Journal of the American Statistical Association},
month = {sep},
number = {467},
pages = {854--866},
title = {{Causal Inference With General Treatment Regimes}},
volume = {99},
year = {2004}
}
@article{Cook:2011cg,
author = {Cook, Nancy R and Paynter, Nina P},
journal = {Biometrical Journal},
month = {feb},
number = {2},
pages = {237--258},
title = {{Performance of reclassification statistics in comparing risk prediction models}},
volume = {53},
year = {2011}
}
@article{barker2009spy,
author = {Barker, A D and Sigman, C C and Kelloff, G J and Hylton, N M and Berry, D A and Esserman, LJs},
journal = {Clinical Pharmacology {\&} Therapeutics},
number = {1},
pages = {97--100},
publisher = {Wiley Online Library},
title = {{I-SPY 2: an adaptive breast cancer trial design in the setting of neoadjuvant chemotherapy}},
volume = {86},
year = {2009}
}
@article{Borly:2009ij,
author = {Borly, L},
journal = {Scandinavian Journal of Gastroenterology},
month = {jul},
number = {11},
pages = {1144--1152},
title = {{Preoperative Prediction Model of Outcome after Cholecystectomy for Symptomatic Gallstones}},
volume = {34},
year = {2009}
}
@article{Journal2009,
author = {Journal, Source and Statistical, American and Sep, No},
number = {407},
pages = {797--804},
title = {{Analysis of Rank Measures of Association for Ordinal Data from Longitudinal Studies Author ( s ): Gregory J . Carr , Kerry B . Hafner , Gary G . Koch Published by : American Statistical Association Stable URL : http://www.jstor.org/stable/2289669}},
volume = {84},
year = {2009}
}
@article{Vicier2019,
abstract = {BACKGROUND: Inflammation and infections have been associated with prostate cancer progression. We assessed whether elevated serum cytokines or T. vaginalis seropositivity at the time of diagnosis was associated with higher grade or lethal prostate cancer. PATIENTS AND METHODS: Men with localized or metastatic prostate cancer were included in this study. Cytokine serum levels including interleukin (IL)-1alpha, IL-1beta, IL-2, IL-6, IL-8, monocyte chemotactic protein 1 (CCL-2), tumor necrosis factor alpha, and growth-regulated oncogene alpha (CXCL-1) using a multiplex enzyme-linked immunosorbent assay and T. vaginalis serology were measured in blood samples at diagnosis. RESULTS: A total of 324 patients were identified at time of localized disease and 118 at time of metastatic disease. Of the 189 patients with localized disease and clinical follow-up data (median, 73 months), 28 developed lethal disease. There was no association between circulating cytokine levels above median concentrations nor T. vaginalis seropositivity and risk of intermediate- to high-risk or lethal prostate cancer. CONCLUSION: Higher levels of serum cytokine levels and T. vaginalis seropositivity at diagnosis are not associated with high-grade or lethal prostate cancer and do not aid risk stratification of localized prostate cancer.},
author = {Vicier, Cecile and Werner, Lillian and Chipman, Jonathan and Harshman, Lauren C and Patil, Dattatraya H and Fichorova, Raina N and Rider, Jennifer R and Sanda, Martin G and Mucci, Lorelei A and Sweeney, Christopher J},
doi = {10.1016/j.clgc.2018.09.022},
issn = {1938-0682 (Electronic)},
journal = {Clinical genitourinary cancer},
keywords = {Aged,Biomarkers, Tumor,Cohort Studies,Cytokines,Follow-Up Studies,Humans,Male,Middle Aged,Neoplasm Grading,Prognosis,Prostatic Neoplasms,Seroepidemiologic Studies,Trichomonas Infections,Trichomonas vaginalis,analysis,blood,complications,epidemiology,parasitology,pathology,physiology},
language = {eng},
month = {feb},
number = {1},
pages = {32--37},
pmid = {30348512},
title = {{Elevated Serum Cytokines and Trichomonas vaginalis Serology at Diagnosis Are Not  Associated With Higher Gleason Grade or Lethal Prostate Cancer.}},
volume = {17},
year = {2019}
}
@article{therneau1993many,
author = {Therneau, Terry M},
journal = {Controlled clinical trials},
number = {2},
pages = {98--108},
publisher = {Elsevier},
title = {{How many stratification factors are “too many” to use in a randomization plan?}},
volume = {14},
year = {1993}
}
@article{paik2004multigene,
author = {Paik, Soonmyung and Shak, Steven and Tang, Gong and Kim, Chungyeul and Baker, Joffre and Cronin, Maureen and Baehner, Frederick L and Walker, Michael G and Watson, Drew and Park, Taesung and Others},
journal = {New England Journal of Medicine},
number = {27},
pages = {2817--2826},
publisher = {Mass Medical Soc},
title = {{A multigene assay to predict recurrence of tamoxifen-treated, node-negative breast cancer}},
volume = {351},
year = {2004}
}
@article{Vickers:2006bb,
author = {Vickers, A J and Elkin, E B},
journal = {Medical Decision Making},
month = {nov},
number = {6},
pages = {565--574},
title = {{Decision Curve Analysis: A Novel Method for Evaluating Prediction Models}},
volume = {26},
year = {2006}
}
@article{Bertsimas2019,
abstract = {The decision of how to allocate subjects to treatment groups is of great importance in experimental clinical trials for novel investigational drugs, a multibillion-dollar industry. Statistical power, the ability of an experiment to detect a positive treatment effect when one exists, depends in part on the similarity of the groups in terms of measurable covariates that affect the treatment response. We present a novel algorithm for online allocation that leverages robust mixed-integer optimization. In all tested scenarios, the proposed method yields statistical power at least as high as, and sometimes significantly higher than, state-of-the-art covariate-adaptive randomization approaches. We present a setting in which our algorithm achieves a desired level of power at a sample size 25{\%}-. smaller than that required with randomization-based approaches. Correspondingly, we expect that our covariate-adaptive optimization approach could substantially reduce both the duration and operating costs of clinical trials in many commonly observed settings while maintaining computational efficiency and protection against experimental bias.},
author = {Bertsimas, Dimitris and Korolko, Nikita and Weinstein, Alexander M.},
doi = {10.1287/opre.2018.1818},
file = {::},
isbn = {0000000183062},
issn = {15265463},
journal = {Operations Research},
keywords = {clinical trials,covariate-adaptive randomization,mixed-integer optimization,online allocation,robust optimization,statistical power},
number = {4},
pages = {1150--1161},
title = {{Covariate-adaptive optimization in online clinical trials}},
volume = {67},
year = {2019}
}
@article{jakobsen2014thresholds,
author = {Jakobsen, Janus Christian and Gluud, Christian and Winkel, Per and Lange, Theis and Wetterslev, J{\o}rn},
journal = {BMC medical research methodology},
number = {1},
pages = {1--12},
publisher = {BioMed Central},
title = {{The thresholds for statistical and clinical significance--a five-step procedure for evaluation of intervention effects in randomised clinical trials}},
volume = {14},
year = {2014}
}
@article{Anonymous:1999ta,
journal = {Lancet (London, England)},
month = {jan},
number = {9146},
pages = {9--13},
title = {{The Cardiac Insufficiency Bisoprolol Study II (CIBIS-II): a randomised trial.}},
volume = {353},
year = {1999}
}
@article{Katki:2008gy,
author = {Katki, Hormuzd A and Blackford, Amanda and Chen, Sining and Parmigiani, Giovanni},
journal = {Statistics in medicine},
month = {sep},
number = {22},
pages = {4532--4548},
title = {{Multiple diseases in carrier probability estimation: Accounting for surviving all cancers other than breast and ovary in BRCAPRO}},
volume = {27},
year = {2008}
}
@article{therneau2020multi,
author = {Therneau, Terry and Crowson, Cynthia and Atkinson, Elizabeth},
journal = {CRAN-R (https://cran. r-project. org/web/packages/survival/vignettes/compete. pdf)},
title = {{Multi-state models and competing risks}},
year = {2020}
}
@article{Anonymous:OsVcL2zm,
month = {nov},
pages = {1--20},
title = {{Estimating Average Dose Response Functions Using the R Package causaldrf}},
year = {2015}
}
@article{Aronow2014,
abstract = {We propose a consistent estimator of sharp bounds on the variance of the difference-in-means estimator in completely randomized experiments. Generalizing Robins [Stat. Med. 7 (1988) 773-785], our results resolve a wellknown identification problem in causal inference posed by Neyman [Statist. Sci. 5 (1990) 465-472. Reprint of the original 1923 paper]. A practical implication of our results is that the upper bound estimator facilitates the asymptotically narrowest conservative Wald-type confidence intervals, with applications in randomized controlled and clinical trials. {\textcopyright} Institute of Mathematical Statistics, 2014.},
author = {Aronow, Peter M. and Green, Donald P. and Lee, Donald K.K.},
doi = {10.1214/13-AOS1200},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Causal inference,Finite populations,Potential outcomes,Randomized experiments,Variance estimation},
number = {3},
pages = {850--871},
title = {{Sharp bounds on the variance in randomized experiments}},
volume = {42},
year = {2014}
}
@article{schoenfeld1983sample,
author = {Schoenfeld, David A},
journal = {Biometrics},
pages = {499--503},
publisher = {JSTOR},
title = {{Sample-size formula for the proportional-hazards regression model}},
year = {1983}
}
@article{Bang2010,
abstract = {Background Trastuzumab, a monoclonal antibody against human epidermal growth factor receptor 2 (HER2; also known as ERBB2), was investigated in combination with chemotherapy for first-line treatment of HER2-positive advanced gastric or gastro-oesophageal junction cancer. Methods ToGA (Trastuzumab for Gastric Cancer) was an open-label, international, phase 3, randomised controlled trial undertaken in 122 centres in 24 countries. Patients with gastric or gastro-oesophageal junction cancer were eligible for inclusion if their tumours showed overexpression of HER2 protein by immunohistochemistry or gene amplification by fluorescence in-situ hybridisation. Participants were randomly assigned in a 1:1 ratio to receive a chemotherapy regimen consisting of capecitabine plus cisplatin or fluorouracil plus cisplatin given every 3 weeks for six cycles or chemotherapy in combination with intravenous trastuzumab. Allocation was by block randomisation stratified by Eastern Cooperative Oncology Group performance status, chemotherapy regimen, extent of disease, primary cancer site, and measurability of disease, implemented with a central interactive voice recognition system. The primary endpoint was overall survival in all randomised patients who received study medication at least once. This trial is registered with ClinicalTrials.gov, number NCT01041404. Findings 594 patients were randomly assigned to study treatment (trastuzumab plus chemotherapy, n=298; chemotherapy alone, n=296), of whom 584 were included in the primary analysis (n=294; n=290). Median follow-up was 18{\textperiodcentered}6 months (IQR 11-25) in the trastuzumab plus chemotherapy group and 17{\textperiodcentered}1 months (9-25) in the chemotherapy alone group. Median overall survival was 13{\textperiodcentered}8 months (95 CI 12-16) in those assigned to trastuzumab plus chemotherapy compared with 11{\textperiodcentered}1 months (10-13) in those assigned to chemotherapy alone (hazard ratio 0{\textperiodcentered}74; 95 CI 0{\textperiodcentered}60-0{\textperiodcentered}91; p=0{\textperiodcentered}0046). The most common adverse events in both groups were nausea (trastuzumab plus chemotherapy, 197 [67] vs chemotherapy alone, 184 [63]), vomiting (147 [50] vs 134 [46]), and neutropenia (157 [53] vs 165 [57]). Rates of overall grade 3 or 4 adverse events (201 [68] vs 198 [68]) and cardiac adverse events (17 [6] vs 18 [6]) did not differ between groups. Interpretaion Trastuzumab in combination with chemotherapy can be considered as a new standard option for patients with HER2-positive advanced gastric or gastro-oesophageal junction cancer. Funding F Hoffmann-La Roche. {\textcopyright} 2010 Elsevier Ltd.},
author = {Bang, Yung Jue and {Van Cutsem}, Eric and Feyereislova, Andrea and Chung, Hyun C. and Shen, Lin and Sawaki, Akira and Lordick, Florian and Ohtsu, Atsushi and Omuro, Yasushi and Satoh, Taroh and Aprile, Giuseppe and Kulikov, Evgeny and Hill, Julie and Lehle, Michaela and R{\"{u}}schoff, Josef and Kang, Yoon Koo},
doi = {10.1016/S0140-6736(10)61121-X},
file = {::},
issn = {01406736},
journal = {The Lancet},
number = {9742},
pages = {687--697},
pmid = {20728210},
publisher = {Elsevier Ltd},
title = {{Trastuzumab in combination with chemotherapy versus chemotherapy alone for treatment of HER2-positive advanced gastric or gastro-oesophageal junction cancer (ToGA): A phase 3, open-label, randomised controlled trial}},
url = {http://dx.doi.org/10.1016/S0140-6736(10)61121-X},
volume = {376},
year = {2010}
}
@article{Mangin2016,
author = {Mangin, Author B and Thoquet, P and Grimsley, N},
file = {::},
number = {1},
pages = {88--99},
title = {{Pleiotropic QTL Analysis Published by : International Biometric Society Stable URL : http://www.jstor.org/stable/2533998 REFERENCES Linked references are available on JSTOR for this article : You may need to log in to JSTOR to access the linked references}},
volume = {54},
year = {2016}
}
@article{Xanthakis:2014bl,
author = {Xanthakis, Vanessa and Sullivan, Lisa M and Vasan, Ramachandran S and Benjamin, Emelia J and Massaro, Joseph M and {D'Agostino Sr.}, Ralph B and Pencina, Michael J},
journal = {Statistics in medicine},
month = {apr},
number = {15},
pages = {2577--2584},
title = {{Assessing the incremental predictive performance of novel biomarkers over standard predictors}},
volume = {33},
year = {2014}
}
@article{Biller:2002cj,
author = {Biller, Beverly M K and Samuels, Mary H and Zagar, Anthony and Cook, David M and Arafah, Baha M and Bonert, Vivien and Stavrou, Stavros and Kleinberg, David L and Chipman, John J and Hartman, Mark L},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {may},
number = {5},
pages = {2067--2079},
title = {{Sensitivity and Specificity of Six Tests for the Diagnosis of Adult GH Deficiency}},
volume = {87},
year = {2002}
}
@article{Vedder:2014gk,
author = {Vedder, Moniek M and de Bekker-Grob, Esther W and Lilja, Hans G and Vickers, Andrew J and van Leenders, Geert J L H and Steyerberg, Ewout W and Roobol, Monique J},
journal = {European urology},
month = {dec},
number = {6},
pages = {1109--1115},
title = {{The Added Value of Percentage of Free to Total Prostate-specific Antigen, PCA3, and a Kallikrein Panel to the ERSPC Risk Calculator for Prostate Cancer in Prescreened Men}},
volume = {66},
year = {2014}
}
@article{Anonymous:tKW1fHL5,
month = {aug},
pages = {1--13},
title = {{1984 Begg Kalish Biometrics - Treatment allocation for nonlinear models}},
year = {2017}
}
@article{Kelcey2017,
author = {Kelcey, Benjamin and Cox, Kyle},
doi = {10.3102/1076998617695506},
keywords = {indirect effects,mediation,multilevel models,power,sample size},
number = {5},
pages = {499--530},
title = {{Statistical Power for Causally Defined Indirect Effects in Group-Randomized Trials With Individual-Level Mediators}},
volume = {42},
year = {2017}
}
@article{Pencina:2012ed,
author = {Pencina, Michael J and D'Agostino, Ralph B and Massaro, Joseph M},
journal = {Lifetime Data Analysis},
month = {dec},
number = {2},
pages = {202--218},
title = {{Understanding increments in model performance metrics}},
volume = {19},
year = {2012}
}
@article{Alberg2014,
abstract = {The question of whether cigarette smoking was associated with lung cancer was central to the expansion of epidemiology into the study of chronic diseases in the 1950s. The culmination of this era was the 1964 report of the Advisory Committee to the Surgeon General, a landmark document that included an objective synthesis of the evidence of the health consequences of smoking according to causal criteria. The report concluded that cigarette smoking was a cause of lung cancer in men and sufficient in scope that "remedial action" was warranted at the societal level. The 2014 Surgeon General's report commemorates the 50th anniversary of the 1964 report. The evidence on the health consequences of smoking has been updated many times in Surgeon General's reports since 1964. These have summarized our increasingly greater understanding of the broad spectrum of the deleterious health effects of exposure to tobacco smoke across most major organ systems. In turn, this evidence has been translated into tobacco control strategies implemented to protect the public's health. The Surgeon General report process is an enduring example of evidence-based public health in practice. Substantial progress has been made, but cigarette smoking remains one of the most pressing global health issues of our time. {\textcopyright} The Author 2013.},
author = {Alberg, Anthony J. and Shopland, Donald R. and Cummings, K. Michael},
doi = {10.1093/aje/kwt335},
issn = {00029262},
journal = {American Journal of Epidemiology},
keywords = {causal inference,cigarette smoking,epidemiology,evidence-based public health,history,lung cancer,research methods,secondhand smoke exposure},
number = {4},
pages = {403--412},
pmid = {24436362},
title = {{The 2014 Surgeon General's Report: Commemorating the 50th Anniversary of the 1964 Report of the Advisory Committee to the US Surgeon General and Updating the Evidence on the Health Consequences of Cigarette Smoking}},
volume = {179},
year = {2014}
}
@article{Leening:2014ve,
author = {Leening, Maarten J G and Vedder, Moniek M and Witteman, Jacqueline C M and Pencina, Michael J and Steyerberg, Ewout W},
journal = {Annals of Internal Medicine},
month = {jan},
number = {2},
pages = {122--131},
title = {{Net Reclassification Improvement: Computation, Interpretation, and Controversies}},
volume = {160},
year = {2014}
}
@article{scorespy,
author = {Score, MammaPrint M P},
file = {::},
title = {{I-SPY 2 Adaptive TRIAL Schema: Screening Eligibility $\backslash${\&} Randomization}}
}
@article{mayberry2020mixed,
author = {Mayberry, Lindsay S and Berg, Cynthia A and Greevy, Robert A and Nelson, Lyndsay A and Bergner, Erin M and Wallston, Kenneth A and Harper, Kryseana J and Elasy, Tom A},
journal = {Annals of Behavioral Medicine},
title = {{Mixed-Methods Randomized Evaluation of FAMS: A Mobile Phone-Delivered Intervention to Improve Family/Friend Involvement in Adults' Type 2 Diabetes Self-Care}},
year = {2020}
}
@article{Wasserman1996,
abstract = {[Ilt may be that ... reason, self-consciousness and self-control which seem to sever human intellect so sharply from that of all other animals are really but secondary re- sults of the tremendous increase in the number, delicacy and complexity of associations which the human animal can form. It may be that the evolution of intellect has no breaks, that its progress is continuous from its first appearance to its present condition in adult ... human beings. If we could prove that what we call ideational life and reasoning were not new and unexplainable species of intellectual life but only the natural consequences of an increase in the number, delicacy, and complexity of associations of the general animal sort, we should have made out an evolution of mind comparable to the evolution of living forms. (p. 286). {\textcopyright} 1996 Academic Press Inc.},
author = {Wasserman, Edward A. and Kao, Shu Fang and {Van Hamme}, Linda J. and Katagiri, Masayoshi and Young, Michael E.},
doi = {10.1016/S0079-7421(08)60562-9},
issn = {00797421},
journal = {Psychology of Learning and Motivation - Advances in Research and Theory},
number = {C},
pages = {207--264},
title = {{Causation and Association}},
volume = {34},
year = {1996}
}
@article{RN12,
author = {Vidrine, J I and Reitzel, L R and Figueroa, P Y and Velasquez, M M and Mazas, C A and Cinciripini, P M and Wetter, D W},
doi = {10.1016/j.cbpra.2011.11.001},
issn = {1077-7229 (Print) 1077-7229},
journal = {Cogn Behav Pract},
keywords = {motivation skills training smoking cessation socia},
number = {4},
pages = {501--516},
title = {{Motivation and Problem Solving (MAPS): Motivationally based skills training for treating substance use}},
type = {Journal Article},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7685295/pdf/nihms-1646547.pdf},
volume = {20},
year = {2013}
}
@article{Teerenstra2008,
abstract = {Background: The first applications of cluster randomized trials with three instead of two levels are beginning to appear in health research, for instance, in trials where different strategies to implement best-practice guidelines are compared. In such trials, the strategy is implemented in health care units ('clusters') and aims at changing the behavior of health care professionals working in this unit ('subjects'), while the effects are measured at patient level ('evaluations'). Purpose: To guide the choice of number of clusters, number of subjects per cluster, and number of evaluations per subject. Methods: We derive a sample size formula and investigate the influence of sample allocation on power or number of clusters required. Results: The required sample size is the product of the sample size in absence of correlation and two variance inflation factors (VIFs) that describe the clustering of evaluations within subjects and of subjects within cluster, respectively. Because each VIF is expressed in terms of an interpretable Pearson correlation, subject matter knowledge can be incorporated. Moreover, these Pearson's correlations are related to intracluster correlations (ICCs) from comparable, but 2-level cluster randomized trials. Formulas are obtained to guide the sample allocation (number of clusters, subjects, and evaluations) for minimizing total sample size, minimizing the number of clusters, or maximizing power given a budget constraint. Limitations: Empirical estimates of variance components or ICCs from 3-level cluster trials are scarce which limits reliably powering. Conclusions: When parameterized in terms of Pearson correlations, the two variance inflation factors give quantitative insight into the impact of the number of clusters, subjects and evaluations on power. Moreover, subject matter knowledge as well as ICCs from 2-level cluster randomized trials can be incorporated in the sample size calculation, when empirical estimates of variance components or ICCs from a pilot or comparable 3-level study are lacking. {\textcopyright} Society for Clinical Trials 2008.},
author = {Teerenstra, Steven and Moerbeek, Mirjam and van Achterberg, Theo and Pelzer, Ben J. and Borm, George F.},
doi = {10.1177/1740774508096476},
file = {::},
isbn = {1740774508096},
issn = {17407745},
journal = {Clinical Trials},
number = {5},
pages = {486--495},
pmid = {18827041},
title = {{Sample size calculations for 3-level cluster randomized trials}},
volume = {5},
year = {2008}
}
@article{Ding:2015vp,
author = {Ding, Peng and VanderWeele, Tyler},
journal = {arXiv.org},
month = {jul},
title = {{Sensitivity Analysis Without Assumptions}},
year = {2015}
}
@article{Kaul:2005co,
author = {Kaul, Sanjay and Diamond, George A and Weintraub, William S},
journal = {Journal of the American College of Cardiology},
month = {dec},
number = {11},
pages = {1986--1995},
title = {{Trials and Tribulations of Non-Inferiority}},
volume = {46},
year = {2005}
}
@article{Shintani:2009fk,
author = {Shintani, Ayumi K and Girard, Timothy D and Eden, Svetlana K and Arbogast, Patrick G and Moons, Karel G M and Ely, E Wesley},
journal = {Critical care medicine},
month = {nov},
number = {11},
pages = {2939--2945},
title = {{Immortal time bias in critical care research: Application of time-varying Cox regression for observational cohort studies*}},
volume = {37},
year = {2009}
}
@article{Berger:2015gl,
author = {Berger, Vance W and Antsygina, Olga},
journal = {Clinical Investigation},
month = {dec},
number = {12},
pages = {847--853},
title = {{A review of randomization methods in clinical trials}},
volume = {5},
year = {2015}
}
@article{aliyu2016integrated,
author = {Aliyu, Muktar H and Blevins, Meridith and Audet, Carolyn M and Kalish, Marcia and Gebi, Usman I and Onwujekwe, Obinna and Lindegren, Mary Lou and Shepherd, Bryan E and Wester, C William and Vermund, Sten H},
journal = {The lancet HIV},
number = {5},
pages = {e202----e211},
publisher = {Elsevier},
title = {{Integrated prevention of mother-to-child HIV transmission services, antiretroviral therapy initiation, and maternal and infant retention in care in rural north-central Nigeria: a cluster-randomised controlled trial}},
volume = {3},
year = {2016}
}
@article{Balmana:2008bo,
author = {Balma{\~{n}}a, J and Balaguer, F and Castellv$\backslash$'$\backslash$i-Bel, S and Steyerberg, E W and Andreu, M and Llor, X and Jover, R and Castells, A and Syngal, S and {for the Gastrointestinal Oncology Group of the Spanish Gastroenterological Association}},
journal = {Journal of Medical Genetics},
month = {jun},
number = {9},
pages = {557--563},
title = {{Comparison of predictive models, clinical criteria and molecular tumour screening for the identification of patients with Lynch syndrome in a population-based cohort of colorectal cancer patients}},
volume = {45},
year = {2008}
}
@article{mackinnon2002comparison,
author = {MacKinnon, David P and Lockwood, Chondra M and Hoffman, Jeanne M and West, Stephen G and Sheets, Virgil},
journal = {Psychological methods},
number = {1},
pages = {83},
publisher = {American Psychological Association},
title = {{A comparison of methods to test mediation and other intervening variable effects.}},
volume = {7},
year = {2002}
}
@article{Wang2019,
abstract = {Bootstrap is a useful tool for making statistical inference, but it may provide erroneous results under complex survey sampling. Most studies about bootstrap-based inference are developed under simple random sampling and stratified random sampling. In this paper, we propose a unified bootstrap method applicable to some complex sampling designs, including Poisson sampling and probability-proportional-to-size sampling. Two main features of the proposed bootstrap method are that studentization is used to make inference, and the finite population is bootstrapped based on a multinomial distribution by incorporating the sampling information. We show that the proposed bootstrap method is second-order accurate using the Edgeworth expansion. Two simulation studies are conducted to compare the proposed bootstrap method with the Wald-type method, which is widely used in survey sampling. Results show that the proposed bootstrap method is better in terms of coverage rate especially when sample size is limited.},
archivePrefix = {arXiv},
arxivId = {1901.01645},
author = {Wang, Zhonglei and Kim, Jae Kwang and Peng, Liuhua},
eprint = {1901.01645},
file = {::},
keywords = {confidence interval,edgeworth expansion,multinomial distribution,second-order accurate},
title = {{Bootstrap inference for the finite population total under complex sampling designs}},
url = {http://arxiv.org/abs/1901.01645},
year = {2019}
}
@article{DAgostino:2003bn,
author = {D'Agostino, Ralph B and Massaro, Joseph M and Sullivan, Lisa M},
journal = {Statistics in medicine},
number = {2},
pages = {169--186},
title = {{Non-inferiority trials: design concepts and issues - the encounters of academic consultants in statistics}},
volume = {22},
year = {2003}
}
@article{hampson2013group,
author = {Hampson, Lisa V and Jennison, Christopher},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {1},
pages = {3--54},
publisher = {Wiley Online Library},
title = {{Group sequential tests for delayed responses (with discussion)}},
volume = {75},
year = {2013}
}
@article{mao2019propensity,
author = {Mao, Huzhang and Li, Liang and Greene, Tom},
journal = {Statistical methods in medical research},
number = {8},
pages = {2439--2454},
publisher = {SAGE Publications Sage UK: London, England},
title = {{Propensity score weighting analysis and treatment effect discovery}},
volume = {28},
year = {2019}
}
@article{sparano2018adjuvant,
author = {Sparano, Joseph A and Gray, Robert J and Makower, Della F and Pritchard, Kathleen I and Albain, Kathy S and Hayes, Daniel F and {Geyer Jr}, Charles E and Dees, Elizabeth C and Goetz, Matthew P and {Olson Jr}, John A and Others},
journal = {New England Journal of Medicine},
number = {2},
pages = {111--121},
publisher = {Mass Medical Soc},
title = {{Adjuvant chemotherapy guided by a 21-gene expression assay in breast cancer}},
volume = {379},
year = {2018}
}
@article{Greenland:2004dy,
author = {Greenland, Sander},
journal = {Biometrics},
month = {may},
number = {3},
pages = {915--921},
title = {{When Should Epidemiologic Regressions Use Random Coefficients?}},
volume = {56},
year = {2004}
}
@article{Nee:2013kr,
author = {Nee, Robert J and Vicenzino, Bill and Jull, Gwendolen A and Cleland, Joshua A and Coppieters, Michel W},
journal = {Journal of Orthopaedic {\&} Sports Physical Therapy},
month = {jun},
number = {6},
pages = {379--391},
title = {{Baseline Characteristics of Patients With Nerve-Related Neck and Arm Pain Predict the Likely Response to Neural Tissue Management}},
volume = {43},
year = {2013}
}
@article{Renfro2017,
abstract = {In recent years, cancers once viewed as relatively homogeneous in terms of organ location and treatment strategy are now better understood to be increasingly heterogeneous across biomarker and genetically defined patient subgroups. This has produced a shift toward development of biomarker-targeted agents during a time when funding for cancer research has been limited; as a result, the need for improved operational efficiency in studying many agent-and-target combinations in parallel has emerged. Platform trials, basket trials, and umbrella trials are new approaches to clinical research driven by this need for enhanced efficiency in the modern era of increasingly specific cancer subpopulations and decreased resources to study treatments for individual cancer subtypes in a traditional way. In this review, we provide an overview of these new types of clinical trial designs, including discussions ofmotivation for their use, recommended terminology, examples, and challenges encountered in their application.},
author = {Renfro, L. A. and Sargent, D. J.},
doi = {10.1093/annonc/mdw413},
file = {::;::},
issn = {15698041},
journal = {Annals of Oncology},
keywords = {Basket trialbiomarker-based trialmaster protocolpl},
number = {1},
pages = {34--43},
pmid = {28177494},
publisher = {Elsevier Masson SAS},
title = {{Statistical controversies in clinical research: Basket trials, umbrella trials, and other master protocols: A review and examples}},
url = {https://doi.org/10.1093/annonc/mdw413},
volume = {28},
year = {2017}
}
@article{Pocock:2015cf,
author = {Pocock, Stuart J and Clayton, Tim C and Stone, Gregg W},
journal = {Journal of the American College of Cardiology},
month = {dec},
number = {25},
pages = {2886--2898},
title = {{Challenging Issues in Clinical Trial Design: Part 4 of a 4-Part Series on Statistics for Clinical Trials.}},
volume = {66},
year = {2015}
}
@article{Bhaskaran2014,
abstract = {Background: High body-mass index (BMI) predisposes to several site-specific cancers, but a large-scale systematic and detailed characterisation of patterns of risk across all common cancers adjusted for potential confounders has not previously been undertaken. We aimed to investigate the links between BMI and the most common site-specific cancers. Methods: With primary care data from individuals in the Clinical Practice Research Datalink with BMI data, we fitted Cox models to investigate associations between BMI and 22 of the most common cancers, adjusting for potential confounders. We fitted linear then non-linear (spline) models; investigated effect modification by sex, menopausal status, smoking, and age; and calculated population effects. Findings: 5{\textperiodcentered}24 million individuals were included; 166 955 developed cancers of interest. BMI was associated with 17 of 22 cancers, but effects varied substantially by site. Each 5 kg/m2 increase in BMI was roughly linearly associated with cancers of the uterus (hazard ratio [HR] 1{\textperiodcentered}62, 99{\%} CI 1{\textperiodcentered}56–1{\textperiodcentered}69; p{\textless}0{\textperiodcentered}0001), gallbladder (1{\textperiodcentered}31, 1{\textperiodcentered}12–1{\textperiodcentered}52; p{\textless}0{\textperiodcentered}0001), kidney (1{\textperiodcentered}25, 1{\textperiodcentered}17–1{\textperiodcentered}33; p{\textless}0{\textperiodcentered}0001), cervix (1{\textperiodcentered}10, 1{\textperiodcentered}03–1{\textperiodcentered}17; p=0{\textperiodcentered}00035), thyroid (1{\textperiodcentered}09, 1{\textperiodcentered}00–1{\textperiodcentered}19; p=0{\textperiodcentered}0088), and leukaemia (1{\textperiodcentered}09, 1{\textperiodcentered}05–1{\textperiodcentered}13; p≤0{\textperiodcentered}0001). BMI was positively associated with liver (1{\textperiodcentered}19, 1{\textperiodcentered}12–1{\textperiodcentered}27), colon (1{\textperiodcentered}10, 1{\textperiodcentered}07–1{\textperiodcentered}13), ovarian (1{\textperiodcentered}09, 1.04–1.14), and postmenopausal breast cancers (1{\textperiodcentered}05, 1{\textperiodcentered}03–1{\textperiodcentered}07) overall (all p{\textless}0{\textperiodcentered}0001), but these effects varied by underlying BMI or individual-level characteristics. We estimated inverse associations with prostate and premenopausal breast cancer risk, both overall (prostate 0{\textperiodcentered}98, 0{\textperiodcentered}95–1{\textperiodcentered}00; premenopausal breast cancer 0{\textperiodcentered}89, 0{\textperiodcentered}86–0{\textperiodcentered}92) and in never-smokers (prostate 0{\textperiodcentered}96, 0{\textperiodcentered}93–0{\textperiodcentered}99; premenopausal breast cancer 0{\textperiodcentered}89, 0{\textperiodcentered}85–0{\textperiodcentered}94). By contrast, for lung and oral cavity cancer, we observed no association in never smokers (lung 0{\textperiodcentered}99, 0{\textperiodcentered}93–1{\textperiodcentered}05; oral cavity 1{\textperiodcentered}07, 0{\textperiodcentered}91–1{\textperiodcentered}26): inverse associations overall were driven by current smokers and ex-smokers, probably because of residual confounding by smoking amount. Assuming causality, 41{\%} of uterine and 10{\%} or more of gallbladder, kidney, liver, and colon cancers could be attributable to excess weight. We estimated that a 1 kg/m2 population-wide increase in BMI would result in 3790 additional annual UK patients developing one of the ten cancers positively associated with BMI. Interpretation: BMI is associated with cancer risk, with substantial population-level effects. The heterogeneity in the effects suggests that different mechanisms are associated with different cancer sites and different patient subgroups. Funding: National Institute for Health Research, Wellcome Trust, and Medical Research Council.},
author = {Bhaskaran, Krishnan and Douglas, Ian and Forbes, Harriet and Dos-Santos-Silva, Isabel and Leon, David A. and Smeeth, Liam},
doi = {10.1016/S0140-6736(14)60892-8},
file = {::},
issn = {1474547X},
journal = {The Lancet},
number = {9945},
pages = {755--765},
pmid = {25129328},
publisher = {Bhaskaran et al. Open Access article distributed under the terms of CC BY},
title = {{Body-mass index and risk of 22 specific cancers: a population-based cohort study of 5{\textperiodcentered}24 million UK adults}},
url = {http://dx.doi.org/10.1016/S0140-6736(14)60892-8},
volume = {384},
year = {2014}
}
@article{Taves:1974hn,
author = {Taves, Donald R},
file = {::},
journal = {Clinical Pharmacology {\&} Therapeutics},
month = {may},
number = {5},
pages = {443--453},
title = {{Minimization: A new method of assigning patients to treatment and control groups}},
volume = {15},
year = {1974}
}
@article{krause2020covid,
author = {Krause, Philip and Fleming, Thomas R and Longini, Ira and Henao-Restrepo, Ana Maria and Peto, Richard and Dean, N E and Halloran, M E and Huang, Y and Fleming, T R and Gilbert, P B and Others},
journal = {The Lancet},
number = {10253},
pages = {741--743},
publisher = {Elsevier},
title = {{COVID-19 vaccine trials should seek worthwhile efficacy}},
volume = {396},
year = {2020}
}
@article{Little:2011di,
annote = {Published in at http://dx.doi.org/10.1214/10-STS318 the Statistical Science (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics (http://www.imstat.org)},
author = {Little, Roderick},
journal = {arXiv.org},
month = {aug},
number = {2},
pages = {162--174},
title = {{Calibrated Bayes, for Statistics in General, and Missing Data in Particular}},
year = {2011}
}
@article{Janes:2008bg,
author = {Janes, Holly},
journal = {Annals of Internal Medicine},
month = {nov},
number = {10},
pages = {751},
title = {{Assessing the Value of Risk Predictions by Using Risk Stratification Tables}},
volume = {149},
year = {2008}
}
@article{bayarri2004interplay,
author = {Bayarri, M J{\'{e}}sus and Berger, James O},
journal = {Statistical Science},
pages = {58--80},
publisher = {JSTOR},
title = {{The interplay of Bayesian and frequentist analysis}},
year = {2004}
}
@article{Gillespie2021,
author = {Gillespie, D L and Meyers, L A and Lachmann, M and Redd, S C and Zenilman, J M},
doi = {10.1111/josh.13008},
issn = {0022-4391 (Print) 0022-4391},
journal = {J Sch Health},
number = {5},
pages = {347--355},
title = {{The Experience of 2 Independent Schools With In-Person Learning During the COVID-19 Pandemic}},
volume = {91},
year = {2021}
}
@article{Rosenbaum:1984cj,
author = {Rosenbaum, Paul R and Rubin, Donald B},
journal = {The American statistician},
month = {may},
number = {2},
pages = {106--109},
title = {{Sensitivity of Bayes Inference with Data-Dependent Stopping Rules}},
volume = {38},
year = {1984}
}
@article{Kraemer:2007gv,
author = {Kraemer, Helena Chmura},
journal = {Statistics in medicine},
number = {2},
pages = {196--198},
title = {{Comments on {\{}$\backslash$textquoteleft{\}}Evaluating the added predictive ability of a new marker{\{}$\backslash$textquoteright{\}} by M. Pencina, R. D'Agostino, R. D'Agostino Jr, R. Vasan,Statistics in Medicine (DOI: 10.1002/sim.2929)}},
volume = {27},
year = {2007}
}
@article{Greenland:1999te,
author = {Greenland, S and Pearl, J and Robins, J M},
journal = {Epidemiology},
month = {jan},
number = {1},
pages = {37--48},
title = {{Causal diagrams for epidemiologic research.}},
volume = {10},
year = {1999}
}
@article{Allison2015,
abstract = {Background: Visceral leishmaniasis (VL) is a parasitic disease transmitted by sandflies and is fatal if left untreated. Phase II trials of new treatment regimens for VL are primarily carried out to evaluate safety and efficacy, while pharmacokinetic data are also important to inform future combination treatment regimens. The efficacy of VL treatments is evaluated at two time points, initial cure, when treatment is completed and definitive cure, commonly 6 months post end of treatment, to allow for slow response to treatment and detection of relapses. This paper investigates a generalization of the triangular design to impose a minimum sample size for pharmacokinetic or other analyses, and methods to estimate efficacy at extended follow-up accounting for the sequential design and changes in cure status during extended follow-up. Methods: We provided R functions that generalize the triangular design to impose a minimum sample size before allowing stopping for efficacy. For estimation of efficacy at a second, extended, follow-up time, the performance of a shrinkage estimator (SHE), a probability tree estimator (PTE) and the maximum likelihood estimator (MLE) for estimation was assessed by simulation. Results: The SHE and PTE are viable approaches to estimate an extended follow-up although the SHE performed better than the PTE: the bias and root mean square error were lower and coverage probabilities higher. Conclusions: Generalization of the triangular design is simple to implement for adaptations to meet requirements for pharmacokinetic analyses. Using the simple MLE approach to estimate efficacy at extended follow-up will lead to biased results, generally over-estimating treatment success. The SHE is recommended in trials of two or more treatments. The PTE is an acceptable alternative for one-arm trials or where use of the SHE is not possible due to computational complexity.},
author = {Allison, Annabel and Edwards, Tansy and Omollo, Raymond and Alves, Fabiana and Magirr, Dominic and Alexander, Neal D.E.},
doi = {10.1186/s13063-015-1018-1},
file = {::;::},
issn = {17456215},
journal = {Trials},
keywords = {Randomized trials,Sequential methods,Shrinkage estimator,Triangular boundaries,Visceral leishmaniasis},
number = {1},
pmid = {26573827},
title = {{Generalizing boundaries for triangular designs, and efficacy estimation at extended follow-ups}},
volume = {16},
year = {2015}
}
@article{Dirac1953888,
author = {Dirac, P A M},
doi = {10.1016/S0031-8914(53)80099-6},
journal = {Physica},
number = {1-–12},
pages = {888--896},
title = {{The lorentz transformation and absolute time}},
volume = {19},
year = {1953}
}
@article{Hartman:2013iy,
author = {Hartman, Mark L and Xu, Rong and Crowe, Brenda J and Robison, Leslie L and Erfurth, Eva Marie and Kleinberg, David L and Zimmermann, Alan G and Woodmansee, Whitney W and {Cutler Jr.}, Gordon B and Chipman, John J and Melmed, Shlomo},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {mar},
number = {3},
pages = {980--988},
title = {{Prospective Safety Surveillance of GH-Deficient Adults: Comparison of GH-Treated vs Untreated Patients}},
volume = {98},
year = {2013}
}
@article{bergenstal2013threshold,
author = {Bergenstal, Richard M and Klonoff, David C and Garg, Satish K and Bode, Bruce W and Meredith, Melissa and Slover, Robert H and Ahmann, Andrew J and Welsh, John B and Lee, Scott W and Kaufman, Francine R},
journal = {New England Journal of Medicine},
number = {3},
pages = {224--232},
publisher = {Mass Medical Soc},
title = {{Threshold-based insulin-pump interruption for reduction of hypoglycemia}},
volume = {369},
year = {2013}
}
@article{Vidrine2013,
author = {Vidrine, J I and Reitzel, L R and Figueroa, P Y and Velasquez, M M and Mazas, C A and Cinciripini, P M and Wetter, D W},
doi = {10.1016/j.cbpra.2011.11.001},
issn = {1077-7229 (Print) 1077-7229},
journal = {Cogn Behav Pract},
number = {4},
pages = {501--516},
title = {{Motivation and Problem Solving (MAPS): Motivationally based skills training for treating substance use}},
volume = {20},
year = {2013}
}
@article{Smith:1979kr,
author = {Smith, Patricia L},
journal = {The American statistician},
month = {may},
number = {2},
pages = {57--62},
title = {{Splines as a Useful and Convenient Statistical Tool}},
volume = {33},
year = {1979}
}
@article{Hewitt:2006ht,
author = {Hewitt, C E},
journal = {BMJ},
month = {jun},
number = {7556},
pages = {1506--1508},
title = {{Is restricted randomisation necessary?}},
volume = {332},
year = {2006}
}
@article{Li:2013ke,
author = {Li, Liang and Greene, Tom},
journal = {The international journal of biostatistics},
month = {jul},
number = {2},
pages = {215--234},
title = {{A weighting analogue to pair matching in propensity score analysis.}},
volume = {9},
year = {2013}
}
@article{Kastrinos:2011eq,
author = {Kastrinos, Fay and Steyerberg, Ewout W and Mercado, Rowena and Balma{\~{n}}a, Judith and Holter, Spring and Gallinger, Steven and Siegmund, Kimberly D and Church, James M and Jenkins, Mark A and Lindor, Noralane M and Thibodeau, Stephen N and Burbidge, Lynn Anne and Wenstrup, Richard J and Syngal, Sapna},
journal = {Gastroenterology},
month = {jan},
number = {1},
pages = {73----81.e5},
title = {{The PREMM1,2,6 Model Predicts Risk of MLH1, MSH2, and MSH6 Germline Mutations Based on Cancer History}},
volume = {140},
year = {2011}
}
@article{Zhou2018,
abstract = {The seminal work of [Morgan 2012] considers rerandomization for a sample of size {\$}2N{\$} units all randomized at one time. In practice, however, experimenters may have to rerandomize units sequentially. For example, a clinician studying a rare disease may be unable to wait to perform an experiment until all {\$}2N{\$} experimental units are recruited. Our work offers a mathematical framework for sequential designs using rerandomization. Given the same number of rerandomizations (in expected value), a seemingly natural conjecture would be that the matches created by rerandomization at one time would, in expectation, be more balanced than those generated by sequential rerandomization. Surprisingly, under certain assumptions, our key result in Theorem 3 proves the opposite to be true. We further study sequential rerandomization using simulated data as well as publicly available clinical data from the TCGA-UCEC project.},
author = {Zhou, Quan and Ernst, Philip A. and Morgan, Kari Lock and Rubin, Donald B. and Zhang, Anru},
doi = {10.1093/biomet/asy031},
issn = {14643510},
journal = {Biometrika},
keywords = {Experimental design,Mahalanobis distance,Noncentral chi-squared distribution,Sequential enrolment},
number = {3},
pages = {745--752},
title = {{Sequential rerandomization}},
volume = {105},
year = {2018}
}
@article{Brazer:1991fu,
author = {Brazer, Scott R and Pancotto, Frank S and {Long III}, Thomas T and {Harrell Jr}, Frank E and Lee, Kerry L and Tyor, Malcolm P and Pryor, David B},
journal = {Journal of Clinical Epidemiology},
month = {jan},
number = {11},
pages = {1263--1270},
title = {{Using ordinal logistic regression to estimate the likelihood of colorectal neoplasia}},
volume = {44},
year = {1991}
}
@article{Wang2007,
abstract = {With the advances in human genomic/genetic studies, the clinical trial community gradually recognizes that phenotypically homogeneous patients may be heterogeneous at the genomic level. The genomic technology brings a possible avenue for developing a genomic (composite) biomarker to predict a genomically responsive patient subset that may have a (much) higher likelihood of benefiting from a treatment. Randomized controlled trial is the mainstay to provide scientifically convincing evidence of a purported effect a new treatment may demonstrate. In conventional clinical trials, the primary clinical hypothesis pertains to the therapeutic effect in all patients who are eligible for the study defined by the primary efficacy endpoint. The aspect of one-size-fits-all surrounding the conventional design has been challenged, particularly when the diseases may be heterogeneous due to observable clinical characteristics and/or unobservable underlying the genomic characteristics. Extension from the conventional single population design objective to an objective that encompasses two possible patient populations will allow more informative evaluation in the patients having different degrees of responsiveness to medication. Building in conventional clinical trials, an additional genomic objective can generate an appealing conceptual framework from the patient's perspective in addressing personalized medicine in well-controlled clinical trials. There are many perceived benefits of personalized medicine that are based on the notion of being genomically proactive in the identification of disease and prevention of disease or recurrence. In this paper, we show that an adaptive design approach can be constructed to study a clinical hypothesis of overall treatment effect and a hypothesis of treatment effect in a genomic subset more efficiently than the conventional non-adaptive approach.},
author = {Wang, Sue Jane and O'Neill, Robert T. and Hung, H. M.James},
doi = {10.1002/pst.300},
file = {::},
issn = {15391604},
journal = {Pharmaceutical Statistics},
keywords = {Adaptive design,Alpha allocation,Effect size ratio,Futility,Genomic composite biomarker,Prevalence},
number = {3},
pages = {227--244},
pmid = {17688238},
title = {{Approaches to evaluation of treatment effect in randomized clinical trials with genomic subset}},
volume = {6},
year = {2007}
}
@article{White:2010id,
author = {White, Ian R and Carlin, John B},
journal = {Statistics in medicine},
month = {sep},
number = {28},
pages = {2920--2931},
title = {{Bias and efficiency of multiple imputation compared with complete-case analysis for missing covariate values}},
volume = {29},
year = {2010}
}
@article{Parmar2008,
abstract = {Despite both the increase in basic biologic knowledge and the fact that many new agents have reached various stages of development during the last 10 years, the number of new treatments that have been approved for patients has not increased as expected. We propose the multi-arm, multi-stage trial design as a way to evaluate treatments faster and more efficiently than current standard trial designs. By using intermediate outcomes and testing a number of new agents (and combinations) simultaneously, the new design requires fewer patients. Three trials using this methodology are presented. {\textcopyright} 2008 The Author(s).},
author = {Parmar, Mahesh K.B. and Barthel, Friederike M.S. and Sydes, Matthew and Langley, Ruth and Kaplan, Rick and Eisenhauer, Elizabeth and Brady, Mark and James, Nicholas and Bookman, Michael A. and Swart, Ann Marie and Qian, Wendi and Royston, Patrick},
doi = {10.1093/jnci/djn267},
issn = {00278874},
journal = {Journal of the National Cancer Institute},
number = {17},
pages = {1204--1214},
pmid = {18728279},
title = {{Speeding up the evaluation of new agents in cancer}},
volume = {100},
year = {2008}
}
@article{Mao2019,
author = {Mao, Huzhang and Li, Liang and Greene, Tom},
journal = {Statistical methods in medical research},
number = {8},
pages = {2439--2454},
publisher = {SAGE Publications Sage UK: London, England},
title = {{Propensity score weighting analysis and treatment effect discovery}},
volume = {28},
year = {2019}
}
@article{Holland:1985hj,
author = {Holland, Paul W and Glymour, Clark and Granger, Clive},
journal = {ETS Research Report Series},
month = {dec},
number = {2},
pages = {i----72},
title = {{STATISTICS AND CAUSAL INFERENCE}},
volume = {1985},
year = {1985}
}
@article{Anonymous:EKo03RNu,
month = {nov},
pages = {1},
title = {{HONORCODE}},
year = {2018}
}
@article{Meyers:2014io,
author = {Meyers, Abby G and Salanitro, Amanda and Wallston, Kenneth A and Cawthon, Courtney and Vasilevskis, Eduard E and Goggins, Kathryn M and Davis, Corinne M and Rothman, Russell L and Castel, Liana D and Donato, Katharine M and Schnelle, John F and Bell, Susan P and Schildcrout, Jonathan S and Osborn, Chandra Y and Harrell, Frank E and Kripalani, Sunil},
journal = {BMC Health Services Research},
month = {jan},
number = {1},
pages = {314},
title = {{Determinants of health after hospital discharge: rationale and design of the Vanderbilt Inpatient Cohort Study (VICS)}},
volume = {14},
year = {2014}
}
@article{Blume:2003ed,
author = {Blume, Jeffrey and Peipert, Jeffrey F},
journal = {The Journal of the American Association of Gynecologic Laparoscopists},
month = {nov},
number = {4},
pages = {439--444},
title = {{What Your Statistician Never Told You about P-Values}},
volume = {10},
year = {2003}
}
@article{Zhang2021,
abstract = {Rerandomization has recently attracted more attention in the literature randomized experiments. It leverages covariate information of participants to achieve a well-balanced allocation, and thus improves the efficiency of inference. However, by only considering covariate information, it may lead to potential ethical issues in clinical trials as a large number of patients might be assigned to the inferior treatment arm. To mitigate this issue, we propose a response-adaptive rerandomization scheme by incorporating response information for two-arm comparative clinical trials. Not only is our method applicable to both continuous and binary outcomes, but it also demonstrates desirable statistical and ethical properties. Extensive simulation studies are performed to illustrate the practicality and superiority of our approach.},
author = {Zhang, Hengtao and Yin, Guosheng},
doi = {10.1111/rssc.12513},
file = {::},
issn = {14679876},
journal = {Journal of the Royal Statistical Society. Series C: Applied Statistics},
keywords = {clinical trial,randomization,response-adaptive design,sequential enrolment},
number = {5},
pages = {1281--1298},
title = {{Response-adaptive rerandomization}},
volume = {70},
year = {2021}
}
@article{little2013,
abstract = {The importance of hemoglobin A1c (HbA1c) as an indicator of mean glycemia and risks for complications in patients with diabetes mellitus was established by the results of long-term clinical trials, most notably the Diabetes Control and Complications Trial (DCCT) and United Kingdom Prospective Diabetes Study (UKPDS), published in 1993 and 1998 respectively. However, clinical application of recommended HbA1c targets that were based on these studies was difficult due to lack of comparability of HbA1c results among assay methods and laboratories. Thus, the National Glycohemoglobin Standardization Program (NGSP) was initiated in 1996 with the goal of standardizing HbA1c results to those of the DCCT/UKPDS. HbA1c standardization efforts have been highly successful; however, a number of issues have emerged on the "long and winding road" to better HbA1c, including the development of a higher-order HbA1c reference method by the International Federation of Clinical Chemistry (IFCC), recommendations to use HbA1c to diagnose as well as monitor diabetes, and point-of-care (POC) HbA1c testing. Here, we review the past, present and future of HbA1c standardization and describe the current status of HbA1c testing, including limitations that healthcare providers need to be aware of when interpreting HbA1c results. {\textcopyright} 2013 Elsevier B.V.},
author = {Little, Randie R. and Rohlfing, Curt L.},
doi = {10.1016/j.cca.2012.12.026},
issn = {00098981},
journal = {Clinica Chimica Acta},
keywords = {Diabetes,Glycated hemoglobin,HbA1c,Standardization},
pages = {63--71},
pmid = {23318564},
title = {{The long and winding road to optimal HbA1c measurement}},
volume = {418},
year = {2013}
}
@article{Benkeser2021,
abstract = {Time is of the essence in evaluating potential drugs and biologics for the treatment and prevention of COVID-19. There are currently 876 randomized clinical trials (phase 2 and 3) of treatments for COVID-19 registered on clinicaltrials.gov. Covariate adjustment is a statistical analysis method with potential to improve precision and reduce the required sample size for a substantial number of these trials. Though covariate adjustment is recommended by the U.S. Food and Drug Administration and the European Medicines Agency, it is underutilized, especially for the types of outcomes (binary, ordinal, and time-to-event) that are common in COVID-19 trials. To demonstrate the potential value added by covariate adjustment in this context, we simulated two-arm, randomized trials comparing a hypothetical COVID-19 treatment versus standard of care, where the primary outcome is binary, ordinal, or time-to-event. Our simulated distributions are derived from two sources: longitudinal data on over 500 patients hospitalized at Weill Cornell Medicine New York Presbyterian Hospital and a Centers for Disease Control and Prevention preliminary description of 2449 cases. In simulated trials with sample sizes ranging from 100 to 1000 participants, we found substantial precision gains from using covariate adjustment-equivalent to 4-18{\%} reductions in the required sample size to achieve a desired power. This was the case for a variety of estimands (targets of inference). From these simulations, we conclude that covariate adjustment is a low-risk, high-reward approach to streamlining COVID-19 treatment trials. We provide an R package and practical recommendations for implementation.},
author = {Benkeser, David and D{\'{i}}az, Iv{\'{a}}n and Luedtke, Alex and Segal, Jodi and Scharfstein, Daniel and Rosenblum, Michael},
doi = {10.1111/biom.13377},
issn = {15410420},
journal = {Biometrics},
keywords = {COVID-19,covariate adjustment,ordinal outcomes,randomized trial,survival analysis},
number = {4},
pages = {1467--1481},
pmid = {32978962},
title = {{Improving precision and power in randomized trials for COVID-19 treatments using covariate adjustment, for binary, ordinal, and time-to-event outcomes}},
volume = {77},
year = {2021}
}
@article{Collins:2000bp,
author = {Collins, Steve and Myatt, Mark},
journal = {JAMA},
month = {aug},
number = {5},
pages = {621},
title = {{Short-term Prognosis in Severe Adult and Adolescent Malnutrition During Famine}},
volume = {284},
year = {2000}
}
@article{Dmitrienko2006,
abstract = {This paper reviews Bayesian strategies for monitoring clinical trial data. It focuses on a Bayesian stochastic curtailment method based on the predictive probability of observing a clinically significant outcome at the scheduled end of the study given the observed data. The proposed method is applied to derive efficacy and futility stopping rules in clinical trials with continuous, normally distributed and binary endpoints. The sensitivity of the resulting stopping rules to the choice of prior distributions is examined and guidelines for choosing a prior distribution of the treatment effect are discussed. The Bayesian predictive approach is compared to the frequentist (conditional power) and mixed Bayesian-frequentist (predictive power) approaches. The interim monitoring strategies discussed in the paper are illustrated using examples from a small proof-of-concept study and a large mortality trial. Copyright {\textcopyright} 2005 John Wiley {\&} Sons, Ltd.},
author = {Dmitrienko, Alexei and Wang, Ming Dauh},
doi = {10.1002/sim.2204},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Bayesian predictive inference,Clinical trials,Interim analysis,Predictive distribution,Stopping rule},
number = {13},
pages = {2178--2195},
pmid = {16007570},
title = {{Bayesian predictive approach to interim monitoring in clinical trials}},
volume = {25},
year = {2006}
}
@article{Pencina2011,
abstract = {Appropriate quantification of added usefulness offered by new markers included in risk prediction algorithms is a problem of active research and debate. Standard methods, including statistical significance and c statistic are useful but not sufficient. Net reclassification improvement (NRI) offers a simple intuitive way of quantifying improvement offered by new markers and has been gaining popularity among researchers. However, several aspects of the NRI have not been studied in sufficient detail.In this paper we propose a prospective formulation for the NRI which offers immediate application to survival and competing risk data as well as allows for easy weighting with observed or perceived costs. We address the issue of the number and choice of categories and their impact on NRI. We contrast category-based NRI with one which is category-free and conclude that NRIs cannot be compared across studies unless they are defined in the same manner. We discuss the impact of differing event rates when models are applied to different samples or definitions of events and durations of follow-up vary between studies. We also show how NRI can be applied to case-control data. The concepts presented in the paper are illustrated in a Framingham Heart Study example.In conclusion, NRI can be readily calculated for survival, competing risk, and case-control data, is more objective and comparable across studies using the category-free version, and can include relative costs for classifications. We recommend that researchers clearly define and justify the choices they make when choosing NRI for their application. Copyright {\textcopyright} 2010 John Wiley {\&} Sons, Ltd.},
author = {Pencina, Michael J. and D'Agostino, Ralph B. and Steyerberg, Ewout W.},
doi = {10.1002/sim.4085},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Biomarker,Discrimination,Model performance,NRI,Risk prediction},
number = {1},
pages = {11--21},
pmid = {21204120},
title = {{Extensions of net reclassification improvement calculations to measure usefulness of new biomarkers}},
volume = {30},
year = {2011}
}
@article{Magee:1990dz,
author = {Magee, Lonnie},
journal = {The American statistician},
month = {aug},
number = {3},
pages = {250--253},
title = {{R2Measures Based on Wald and Likelihood Ratio Joint Significance Tests}},
volume = {44},
year = {1990}
}
@misc{avastin2018,
author = {{U.S. Food and Drug Administration}},
booktitle = {https://www.accessdata.fda.gov/drugsatfda{\_}docs/label/2018/125085s323lbl.pdf},
file = {::},
howpublished = {https://www.accessdata.fda.gov/drugsatfda{\_}docs/label/2018/125085s323lbl.pdf},
isbn = {1855274132},
issn = {01478389},
title = {{Avastin: Highlights of Prescribing Information}},
url = {https://www.accessdata.fda.gov/drugsatfda{\_}docs/label/2018/125085s323lbl.pdf},
year = {2018}
}
@article{ding2018causal,
author = {Ding, Peng and Li, Fan},
file = {::},
journal = {Statistical Science},
number = {2},
pages = {214--237},
publisher = {JSTOR},
title = {{Causal Inference}},
volume = {33},
year = {2018}
}
@incollection{Siegel:2016wz,
author = {Siegel, Andrew F},
booktitle = {Practical Business Statistics},
pages = {419--430},
publisher = {Elsevier},
title = {{Report Writing}},
year = {2016}
}
@misc{RN1,
author = {{for Disease Control}, Centers and Prevention},
number = {August 22},
title = {{COVID Data Tracker}},
type = {Web Page},
url = {https://covid.cdc.gov/covid-data-tracker/{\#}datatracker-home},
volume = {2023},
year = {2023}
}
@misc{Anonymous:2016ww,
howpublished = {Springer International Publishing},
month = {mar},
title = {{ACCRE: Introduction to the cluster}},
year = {2016}
}
@article{Tchetgen2012,
abstract = {Interference is said to be present when the exposure or treatment received by one individual may affect the outcomes of other individuals. Such interference can arise in settings in which the outcomes of the various individuals come about through social interactions. When interference is present, causal inference is rendered considerably more complex, and the literature on causal inference in the presence of interference has just recently begun to develop. In this article we summarise some of the concepts and results from the existing literature and extend that literature in considering new results for finite sample inference, new inverse probability weighting estimators in the presence of interference and new causal estimands of interest. {\textcopyright} The Author(s) 2010.},
author = {Tchetgen, Eric J.Tchetgen and Vanderweele, Tyler J.},
doi = {10.1177/0962280210386779},
issn = {09622802},
journal = {Statistical Methods in Medical Research},
keywords = {SUTVA,causal inference,interference,spillover effects,two-stage randomisation},
number = {1},
pages = {55--75},
pmid = {21068053},
title = {{On causal inference in the presence of interference}},
volume = {21},
year = {2012}
}
@article{Anonymous:bocePNw0,
author = {B, R Tibshirani Journal of the Royal Statistical Society Series and 2011 and Tibshirani, Robert and 2011},
journal = {Journal of the Royal Statistical Society Series B},
number = {1},
pages = {267--288},
title = {{Regression shrinkage and selection via the lasso: a retrospective}},
volume = {58},
year = {1996}
}
@article{Sidley:2010fp,
author = {Sidley, Gary L and Calam, Rachel and Wells, Adrian and Hughes, Trevine and Whitaker, Kim},
journal = {British Journal of Clinical Psychology},
month = {dec},
number = {4},
pages = {375--386},
title = {{The prediction of parasuicide repetition in a high-risk group}},
volume = {38},
year = {2010}
}
@article{Canary:2016ek,
author = {Canary, Jana D and Blizzard, Leigh and Barry, Ronald P and Hosmer, David W and Quinn, Stephen J},
journal = {Biometrical journal. Biometrische Zeitschrift},
month = {may},
number = {3},
pages = {674--690},
title = {{Summary goodness-of-fit statistics for binary generalized linear models with noncanonical link functions.}},
volume = {58},
year = {2016}
}
@article{Ding2017a,
abstract = {There are two general views in causal analysis of experimental data: the super population view that the units are an independent sample from some hypothetical infinite population, and the finite population view that the potential outcomes of the experimental units are fixed and the randomness comes solely from the treatment assignment. These two views differs conceptually and mathematically, resulting in different sampling variances of the usual difference-in-means estimator of the average causal effect. Practically, however, these two views result in identical variance estimators. By recalling a variance decomposition and exploiting a completeness-type argument, we establish a connection between these two views in completely randomized experiments. This alternative formulation could serve as a template for bridging finite and super population causal inference in other scenarios.},
archivePrefix = {arXiv},
arxivId = {1702.08615},
author = {Ding, Peng and Li, Xinran and Miratrix, Luke W.},
doi = {10.1515/jci-2016-0027},
eprint = {1702.08615},
journal = {Journal of Causal Inference},
keywords = {completeness,finite population correction,of individual causal effects,potential outcomes,simple random sample,variance},
number = {2},
title = {{Bridging Finite and Super Population Causal Inference}},
volume = {5},
year = {2017}
}
@article{Spanos:1989gy,
author = {Spanos, Alan},
journal = {JAMA},
month = {nov},
number = {19},
pages = {2700},
title = {{Differential Diagnosis of Acute Meningitis}},
volume = {262},
year = {1989}
}
@article{Nicholas:2015gi,
author = {Nicholas, Katherine and Yeatts, Sharon D and Zhao, Wenle and Ciolino, Jody and Borg, Keith and Durkalski, Valerie},
journal = {Statistics in medicine},
month = {feb},
number = {11},
pages = {1834--1840},
title = {{The impact of covariate adjustment at randomization and analysis for binary outcomes: understanding differences between superiority and noninferiority trials}},
volume = {34},
year = {2015}
}
@article{thall2015,
abstract = {Background: In recent years, various outcome adaptive randomization (AR) methods have been used to conduct comparative clinical trials. Rather than randomizing patients equally between treatments, outcome AR uses the accumulating data to unbalance the randomization probabilities in favor of the treatment arm that currently is superior empirically. This is motivated by the idea that, on average, more patients in the trial will be given the treatment that is truly superior, so AR is ethically more desirable than equal randomization. AR remains controversial, however, and some of its properties are not well understood by the clinical trials community. Materials and methods: Computer simulation was used to evaluate properties of a 200-patient clinical trial conducted using one of four Bayesian AR methods and compare them to an equally randomized group sequential design. Results: Outcome AR has several undesirable properties. These include a high probability of a sample size imbalance in the wrong direction, which might be surprising to nonstatisticians, wherein many more patients are assigned to the inferior treatment arm, the opposite of the intended effect. Compared with an equally randomized design, outcome AR produces less reliable final inferences, including a greatly overestimated actual treatment effect difference and smaller power to detect a treatment difference. This estimation bias becomes much larger if the prognosis of the accrued patients either improves or worsens systematically during the trial. Conclusions: AR produces inferential problems that decrease potential benefit to future patients, and may decrease benefit to patients enrolled in the trial. These problems should be weighed against its putative ethical benefit. For randomized comparative trials to obtain confirmatory comparisons, designs with fixed randomization probabilities and group sequential decision rules appear to be preferable to AR, scientifically, and ethically.},
author = {Thall, Peter F. and Fox, P. and Wathen, J.},
doi = {10.1093/annonc/mdv238},
file = {::},
issn = {15698041},
journal = {Annals of Oncology},
keywords = {Adaptive randomization,Bayesian design,Clinical trial,Estimation bias,Ethics,Group sequential design},
number = {8},
pages = {1621--1628},
pmid = {25979922},
publisher = {Elsevier Masson SAS},
title = {{Statistical controversies in clinical research: Scientific and ethical problems with adaptive randomization in comparative clinical trials}},
url = {https://doi.org/10.1093/annonc/mdv238},
volume = {26},
year = {2015}
}
@article{RubinD.B1974,
abstract = {A discussion of matching, randomization, random sampling, and other methods of controlling extraneous variation is presented. The objective is to specify the benefits of randomization in estimating causal effects of treatments. The basic conclusion is that randomization should be employed whenever possible but that the use of carefully controlled nonrandomized data to estimate causal effects is a reasonable and nec-essary procedure in many cases.},
author = {{Rubin D. B}},
journal = {Journal of Educational Psychology},
number = {5},
pages = {688--701},
title = {{Estimating causal effects of treatment in randomized and nonrandomized studies}},
url = {http://www.fsb.muohio.edu/lij14/420{\_}paper{\_}Rubin74.pdf},
volume = {66},
year = {1974}
}
@article{Pencina:2012km,
author = {Pencina, M J and D'Agostino, R B and Pencina, K M and Janssens, A C J W and Greenland, P},
journal = {American Journal of Epidemiology},
month = {sep},
number = {6},
pages = {473--481},
title = {{Interpreting Incremental Value of Markers Added to Risk Prediction Models}},
volume = {176},
year = {2012}
}
@misc{U.S.FoodandDrugAdministration2017,
author = {{U.S. Food and Drug Administration}},
booktitle = {https://www.fda.gov/media/108953/download},
file = {::},
howpublished = {https://www.fda.gov/media/108953/download},
keywords = {4139813,pediatric subjects,reference id},
title = {{Statistical Review and Evaluation of NDA/Serial Number: 125261 / 138}},
url = {https://www.fda.gov/media/108953/download},
urldate = {2023-02-03},
year = {2017}
}
@article{lachin1981introduction,
author = {Lachin, John M},
journal = {Controlled clinical trials},
number = {2},
pages = {93--113},
publisher = {Elsevier},
title = {{Introduction to sample size determination and power analysis for clinical trials}},
volume = {2},
year = {1981}
}
@article{Savage:2009vb,
author = {Olavarria, G and Ritter, A},
journal = {AAP Grand Rounds},
month = {may},
number = {5},
pages = {60},
title = {{Managing CSF Shunt Malfunctions: A New Clinical Pathway}},
volume = {25},
year = {2011}
}
@article{Willems2022,
author = {Willems, S J and Castells, M C and Baptist, A P},
doi = {10.1016/j.jaip.2022.01.032},
issn = {2213-2201 (Electronic) 2213-2198 (Print)},
journal = {J Allergy Clin Immunol Pract},
number = {4},
pages = {903--908},
title = {{The Magnification of Health Disparities During the COVID-19 Pandemic}},
volume = {10},
year = {2022}
}
@article{Hill:1963vl,
author = {Hill, A B},
journal = {British Medical Journal},
month = {apr},
number = {5337},
pages = {1043--1049},
title = {{Medical ethics and controlled trials.}},
volume = {1},
year = {1963}
}
@incollection{Binder:1996vz,
address = {Chichester, UK},
author = {Fuller, Wayne A},
booktitle = {Analysis of Survey Data},
month = {mar},
pages = {307--322},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Estimation for Multiple Phase Samples}},
year = {2003}
}
@article{Berger:2003iv,
author = {Berger, Vance W and Bears, Jeffrey D},
journal = {Vaccine},
month = {jan},
number = {5-6},
pages = {468--472},
title = {{When can a clinical trial be called {\{}$\backslash$textquoteleft{\}}randomized{\{}$\backslash$textquoteright{\}}?}},
volume = {21},
year = {2003}
}
@article{,
title = {{PDUFA REAUTHORIZATION PERFORMANCE GOALS AND PROCEDURES FISCAL YEARS 2018 THROUGH 2022}},
url = {https://www.fda.gov/media/99140/download}
}
@article{Gamalo:2016jt,
author = {Gamalo, M Amper and Wu, Rui and Tiwari, Ram C},
journal = {Statistical Methods in Medical Research},
month = {feb},
number = {1},
pages = {221--240},
title = {{Bayesian approach to non-inferiority trials for normal means}},
volume = {25},
year = {2016}
}
@article{Kang2018a,
abstract = {The method of instrumental variables provides a framework to study causal effects in both randomized experiments with non-compliance and in observational studies where natural circumstances produce as if random nudges to accept treatment. Traditionally, inference for instrumental variables relied on asymptotic approximations of the distribution of the Wald estimator or two-stage least squares, often with structural modelling assumptions and/or moment conditions. We utilize the randomization inference approach to instrumental variables inference. First, we outline the exact method, which uses the randomized assignment of treatment in experiments as a basis for inference but lacks a closed form solution and may be computationally infeasible in many applications. We then provide an alternative to the exact method, the almost exact method, which is computationally feasible but retains the advantages of the exact method. We also review asymptotic methods of inference, including those associated with two-stage least squares, and analytically compare them with randomization inference methods. We also perform additional comparisons by using a set of simulations. We conclude with three different applications from the social sciences.},
archivePrefix = {arXiv},
arxivId = {1606.04146},
author = {Kang, Hyunseung and Peck, Laura and Keele, Luke},
doi = {10.1111/rssa.12353},
eprint = {1606.04146},
file = {::;::},
issn = {1467985X},
journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
keywords = {Effect ratio,Exclusion restriction,Instrumental variables,Randomization inference,Weak instrument},
number = {4},
pages = {1231--1254},
title = {{Inference for instrumental variables: a randomization inference approach}},
volume = {181},
year = {2018}
}
@article{Nattino:2016et,
author = {Nattino, Giovanni and Finazzi, Stefano and Bertolini, Guido},
journal = {Statistics in medicine},
month = {feb},
number = {5},
pages = {709--720},
title = {{A new test and graphical tool to assess the goodness of fit of logistic regression models}},
volume = {35},
year = {2016}
}
@book{Anonymous:2008ul,
address = {Hoboken, NJ, USA},
month = {jul},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Classical and Adaptive Clinical Trial Designs using Expdesign Studio{\{}$\backslash$texttrademark{\}}}},
year = {2008}
}
@article{pallmann2018adaptive,
author = {Pallmann, Philip and Bedding, Alun W and Choodari-Oskooei, Babak and Dimairo, Munyaradzi and Flight, Laura and Hampson, Lisa V and Holmes, Jane and Mander, Adrian P and Sydes, Matthew R and Villar, Sof$\backslash$'$\backslash$ia S and Others},
journal = {BMC medicine},
number = {1},
pages = {1--15},
publisher = {BioMed Central},
title = {{Adaptive designs in clinical trials: why use them, and how to run and report them}},
volume = {16},
year = {2018}
}
@incollection{gabbay2011philosophy,
author = {Gabbay, Dov and Thagard, Paul and Woods, John},
booktitle = {Philosophy of Statistics},
pages = {vii----viii},
publisher = {Elsevier},
title = {{General Preface}},
year = {2011}
}
@book{Maclaurin:2014ux,
address = {Chichester, UK},
author = {Barnes, Katherine},
month = {apr},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Markov Chain Monte Carlo (MCMC)}},
year = {2014}
}
@article{VanderWeele:2013cj,
author = {VanderWeele, Tyler and Vansteelandt, Stijn},
journal = {Epidemiologic Methods},
number = {1},
title = {{Mediation Analysis with Multiple Mediators}},
volume = {2}
}
@article{Carlsson:2012cr,
author = {Carlsson, Sigrid and Vickers, Andrew and Lilja, Hans and Hugosson, Jonas},
journal = {Annals of Internal Medicine},
month = {apr},
number = {7},
pages = {539},
title = {{Screening for Prostate Cancer}},
volume = {156},
year = {2012}
}
@article{,
file = {::},
issn = {00316873},
journal = {Pharmaceutical Journal},
number = {7224},
pages = {705},
publisher = {NICE},
title = {{NICE citizens council selected}},
volume = {269},
year = {2002}
}
@article{Williams2022,
author = {Williams, Nathaniel J and Preacher, Kristopher J and Allison, Paul D and Mandell, David S and Marcus, Steven C},
doi = {10.1186/s13012-022-01235-2},
file = {::},
issn = {1748-5908},
journal = {Implementation Science},
keywords = {Indirect effects,Mediation,Mplus,Multilevel,Statistical power,boisestate,correspondence,edu,indirect effects,mediation,mplus,multilevel,natewilliams,statistical power},
pages = {1--13},
publisher = {BioMed Central},
title = {{Required sample size to detect mediation in 3 ‑ level implementation studies}},
url = {https://doi.org/10.1186/s13012-022-01235-2},
year = {2022}
}
@article{Pepe:2008cp,
author = {Pepe, M S and Feng, Z and Huang, Y and Longton, G and Prentice, R and Thompson, I M and Zheng, Y},
journal = {American Journal of Epidemiology},
month = {nov},
number = {3},
pages = {362--368},
title = {{Integrating the Predictiveness of a Marker with Its Performance as a Classifier}},
volume = {167},
year = {2007}
}
@article{Wang2014,
abstract = {Rapid changes of new technologies, market dynamics, and swift fluctuation of customer tastes acerbate the needs for companies to identifying the emerging customer requirements and incorporate them in the conceptual design stage. Discovering emerging customer needs has great potential to create new product opportunities for the success of business. However, identifying customers' requirements in an early design stage has not been well addressed in the traditional design methodology. Because emerging needs are usually not obvious at the budding stage, the related observations are rare in dataset. Traditional methods fall short of providing enough support of eliciting the below-the-radar needs. This paper reports a new approach to identify emerging customer needs in the growing popular online interactive environment with customer participation. The Bayes factor, a methodology to quantify the occurrence possibility of a certain event, is used to calculate the likelihood that current offering cannot meet the customer's requirements whenever a new specification is incorporated. With the sequential input from customers, a series of the Bayes factor value can then be calculated as the weight of evidence that emerging customer needs appear. We show that the decreased value will be the potentially emerging needs which cannot be satisfied by the current product family. Numerical and analytical results are derived to demonstrate the viability and effectiveness of the proposed approach. {\textcopyright} 1988-2012 IEEE.},
author = {Wang, Yue and Tseng, Mitchell M.},
doi = {10.1109/TEM.2013.2248729},
file = {::},
issn = {00189391},
journal = {IEEE Transactions on Engineering Management},
keywords = {Bayes factor,customer needs identification,product design},
number = {1},
pages = {129--137},
publisher = {IEEE},
title = {{Identifying emerging customer requirements in an early design stage by applying bayes factor-based sequential analysis}},
volume = {61},
year = {2014}
}
@article{White2011,
abstract = {Multiple imputation by chained equations is a flexible and practical approach to handling missing data. We describe the principles of the method and show how to impute categorical and quantitative variables, including skewed variables. We give guidance on how to specify the imputation model and how many imputations are needed. We describe the practical analysis of multiply imputed data, including model building and model checking. We stress the limitations of the method and discuss the possible pitfalls. We illustrate the ideas using a data set in mental health, giving Stata code fragments. Copyright {\textcopyright} 2010 John Wiley {\&} Sons, Ltd.},
author = {White, Ian R. and Royston, Patrick and Wood, Angela M.},
doi = {10.1002/sim.4067},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/White, Royston, Wood - 2011 - Multiple imputation using chained equations Issues and guidance for practice.pdf:pdf},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Fully conditional specification,Missing data,Multiple imputation},
number = {4},
pages = {377--399},
title = {{Multiple imputation using chained equations: Issues and guidance for practice}},
volume = {30},
year = {2011}
}
@article{Tibshirani:1996bc,
author = {Tibshirani, R},
journal = {Journal of the Royal Statistical Society Series B ( {\ldots}},
title = {{Regression shrinkage and selection via the lasso}},
year = {1996}
}
@article{little2006,
abstract = {The lack of an agreed inferential basis for statistics makes life "interesting" for academic statisticians, but at the price of negative implications for the status of statistics in industry, science, and government. The practice of our discipline will mature only when we can come to a basic agreement about how to apply statistics to real problems. Simple and more general illustrations are given of the negative consequences of the existing schism between frequentists and Bayesians. An assessment of strengths and weaknesses of the frequentist and Bayes systems of inference suggests that calibrated Bayes-a compromise based on the works of Box, Rubin, and others-captures the strengths of both approaches and provides a roadmap for future advances. The approach asserts that inferences under a particular model should be Bayesian, but model assessment can and should involve frequentist ideas. This article also discusses some implications of this proposed compromise for the teaching and practice of statistics. {\textcopyright} 2006 American Statistical Association.},
author = {Little, Roderick J.},
doi = {10.1198/000313006X117837},
file = {::},
issn = {00031305},
journal = {American Statistician},
keywords = {Bayesian statistics,Frequentist statistics,Likelihood principle,Model checking,Statistical inference},
number = {3},
pages = {213--223},
title = {{Calibrated Bayes: A Bayes/frequentist roadmap}},
volume = {60},
year = {2006}
}
@article{Anonymous:R6X4eV5t,
month = {oct},
pages = {1--9},
title = {{The Second Century of Brigham Young University}},
year = {2015}
}
@article{Morrow:2011ix,
author = {Morrow, D A and Cook, N R},
journal = {Clinical chemistry},
month = {dec},
number = {1},
pages = {1--3},
title = {{Determining Decision Limits for New Biomarkers: Clinical and Statistical Considerations}},
volume = {57},
year = {2010}
}
@article{Haude:1996hp,
author = {Haude, Michael and Budde, Thomas and Hoepp, Hans W and Kerber, Sebastian and Caspari, Guido and Fa{\ss}bender, Guido and Fingerhuth, Maria and Erdmann, Erland and Breithardt, G{\"{u}}nter and Erbel, Raimund and Wischnewski, Manfred B},
journal = {Journal of the American College of Cardiology},
month = {feb},
number = {2},
pages = {8},
title = {{A prognostic computer model to predict individual outcome in interventional cardiology{\{}$\backslash$textemdash{\}}The INTERVENT project}},
volume = {27},
year = {1996}
}
@article{Kapelner2019,
abstract = {We present an optimized rerandomization design procedure for a non-sequential treatment-control experiment. Randomized experiments are the gold standard for finding causal effects in nature. But sometimes random assignments result in unequal partitions of the treatment and control group, visibly seen as imbalanced observed covariates, increasing estimator error. There is also imbalance on unobserved covariates which likewise increase estimator error. Rerandomization can throw away poor assignments only in the observed covariates by limiting the imbalance to a prespecified threshold. Limiting this threshold too much can increase the risk of having error due to unobserved covariates. We introduce a criterion that gauges errors due to both imbalance in the observed and the risk of imbalance in the unobserved covariates. We then use this criterion to locate the optimal rerandomization threshold based on the practitioner's level of desired insurance. We also provide an open source R package available on CRAN named OptimalRerandExpDesigns which generates designs according to our algorithm.},
archivePrefix = {arXiv},
arxivId = {1905.03337},
author = {Kapelner, Adam and Krieger, Abba M. and Sklar, Michael and Azriel, David},
eprint = {1905.03337},
pages = {1--27},
title = {{Optimal Rerandomization via a Criterion that Provides Insurance Against Failed Experiments}},
url = {http://arxiv.org/abs/1905.03337},
year = {2019}
}
@article{Villar2015,
abstract = {Multi-armed bandit problems (MABPs) are a special type of optimal control problem well suited to model resource allocation under uncertainty in a wide variety of contexts. Since the first publication of the optimal solution of the classic MABP by a dynamic index rule, the bandit literature quickly diversified and emerged as an active research topic. Across this literature, the use of bandit models to optimally design clinical trials became a typical motivating application, yet little of the resulting theory has ever been used in the actual design and analysis of clinical trials. To this end, we review two MABP decision-theoretic approaches to the optimal allocation of treatments in a clinical trial: the infinite-horizon Bayesian Bernoulli MABP and the finite-horizon variant. These models possess distinct theoretical properties and lead to separate allocation rules in a clinical trial design context. We evaluate their performance compared to other allocation rules, including fixed randomization. Our results indicate that bandit approaches offer significant advantages, in terms of assigning more patients to better treatments, and severe limitations, in terms of their resulting statistical power. We propose a novel bandit-based patient allocation rule that overcomes the issue of low power, thus removing a potential barrier for their use in practice.},
author = {Villar, Sof{\'{i}}a S. and Bowden, Jack and Wason, James},
doi = {10.1214/14-STS504},
file = {::},
issn = {08834237},
journal = {Statistical Science},
keywords = {Gittins index,Multi-armed bandit,Patient allocation,Response adaptive procedures,Whittle index},
number = {2},
pages = {199--215},
title = {{Multi-armed bandit models for the optimal design of clinical trials: Benefits and challenges}},
volume = {30},
year = {2015}
}
@article{whitehead2004double,
author = {Whitehead, John and Todd, Susan},
journal = {Pharmaceutical Statistics: The Journal of Applied Statistics in the Pharmaceutical Industry},
number = {1},
pages = {39--49},
publisher = {Wiley Online Library},
title = {{The double triangular test in practice}},
volume = {3},
year = {2004}
}
@article{Connor2013,
abstract = {Objective: We present a novel Bayesian adaptive comparative effectiveness trial comparing three treatments for status epilepticus that uses adaptive randomization with potential early stopping. Study Design and Setting: The trial will enroll 720 unique patients in emergency departments and uses a Bayesian adaptive design. Results: The trial design is compared to a trial without adaptive randomization and produces an efficient trial in which a higher proportion of patients are likely to be randomized to the most effective treatment arm while generally using fewer total patients and offers higher power than an analogous trial with fixed randomization when identifying a superior treatment. Conclusion: When one treatment is superior to the other two, the trial design provides better patient care, higher power, and a lower expected sample size. {\textcopyright} 2013 Elsevier Inc. All rights reserved.},
author = {Connor, Jason T. and Elm, Jordan J. and Broglio, Kristine R.},
doi = {10.1016/j.jclinepi.2013.02.015},
file = {::},
issn = {08954356},
journal = {Journal of Clinical Epidemiology},
keywords = {Adaptive sample size,Bayesian adaptive trials,Comparative effectiveness research,Emergency medicine,Response adaptive randomization,Status epilepticus},
number = {8 SUPPL.8},
pages = {S130--S137},
pmid = {23849147},
publisher = {Elsevier Inc},
title = {{Bayesian adaptive trials offer advantages in comparative effectiveness trials: An example in status epilepticus}},
url = {http://dx.doi.org/10.1016/j.jclinepi.2013.02.015},
volume = {66},
year = {2013}
}
@article{Senn:2004eg,
author = {Senn, Stephen},
journal = {Statistics in medicine},
month = {dec},
number = {24},
pages = {3729--3753},
title = {{Controversies concerning randomization and additivity in clinical trials}},
volume = {23},
year = {2004}
}
@article{Steyerberg:2014jx,
author = {Steyerberg, Ewout W and Vergouwe, Yvonne},
journal = {European heart journal},
month = {aug},
number = {29},
pages = {1925--1931},
title = {{Towards better clinical prediction models: seven steps for development and an ABCD for validation}},
volume = {35},
year = {2014}
}
@article{Vickers:2012jd,
author = {Vickers, Andrew J and Cronin, Angel M and Gonen, Mithat},
journal = {Statistics in medicine},
month = {sep},
number = {11},
pages = {1865--1876},
title = {{A simple decision analytic solution to the comparison of two binary diagnostic tests}},
volume = {32},
year = {2012}
}
@article{Harel:2009dd,
author = {Harel, Ofer},
journal = {Journal of Applied Statistics},
month = {sep},
number = {10},
pages = {1109--1118},
title = {{The estimation of R2and adjusted R2in incomplete data sets using multiple imputation}},
volume = {36},
year = {2009}
}
@article{Lin2012,
abstract = {Covariate adaptive allocation is often adopted in sequential clinical trials to maintain the balance of baseline covariates that could potentially confound the outcome of a trial. Several allocation methods exist in the literature that can handle both continuous and categorical covariates. We propose a minimization approach to maintaining the balance of multiple continuous and categorical covariates in sequential clinical trials, which uses the area between the empirical cumulative distribution functions of the observed covariate values as the imbalance metric. Numerical results based on extensive simulation studies and a real dataset show that the proposed approach produces more accurate estimates of the treatment effect and leads to more powerful trials than the existing approaches for trials with binary, continuous, and time-to-event outcomes. {\textcopyright} 2012 John Wiley {\&} Sons, Ltd.},
author = {Lin, Yunzhi and Su, Zheng},
doi = {10.1002/sim.5363},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Baseline covariates,Clinical trial,Cumulative distribution function,Imbalance,Minimization,Randomization},
number = {18},
pages = {1961--1971},
pmid = {22532082},
title = {{Balancing continuous and categorical baseline covariates in sequential clinical trials using the area between empirical cumulative distribution functions}},
volume = {31},
year = {2012}
}
@article{Korn:1991kj,
author = {Korn, Edward L and Simon, Richard},
journal = {The American statistician},
month = {aug},
number = {3},
pages = {201--206},
title = {{Explained Residual Variation, Explained Risk, and Goodness of Fit}},
volume = {45},
year = {1991}
}
@article{RN5,
author = {Willems, S J and Castells, M C and Baptist, A P},
doi = {10.1016/j.jaip.2022.01.032},
issn = {2213-2201 (Electronic) 2213-2198 (Print)},
journal = {J Allergy Clin Immunol Pract},
keywords = {*COVID-19/epidemiology Health Status Disparities H},
number = {4},
pages = {903--908},
title = {{The Magnification of Health Disparities During the COVID-19 Pandemic}},
type = {Journal Article},
url = {https://www.ncbi.nlm.nih.gov/pubmed/35131511},
volume = {10},
year = {2022}
}
@article{Jennison1990,
abstract = {Most medical trials are monitored for early evidence of treatment differences or harmful side effects. In this paper we review and critique various statistical approaches that have been proposed for the design and analysis of sequential experiments in medical applications. We discuss group sequential tests, stochastic curtailment, repeated confidence intervals, and Bayesian procedures. The role that a statistical stopping rule should play in the final analysis is examined. {\textcopyright} 1990, Institute of Mathematical Statistics. All Rights Reserved.},
author = {Jennison, Christopher and Turnbull, Bruce W.},
doi = {10.1214/ss/1177012099},
issn = {08834237},
journal = {Statistical Science},
keywords = {Bayesian inference,Group sequential test,Interim analyses,Repeated P-values,Repeated confidence intervals,Repeated significance test,Sequential design,Stochastic curtailment,Stopping rule},
number = {3},
pages = {299--317},
title = {{Statistical approaches to interim monitoring of medical trials: A review and commentary}},
volume = {5},
year = {1990}
}
@article{BarEven:2015kc,
author = {Bar-Even, Arren and Milo, Ron and Noor, Elad and Tawfik, Dan S},
journal = {Biochemistry},
month = {aug},
number = {32},
pages = {4969--4977},
title = {{The Moderately Efficient Enzyme: Futile Encounters and Enzyme Floppiness}},
volume = {54},
year = {2015}
}
@article{Zheng:2013hy,
author = {Zheng, Yingye and Parast, Layla and Cai, Tianxi and Brown, Marshall},
journal = {Lifetime Data Analysis},
month = {dec},
number = {3},
pages = {350--370},
title = {{Evaluating incremental values from new predictors with net reclassification improvement in survival analysis}},
volume = {19},
year = {2012}
}
@article{Nelson:2009fs,
author = {Nelson, Harold S and Busse, William W and Sanger, Mary and Cutler, Gordon and Ellwanger, Colleen and Chipman, John J},
journal = {Allergy and Asthma Proceedings},
month = {may},
number = {3},
pages = {325--332},
title = {{Short-term safety of somatropin inhalation powder in adults with mild to moderate asthma}},
volume = {30},
year = {2009}
}
@article{Zhang2007,
author = {Zhang, Li-Xin and Hu, Feifang and Cheung, Siu Hung and Chan, Wai Sum},
title = {{Asymptotic properties of covariate-adjusted response-adaptive designs}},
year = {2007}
}
@article{Vickers:2008gu,
author = {Vickers, Andrew J and Jang, Kwang and Sargent, Daniel and Lilja, Hans and Kattan, Michael W},
journal = {Cancer},
number = {8},
pages = {1862--1868},
title = {{Systematic review of statistical methods used in molecular marker studies in cancer}},
volume = {112},
year = {2008}
}
@article{Vickers:2015et,
author = {Vickers, Andrew J and Sjoberg, Daniel D},
journal = {European urology},
month = {feb},
number = {2},
pages = {181--187},
title = {{Guidelines for Reporting of Statistics in European Urology}},
volume = {67},
year = {2015}
}
@book{LectsBioregSan:uPdXig0N,
address = {Cambridge},
author = {Sanders, Robert H},
publisher = {Cambridge University Press},
title = {{Deconstructing Cosmology}},
year = {2016}
}
@article{Rubin2015,
author = {Rubin, D B},
file = {::},
keywords = {1,categorical data,causal effects,incomplete data,introduction and notation,logistic models,non-randomized studies,subclassification},
number = {2},
pages = {212--218},
title = {{Assessing Sensitivity to an Unobserved Covariate Binary in an Observational Study with Binary Outcome}},
volume = {45},
year = {2015}
}
@article{Thompson2018,
abstract = {In stepped-wedge trials (SWTs), the intervention is rolled out in a random order over more than 1 time-period. SWTs are often analysed using mixed-effects models that require strong assumptions and may be inappropriate when the number of clusters is small. We propose a non-parametric within-period method to analyse SWTs. This method estimates the intervention effect by comparing intervention and control conditions in a given period using cluster-level data corresponding to exposure. The within-period intervention effects are combined with an inverse-variance-weighted average, and permutation tests are used. We present an example and, using simulated data, compared the method to (1) a parametric cluster-level within-period method, (2) the most commonly used mixed-effects model, and (3) a more flexible mixed-effects model. We simulated scenarios where period effects were common to all clusters, and when they varied according to a distribution informed by routinely collected health data. The non-parametric within-period method provided unbiased intervention effect estimates with correct confidence-interval coverage for all scenarios. The parametric within-period method produced confidence intervals with low coverage for most scenarios. The mixed-effects models' confidence intervals had low coverage when period effects varied between clusters but had greater power than the non-parametric within-period method when period effects were common to all clusters. The non-parametric within-period method is a robust method for analysing SWT. The method could be used by trial statisticians who want to emphasise that the SWT is a randomised trial, in the common position of being uncertain about whether data will meet the assumptions necessary for mixed-effect models.},
author = {Thompson, J. A. and Davey, C. and Fielding, K. and Hargreaves, J. R. and Hayes, R. J.},
doi = {10.1002/sim.7668},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {cluster randomised trial,confidence interval coverage,permutation test,simulation study,stepped wedge trial},
number = {16},
pages = {2487--2500},
pmid = {29635789},
title = {{Robust analysis of stepped wedge trials using cluster-level summaries within periods}},
volume = {37},
year = {2018}
}
@article{Strug:2012dj,
author = {Strug, Lisa J and Rohde, Charles A and Corey, Paul N},
journal = {The American statistician},
month = {aug},
number = {3},
pages = {207--212},
title = {{An Introduction to Evidential Sample Size Calculations}},
volume = {61},
year = {2007}
}
@article{Robins:2000wv,
author = {Robins, James M and Hern{\'{a}}n, Miguel {\'{A}}ngel and Brumback, Babette},
journal = {Epidemiology},
month = {sep},
number = {5},
pages = {550},
title = {{Marginal Structural Models and Causal Inference in Epidemiology}},
volume = {11},
year = {2000}
}
@article{Jiang2007,
abstract = {Background: Many molecularly targeted anticancer agents entering the definitive stage of clinical development benefit only a subset of treated patients. This may lead to missing effective agents by the traditional broad-eligibility randomized trials due to the dilution of the overall treatment effect. We propose a statistically rigorous biomarker-adaptive threshold phase III design for settings in which a putative biomarker to identify patients who are sensitive to the new agent is measured on a continuous or graded scale. Methods: The design combines a test for overall treatment effect in all randomly assigned patients with the establishment and validation of a cut point for a prespecified biomarker of the sensitive subpopulation. The performance of the biomarker-adaptive design, relative to a traditional design that ignores the biomarker, was evaluated in a simulation study. The biomarker-adaptive design was also used to analyze data from a prostate cancer trial. Results: In the simulation study, the biomarker-adaptive design preserved the power to detect the overall effect when the new treatment is broadly effective. When the proportion of sensitive patients as identified by the biomarker is low, the proposed design provided a substantial improvement in efficiency compared with the traditional trial design. Recommendations for sample size planning and implementation of the biomarker-adaptive design are provided. Conclusions: A statistically valid test for a biomarker-defined subset effect can be prospectively incorporated into a randomized phase III design without compromising the ability to detect an overall effect if the intervention is beneficial in a broad population. {\textcopyright} The Author 2007. Published by Oxford University Press.},
author = {Jiang, Wenyu and Freidlin, Boris and Simon, Richard},
doi = {10.1093/jnci/djm022},
file = {::},
issn = {00278874},
journal = {Journal of the National Cancer Institute},
number = {13},
pages = {1036--1043},
pmid = {17596577},
title = {{Biomarker-adaptive threshold design: A procedure for evaluating treatment with possible biomarker-defined subset effect}},
volume = {99},
year = {2007}
}
@article{Kamarudin:2017kz,
author = {Kamarudin, Adina Najwa and Cox, Trevor and Kolamunnage-Dona, Ruwanthi},
journal = {BMC Medical Research Methodology},
month = {apr},
number = {1},
pages = {53},
title = {{Time-dependent ROC curve analysis in medical research: current methods and applications.}},
volume = {17},
year = {2017}
}
@article{Min2019,
abstract = {AIM: To evaluate whether recent low adherence to metformin monotherapy is associated with hypoglycaemia after addition of a sulfonylurea. METHODS: We assembled a retrospective cohort of veterans who filled a new prescription for metformin between 2001 and 2011 and intensified treatment with a sulfonylurea after {\textgreater}/=1 year of metformin use. We calculated metformin adherence from pharmacy data using the proportion of days covered in the 180-day period before intensification. The primary outcome was hypoglycaemia, defined as a hospitalization or emergency department visit for hypoglycaemia or an outpatient blood glucose measurement {\textless}3.3 mmol/l in the year following intensification. Cox proportional hazards models were used to compare the risk of hypoglycaemia between participants with low ({\textless}80{\%}) and high ({\textgreater}/=80{\%}) adherence. Adherence was also modelled as a continuous variable using restricted cubic splines. RESULTS: Of 187 267 participants who initiated metformin monotherapy, 49 424 added a sulfonylurea after {\textgreater}/=1 year. The median (interquartile range) rate of treatment adherence was 87 (50-100){\%} and 43{\%} had adherence {\textless}80{\%}. Hypoglycaemia rates per 1000 person-years were 23.1 (95{\%} CI 21.1-25.4) and 24.5 (95{\%} CI 22.7-26.4) in participants with low and high adherence, respectively (adjusted hazard ratio 0.95, 95{\%} CI 0.84-1.08). The risk of hypoglycaemia was similar across all levels of adherence when adherence was modelled as a continuous variable. CONCLUSIONS: We found no evidence that past low adherence to metformin monotherapy was associated with hypoglycaemia after intensification with a sulfonylurea.},
author = {Min, J Y and Griffin, M R and Chipman, J and Hackstadt, A J and Greevy, R A and Grijalva, C G and Hung, A M and Roumie, C L},
doi = {10.1111/dme.13853},
issn = {1464-5491 (Electronic)},
journal = {Diabetic medicine : a journal of the British Diabetic Association},
language = {eng},
month = {apr},
number = {4},
pages = {482--490},
pmid = {30378161},
title = {{Recent metformin adherence and the risk of hypoglycaemia in the year following intensification with a sulfonylurea.}},
volume = {36},
year = {2019}
}
@article{RN9,
author = {Vodopivec‐Jamsek, Vlasta and de Jongh, Thyra and Gurol‐Urganci, Ipek and Atun, Rifat and Car, Josip},
issn = {1465-1858},
journal = {The Cochrane Library},
title = {{Mobile phone messaging for preventive health care}},
type = {Journal Article},
year = {2012}
}
@article{insight2015initiation,
author = {Group, Insight Start Study},
file = {::},
journal = {New England Journal of Medicine},
number = {9},
pages = {795--807},
publisher = {Mass Medical Soc},
title = {{Initiation of antiretroviral therapy in early asymptomatic HIV infection}},
volume = {373},
year = {2015}
}
@article{Pajewski:2016fm,
author = {Pajewski, Nicholas M and Williamson, Jeff D and Applegate, William B and Berlowitz, Dan R and Bolin, Linda P and Chertow, Glenn M and Krousel-Wood, Marie A and Lopez-Barrera, Nieves and Powell, James R and Roumie, Christianne L and Still, Carolyn and Sink, Kaycee M and Tang, Rocky and Wright, Clinton B and Supiano, Mark A and {for the SPRINT Study Research Group}},
journal = {The Journals of Gerontology Series A: Biological Sciences and Medical Sciences},
month = {apr},
number = {5},
pages = {649--655},
title = {{Characterizing Frailty Status in the Systolic Blood Pressure Intervention Trial}},
volume = {71},
year = {2016}
}
@article{Spitzer2017,
author = {Spitzer, Robert J},
issn = {0023-9186},
journal = {Law and contemporary problems},
keywords = {Gun control},
language = {eng},
number = {2},
pages = {55--83},
publisher = {Duke University, School of Law},
title = {{Gun law history in the United States and second amendment rights}},
volume = {80},
year = {2017}
}
@article{Grambsch:1991fo,
author = {Grambsch, Patricia M and O'Brien, Peter C},
journal = {Statistics in medicine},
month = {may},
number = {5},
pages = {697--709},
title = {{The effects of transformations and preliminary tests for non-linearity in regression}},
volume = {10},
year = {1991}
}
@book{Gonzalez:2016hx,
address = {Chichester, UK},
author = {Gonzalez, Ruben and Qi, Fei and Huang, Biao},
month = {sep},
publisher = {John Wiley {\&} Sons, Ltd},
series = {A Bayesian Approach},
title = {{Process Control System Fault Diagnosis: A Bayesian Approach}},
year = {2016}
}
@book{rubin2004multiple,
author = {Rubin, Donald B},
publisher = {John Wiley $\backslash${\&} Sons},
title = {{Multiple imputation for nonresponse in surveys}},
volume = {81},
year = {2004}
}
@article{Hall:2007fi,
author = {Hall, Nancy S},
journal = {Journal of the History of Biology},
number = {2},
pages = {295--325},
title = {{R. A. Fisher and his advocacy of randomization}},
volume = {40},
year = {2007}
}
@article{Zhou2008,
abstract = {Background: With the advancement in biomedicine, many biologically targeted therapies have been developed. These targeted agents, however, may not work for everyone. Biomarker profiles can be used to identify effective targeted therapies. Our goals are to characterize the molecular signature of individual tumors, offer the best-fit targeted therapies to patients in a study, and identify promising agents for future development. Methods: We propose an outcome-based adaptive randomization trial design for patients with advanced stage non-small cell lung cancer. All patients have baseline biopsy samples taken for biomarker assessment prior to randomization to treatments. The primary endpoint of this study is the disease control rate at 8 weeks after randomization. The Bayesian probit model is used to characterize the disease control rate. Patients are adaptively randomized to one of four treatments with the randomization rate based on the updated disease control rate from the accumulated data in the trial. For each biomarker profile, high-performing treatments have higher randomization rates, and vice versa. An early stopping rule is implemented to suspend low-performing treatments from randomization. Results: Based on extensive simulation studies, with a total of 200 evaluable patients, our trial has desirable operating characteristics to: (1) identify effective agents with a high probability; (2) suspend ineffective agents; and (3) treat more patients with effective agents that correspond to their biomarker profiles. Our trial design continues to update and refine the estimates as the trial progresses. Limitations: This biomarker-based trial requires biopsible tumors and a two-week turn around time for biomarker profiling before randomization. Additionally, in order to learn from the interim data and adjust the randomization rate accordingly, the outcome-based adaptive randomization design is applicable only for trials when the endpoint can be assessed in a relative short period of time. Conclusion: Bayesian adaptive randomization trial design is a smart, novel, and ethical design. In conjunction with an early stopping rule, it can be used to efficiently identify effective agents, eliminate ineffective ones, and match effective treatments with patients' biomarker profiles. The proposed design is suitable for the development of targeted therapies and provides a rational design for personalized medicine. {\textcopyright} 2008 SAGE Publications.},
author = {Zhou, Xian and Liu, Suyu and Kim, Edward S. and Herbst, Roy S. and Lee, J. Jack J.},
doi = {10.1177/1740774508091815},
issn = {17407745},
journal = {Clinical Trials},
number = {3},
pages = {181--193},
pmid = {18559407},
title = {{Bayesian adaptive design for targeted therapy development in lung cancer - A step toward personalized medicine}},
volume = {5},
year = {2008}
}
@article{Kass:2012vb,
author = {Kass, Robert E and Raftery, Adrian E},
journal = {Journal of the American Statistical Association},
month = {jun},
number = {430},
pages = {773--795},
title = {{Bayes Factors}},
volume = {90},
year = {1995}
}
@article{Benjamin:2017gh,
author = {Benjamin, Daniel J and Berger, James O and Johannesson, Magnus and Nosek, Brian A and Wagenmakers, E-J J and Berk, Richard and Bollen, Kenneth A and x000F6 rn Brembs, Bj{\"{o}}rn Bjamp and Brown, Lawrence and Camerer, Colin and Others and Cesarini, David and Chambers, Christopher D and Clyde, Merlise and Cook, Thomas D and {De Boeck}, Paul and Dienes, Zoltan and Dreber, Anna and Easwaran, Kenny and Efferson, Charles and Fehr, Ernst and Fidler, Fiona and Field, Andy P and Forster, Malcolm and George, Edward I and Gonzalez, Richard and Goodman, Steven and Green, Edwin and Green, Donald P and Greenwald, Anthony G and Hadfield, Jarrod D and Hedges, Larry V and Held, Leonhard and Ho, Teck Hua and Hoijtink, Herbert and Hruschka, Daniel J and Imai, Kosuke and Imbens, Guido and Ioannidis, John P A and Jeon, Minjeong and Jones, James Holland and Kirchler, Michael and Laibson, David and List, John and Little, Roderick and Lupia, Arthur and Machery, Edouard and Maxwell, Scott E and McCarthy, Michael and Moore, Don A and Morgan, Stephen L and X000F3, Marcus Munafamp and Nakagawa, Shinichi and Nyhan, Brendan and Parker, Timothy H and Pericchi, Luis and Perugini, Marco and Rouder, Jeff and Rousseau, Judith and Savalei, Victoria and x000F6 Nbrodt, Felix D Schamp and Sellke, Thomas and Sinclair, Betsy and Tingley, Dustin and {Van Zandt}, Trisha and Vazire, Simine and Watts, Duncan J and Winship, Christopher and Wolpert, Robert L and Xie, Yu and Young, Cristobal and Zinman, Jonathan and Johnson, Valen E},
journal = {Nature Human Behaviour},
month = {aug},
number = {1},
pages = {6},
publisher = {Nature Publishing Group},
title = {{Redefine statistical significance}},
volume = {2},
year = {2018}
}
@article{mehta2011adaptive,
author = {Mehta, Cyrus R and Pocock, Stuart J},
journal = {Statistics in medicine},
number = {28},
pages = {3267--3284},
publisher = {Wiley Online Library},
title = {{Adaptive increase in sample size when interim results are promising: a practical guide with examples}},
volume = {30},
year = {2011}
}
@article{Pencina:2007kj,
author = {Pencina, Michael J and {D' Agostino}, Ralph B and Vasan, Ramachandran S},
journal = {Statistics in medicine},
number = {2},
pages = {157--172},
title = {{Evaluating the added predictive ability of a new marker: From area under the ROC curve to reclassification and beyond}},
volume = {27},
year = {2007}
}
@article{RN7,
author = {Gillespie, D L and Meyers, L A and Lachmann, M and Redd, S C and Zenilman, J M},
doi = {10.1111/josh.13008},
issn = {0022-4391 (Print) 0022-4391},
journal = {J Sch Health},
keywords = {Adolescent COVID-19/*diagnosis/*prevention {\&} contr,U.S. Child Communicable Disease Control/*methods/},
number = {5},
pages = {347--355},
title = {{The Experience of 2 Independent Schools With In-Person Learning During the COVID-19 Pandemic}},
type = {Journal Article},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8251146/pdf/JOSH-91-347.pdf},
volume = {91},
year = {2021}
}
@article{Vickers:2010ei,
author = {Vickers, Andrew},
journal = {European urology},
month = {apr},
number = {4},
pages = {571--573},
title = {{Prediction Models in Urology: Are They Any Good, and How Would We Know Anyway?}},
volume = {57},
year = {2010}
}
@article{Biswas:2012cw,
author = {Biswas, Swati and Tankhiwale, Neelam and Blackford, Amanda and Barrera, Angelica M Gutierrez and Ready, Kaylene and Lu, Karen and Amos, Christopher I and Parmigiani, Giovanni and Arun, Banu},
journal = {Breast Cancer Research and Treatment},
month = {jan},
number = {1},
pages = {347--355},
title = {{Assessing the added value of breast tumor markers in genetic risk prediction model BRCAPRO}},
volume = {133},
year = {2012}
}
@book{Robert:2012wb,
author = {Suissa, Samy Salomon},
publisher = {[s.n.]},
title = {{Exact unconditional tests for 2x2 contingency tables / by Samy Salomon Suissa.}}
}
@article{Whitehead2011,
abstract = {The methodology of group sequential trials is now well established and widely implemented. The benefits of the group sequential approach are generally acknowledged, and its use, when applied properly, is accepted by researchers and regulators. This article describes how a wide range of group sequential designs can easily be implemented using two accessible SAS functions. One of these, PROBBNRM is a standard function, while the other, SEQ, is part of the interactive matrix language of SAS, PROC IML. The account focuses on the essentials of the approach and reveals how straightforward it can be. The design of studies is described, including their evaluation in terms of the distribution of final sample size. The conduct of the interim analyses is discussed, with emphasis on the consequences of inevitable departures from the planned schedule of information accrual. The computations required for the final analysis, allowing for the sequential design, are closely related to those conducted at the design stage. Illustrative examples are given and listings of suitable of SAS code are provided. {\textcopyright} 2011 The Author(s).},
annote = {Revisit for removing bias from sequential monitoring},
author = {Whitehead, John},
doi = {10.1177/0962280210379036},
file = {::},
issn = {14770334},
journal = {Statistical Methods in Medical Research},
keywords = {SAS,adaptive designs,clinical trials,group sequential trials,sequential analysis,two-stage trials},
number = {6},
pages = {635--656},
pmid = {20876163},
title = {{Group sequential trials revisited: Simple implementation using SAS}},
volume = {20},
year = {2011}
}
@article{Steyerberg:2008cp,
author = {Steyerberg, E W and Vickers, A J},
journal = {Medical Decision Making},
month = {jul},
number = {1},
pages = {146--149},
title = {{Decision Curve Analysis: A Discussion}},
volume = {28},
year = {2007}
}
@article{Greenland:2008kn,
author = {Pepe, M S and Feng, Z and Gu, J W and Chi, Yueh-Yun and Zhou, Xiao-Hua and Greenland, Sander and Cook, Nancy R and Ware, J H and Cai, T and Chi, Yueh-Yun and Zhou, Xiao-Hua and Ware, J H and Cai, T and Greenland, Philip and Cook, Nancy R and Pepe, M S and Feng, Z and Gu, J W},
journal = {Statistics in medicine},
number = {2},
pages = {188--190},
title = {{Comments on {\{}$\backslash$textquoteleft{\}}Evaluating the added predictive ability of a new marker: From area under the ROC curve to reclassification and beyond{\{}$\backslash$textquoteright{\}} by M. J. Pencinaet al.,Statistics in Medicine (DOI: 10.1002/sim.2929)}},
volume = {27},
year = {2007}
}
@article{Walter:2017ga,
author = {Walter, S D and Han, H and Briel, M and Guyatt, G H},
journal = {Statistics in medicine},
month = {apr},
number = {9},
pages = {1506--1518},
title = {{Quantifying the bias in the estimated treatment effect in randomized trials having interim analyses and a rule for early stopping for futility.}},
volume = {36},
year = {2017}
}
@article{Blume:2008cw,
author = {Blume, Jeffrey D},
journal = {Communications in Statistics - Theory and Methods},
month = {feb},
number = {8},
pages = {1193--1206},
title = {{How Often Likelihood Ratios are Misleading in Sequential Trials}},
volume = {37},
year = {2008}
}
@incollection{Andrew:2013un,
address = {Hoboken, NJ, USA},
author = {Bolstad, William M and Curran, James M},
booktitle = {Introduction to Bayesian Statistics, Third Edition},
month = {sep},
pages = {31--57},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Displaying and Summarizing Data}},
year = {2016}
}
@article{BaldiAntognini:2011jk,
author = {{Baldi Antognini}, A and Zagoraiou, M},
journal = {Biometrika},
month = {aug},
number = {3},
pages = {519--535},
title = {{The covariate-adaptive biased coin design for balancing clinical trials in the presence of prognostic factors}},
volume = {98},
year = {2011}
}
@article{Pearl2009,
abstract = {This review presents empirical researcherswith recent advances in causal inference, and stresses the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that underly all causal inferences, the languages used in formulating those assumptions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and unifies other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: (1) queries about the effects of potential interventions, (also called "causal effects" or "policy evaluation") (2) queries about probabilities of counterfactuals, (including assessment of "regret," "attribution" or "causes of effects") and (3) queries about direct and indirect effects (also known as "mediation"). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both.},
author = {Pearl, Judea},
doi = {10.1214/09-SS057},
issn = {19357516},
journal = {Statistics Surveys},
keywords = {Causal effects,Causes of effects,Confounding,Counterfactuals,Graphical methods,Mediation,Policy evaluation,Potential-outcome,Structural equationmodels},
number = {September},
pages = {96--146},
title = {{Causal inference in statistics: An overview}},
volume = {3},
year = {2009}
}
@article{Katki:2007fs,
author = {Katki, Hormuzd A},
journal = {BMC Medical Genetics},
month = {mar},
number = {1},
pages = {126},
title = {{Incorporating medical interventions into carrier probability estimation for genetic counseling}},
volume = {8},
year = {2007}
}
@article{hulsen2019big,
abstract = {For over a decade the term "Big data" has been used to describe the rapid increase in volume, variety and velocity of information available, not just in medical research but in almost every aspect of our lives. As scientists, we now have the capacity to rapidly generate, store and analyse data that, only a few years ago, would have taken many years to compile. However, "Big data" no longer means what it once did. The term has expanded and now refers not to just large data volume, but to our increasing ability to analyse and interpret those data. Tautologies such as "data analytics" and "data science" have emerged to describe approaches to the volume of available information as it grows ever larger. New methods dedicated to improving data collection, storage, cleaning, processing and interpretation continue to be developed, although not always by, or for, medical researchers. Exploiting new tools to extract meaning from large volume information has the potential to drive real change in clinical practice, from personalized therapy and intelligent drug design to population screening and electronic health record mining. As ever, where new technology promises "Big Advances," significant challenges remain. Here we discuss both the opportunities and challenges posed to biomedical research by our increasing ability to tackle large datasets. Important challenges include the need for standardization of data content, format, and clinical definitions, a heightened need for collaborative networks with sharing of both data and expertise and, perhaps most importantly, a need to reconsider how and when analytic methodology is taught to medical researchers. We also set "Big data" analytics in context: recent advances may appear to promise a revolution, sweeping away conventional approaches to medical science. However, their real promise lies in their synergy with, not replacement of, classical hypothesis-driven methods. The generation of novel, data-driven hypotheses based on interpretable models will always require stringent validation and experimental testing. Thus, hypothesis-generating research founded on large datasets adds to, rather than replaces, traditional hypothesis driven science. Each can benefit from the other and it is through using both that we can improve clinical practice.},
author = {Hulsen, Tim and Jamuar, Saumya S. and Moody, Alan R. and Karnes, Jason H. and Varga, Orsolya and Hedensted, Stine and Spreafico, Roberto and Hafler, David A. and McKinney, Eoin F.},
doi = {10.3389/fmed.2019.00034},
file = {::},
issn = {2296858X},
journal = {Frontiers in Medicine},
keywords = {Big data,Big data analytics,Data science,Precision medicine,Translational medicine},
number = {MAR},
pages = {1--14},
pmid = {30881956},
title = {{From big data to precision medicine}},
volume = {6},
year = {2019}
}
@article{Wang:2016ff,
author = {Wang, Hao and Rosner, Gary L and Goodman, Steven N},
journal = {Clinical trials (London, England)},
month = {dec},
number = {6},
pages = {621--631},
title = {{Quantifying over-estimation in early stopped clinical trials and the "freezing effect" on subsequent research.}},
volume = {13},
year = {2016}
}
@article{Shmueli:2010ec,
author = {Shmueli, Galit},
journal = {Statistical Science},
month = {aug},
number = {3},
pages = {289--310},
title = {{To Explain or to Predict?}},
volume = {25},
year = {2010}
}
@book{Steyerberg:2009de,
address = {New York, NY},
author = {Steyerberg, E W},
publisher = {Springer New York},
series = {Statistics for Biology and Health},
title = {{Clinical Prediction Models}},
year = {2009}
}
@article{Williamson2022,
abstract = {The design of sequential experiments and, in particular, randomised controlled trials involves a trade-off between operational characteristics such as statistical power, estimation bias and patient benefit. The family of randomisation procedures referred to as Constrained Randomised Dynamic Programming (CRDP), which is set in the Bayesian decision-theoretic framework, can be used to balance these competing objectives. A generalisation and novel interpretation of CRDP is proposed to highlight its inherent flexibility to adapt to a variety of practicalities and align with individual trial objectives. CRDP, as with most response-adaptive randomisation procedures, hinges on the limiting assumption of patient responses being available before allocation of the next patient. This forms one of the greatest barriers to their implementation in practice which, despite being an important research question, has not received a thorough treatment. Therefore, motivated by the existing gap between the theory of response-adaptive randomisation (which is abundant with proposed methods in the immediate response setting) and clinical practice (in which responses are typically delayed), the performance of CRDP in the presence of fixed and random delays is evaluated. Simulation results show that CRDP continues to offer patient benefit gains over alternative procedures and is relatively robust to delayed responses. To compensate for a fixed delay, a method which adjusts the time horizon used in the optimisation objective is proposed and its performance illustrated.},
author = {Williamson, S. Faye and Jacko, Peter and Jaki, Thomas},
doi = {10.1016/j.csda.2021.107407},
file = {::},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Bayesian decision-theoretic model,Clinical trials,Delayed responses,Dynamic programming,Response-adaptive randomisation},
pages = {107407},
publisher = {Elsevier B.V.},
title = {{Generalisations of a Bayesian decision-theoretic randomisation procedure and the impact of delayed responses}},
url = {https://doi.org/10.1016/j.csda.2021.107407},
volume = {174},
year = {2022}
}
@article{balzer2015adaptive,
author = {Balzer, Laura B and Petersen, Maya L and van der Laan, Mark J and Consortium, SEARCH},
journal = {Statistics in medicine},
number = {6},
pages = {999--1011},
publisher = {Wiley Online Library},
title = {{Adaptive pair-matching in randomized trials with unbiased and efficient effect estimation}},
volume = {34},
year = {2015}
}
@article{Anonymous:tlRH3kUg,
month = {jan},
pages = {1--167},
title = {{ABSTRACT CAUSAL INFERENCE WITH A CONTINUOUS TREATMENT AND OUTCOME: ALTERNATIVE ESTIMATORS FOR PARAMETRIC DOSE-RESPONSE FUNCTIONS WITH APPLICATIONS Douglas Galagate, Doctor of Philosophy, 2016 Dr. Joseph L. Schafer Office of the Associate Director for Rese}},
year = {2016}
}
@article{Wald:1945kd,
author = {Wald, A},
journal = {The Annals of Mathematical Statistics},
month = {jun},
number = {2},
pages = {117--186},
title = {{Sequential Tests of Statistical Hypotheses}},
volume = {16},
year = {1945}
}
@article{Mihaescu:2010fb,
author = {Mihaescu, R and van Zitteren, M and van Hoek, M and Sijbrands, E J G and Uitterlinden, A G and Witteman, J C M and Hofman, A and Hunink, M G M and van Duijn, C M and Janssens, A C J W},
journal = {American Journal of Epidemiology},
month = {jul},
number = {3},
pages = {353--361},
title = {{Improvement of Risk Prediction by Genomic Profiling: Reclassification Measures Versus the Area Under the Receiver Operating Characteristic Curve}},
volume = {172},
year = {2010}
}
@article{Swami2020,
abstract = {Presence of tumor mutation in speckle-type pox virus and zinc finger protein (SPOP) gene was associated with improved survival outcomes in men with de novo metastatic castration-sensitive prostate cancer receiving standard androgen deprivation therapy.},
author = {Swami, Umang and {Isaacsson Velho}, Pedro and Nussenzveig, Roberto and Chipman, Jonathan and {Sacristan Santos}, Victor and Erickson, Stephanie and Dharmaraj, Divya and Alva, Ajjai Shivaram and Vaishampayan, Ulka N. and Esther, John and Hahn, Andrew W. and Maughan, Benjamin Louis and Antonarakis, Emmanuel S. and Agarwal, Neeraj},
doi = {10.1016/j.eururo.2020.06.033},
file = {::},
issn = {18737560},
journal = {European Urology},
keywords = {Androgen deprivation therapy,Metastatic hormone-sensitive prostate cancer,Overall survival,Progression-free survival,SPOP},
number = {5},
pages = {652--656},
pmid = {32624276},
publisher = {European Association of Urology},
title = {{Association of SPOP Mutations with Outcomes in Men with De Novo Metastatic Castration-sensitive Prostate Cancer}},
url = {https://doi.org/10.1016/j.eururo.2020.06.033},
volume = {78},
year = {2020}
}
@article{xiong1995class,
author = {Xiong, Xiaoping},
journal = {Journal of the American Statistical Association},
month = {dec},
number = {432},
pages = {1463--1473},
title = {{A Class of Sequential Conditional Probability Ratio Tests}},
volume = {90},
year = {1995}
}
@article{sorlie2001gene,
abstract = {The purpose of this study was to classify breast carcinomas based on variations in gene expression patterns derived from cDNA microarrays and to correlate tumor characteristics to clinical outcome. A total of 85 cDNA microarray experiments representing 78 cancers, three fibroadenomas, and four normal breast tissues were analyzed by hierarchical clustering. As reported previously, the cancers could be classified into a basal epithelial-like group, an ERBB2-overexpressing group and a normal breast-like group based on variations in gene expression. A novel finding was that the previously characterized luminal epithelial/estrogen receptor-positive group could be divided into at least two subgroups, each with a distinctive expression profile. These subtypes proved to be reasonably robust by clustering using two different gene sets: first, a set of 456 cDNA clones previously selected to reflect intrinsic properties of the tumors and, second, a gene set that highly correlated with patient outcome. Survival analyses on a subcohort of patients with locally advanced breast cancer uniformly treated in a prospective study showed significantly different outcomes for the patients belonging to the various groups, including a poor prognosis for the basal-like subtype and a significant difference in outcome for the two estrogen receptor-positive groups.},
author = {S{\o}rlie, Therese and Perou, Charles M. and Tibshirani, Robert and Aas, Turid and Geisler, Stephanie and Johnsen, Hilde and Hastie, Trevor and Eisen, Michael B. and {Van De Rijn}, Matt and Jeffrey, Stefanie S. and Thorsen, Thor and Quist, Hanne and Matese, John C. and Brown, Patrick O. and Botstein, David and L{\o}nning, Per Eystein and B{\o}rresen-Dale, Anne Lise},
doi = {10.1073/pnas.191367098},
file = {::},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {19},
pages = {10869--10874},
pmid = {11553815},
title = {{Gene expression patterns of breast carcinomas distinguish tumor subclasses with clinical implications}},
volume = {98},
year = {2001}
}
@article{Cook:2007hp,
author = {Cook, N R},
journal = {Circulation},
month = {feb},
number = {7},
pages = {928--935},
title = {{Use and Misuse of the Receiver Operating Characteristic Curve in Risk Prediction}},
volume = {115},
year = {2007}
}
@article{Zhang:2009dg,
author = {Zhang, Zhiwei},
journal = {Biometrical Journal},
month = {aug},
number = {4},
pages = {710--720},
title = {{Interpreting Statistical Evidence with Empirical Likelihood Functions}},
volume = {51},
year = {2009}
}
@article{Berger:2003im,
author = {Berger, Vance W and Ivanova, Anastasia and {Deloria Knoll}, Maria},
journal = {Statistics in medicine},
number = {19},
pages = {3017--3028},
title = {{Minimizing predictability while retaining balance through the use of less restrictive randomization procedures}},
volume = {22},
year = {2003}
}
@article{Chi:2008dq,
author = {Chi, Yueh-Yun and Zhou, Xiao-Hua},
journal = {Statistics in medicine},
number = {2},
pages = {182--184},
title = {{The need for reorientation toward cost-effective prediction: Comments on {\{}$\backslash$textquoteleft{\}}Evaluating the added predictive ability of a new marker: From area under the ROC curve to reclassification and beyond{\{}$\backslash$textquoteright{\}} by Pencinaet al.,Statistics in }},
volume = {27},
year = {2007}
}
@article{Clark:2001ef,
author = {Clark, T G and Stewart, M E and Altman, D G and Gabra, H and Smyth, J F},
journal = {British Journal of Cancer},
month = {oct},
number = {7},
pages = {944--952},
title = {{A prognostic model for ovarian cancer}},
volume = {85},
year = {2001}
}
@article{Spiegelhalter1994,
abstract = {We consider the problem of critiquing prior beliefs concerning the distribution of a discrete random variable in the light of a sequentially obtained sample. A topical application concerns a probabilistic expert system for the diagnosis of congenital heart disease, which requires specification of a large number of conditional probabilities that are initially imprecisely estimated by a suitable “expert.” These prior beliefs may be formally updated as data become available, but it would seem essential to contrast the original expert assessments with the data obtained to quickly identify inappropriate subjective inputs. We consider both Bayes factor and significance testing techniques for such a prior/data comparison, both in nonsequential and sequential forms. The common basis as alternative standardizations of the logarithm of the predictive ordinate of the observed data is emphasised, and a Bayesian discrepancy statistic with a variety of interpretations provides a formal means of discounting the expert's judgments in the light of the data. The judgments are found to be of generally high quality, and procedures for automatic monitoring and adaptation are recommended. {\textcopyright} 1994 Taylor {\&} Francis Group, LLC.},
author = {Spiegelhalter, David J. and Harris, Nomi L. and Bull, Kate and Franklin, Rodney C.G.},
doi = {10.1080/01621459.1994.10476765},
file = {::},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Bayes factor,Dirichlet distribution,Expert system,Prequential assessment,Scoring rule,Subjective probabilities},
number = {426},
pages = {435--443},
title = {{Empirical evaluation of prior beliefs about frequencies: Methodology and a case study in congenital heart disease}},
volume = {89},
year = {1994}
}
@article{Zhao2014,
abstract = {Stratified permuted block randomization has been the dominant covariate-adaptive randomization procedure in clinical trials for several decades. Its high probability of deterministic assignment and low capacity of covariate balancing have been well recognized. The popularity of this sub-optimal method is largely due to its simplicity in implementation and the lack of better alternatives. Proposed in this paper is a two-stage covariate-adaptive randomization procedure that uses the block urn design or the big stick design in stage one to restrict the treatment imbalance within each covariate stratum, and uses the biased-coin minimization method in stage two to control imbalances in the distribution of additional covariates that are not included in the stratification algorithm. Analytical and simulation results show that the new randomization procedure significantly reduces the probability of deterministic assignments, and improve the covariate balancing capacity when compared to the traditional stratified permuted block randomization.},
author = {Zhao, Wenle},
doi = {10.1002/sim.6266},
file = {::},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Biased-coin minimization method,Big stick design,Block urn design,Clinical trial,Permuted block,Randomization},
number = {30},
pages = {5239--5248},
pmid = {25043719},
title = {{A better alternative to stratified permuted block design for subject randomization in clinical trials}},
volume = {33},
year = {2014}
}
@article{Xiong:2003vd,
author = {Xiong, Xiaoping and Tan, Ming and Boyett, James},
journal = {Biometrics},
month = {sep},
number = {3},
pages = {624--631},
title = {{Sequential conditional probability ratio tests for normalized test statistic on information time.}},
volume = {59},
year = {2003}
}
@article{RN6,
author = {Haroz, Emily E and Kalb, Luther G and Newland, Jason G and Goldman, Jennifer L and Mast, Dana Keener and Ko, Linda K and Grass, Ryan and Shah, Parth and Walsh, Tyler and Schuster, Jennifer E},
doi = {10.1542/peds.2021-054268G},
issn = {0031-4005},
journal = {Pediatrics},
number = {Supplement{\_}2},
title = {{Implementation of School-Based COVID-19 Testing Programs in Underserved Populations}},
type = {Journal Article},
url = {https://doi.org/10.1542/peds.2021-054268G https://watermark.silverchair.com/peds{\_}2021054268g.pdf?token=AQECAHi208BE49Ooan9kkhW{\_}Ercy7Dm3ZL{\_}9Cf3qfKAc485ysgAAAtIwggLOBgkqhkiG9w0BBwagggK{\_}MIICuwIBADCCArQGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM{\_}rjFQaYWyiPQe1XsAgEQ},
volume = {149},
year = {2022}
}
@article{Zhao:2011ce,
author = {Zhao, Wenle and Hill, Michael D and Palesch, Yuko},
journal = {Statistical Methods in Medical Research},
month = {sep},
number = {6},
pages = {989--1002},
title = {{Minimal sufficient balance{\{}$\backslash$textemdash{\}}a new strategy to balance baseline covariates and preserve randomness of treatment allocation}},
volume = {24},
year = {2011}
}
@article{Demidenko:2007hc,
author = {Demidenko, Eugene},
journal = {Statistics in medicine},
month = {aug},
number = {18},
pages = {3385--3397},
title = {{Sample size determination for logistic regression revisited.}},
volume = {26},
year = {2007}
}
@article{LeTourneau2009,
abstract = {Phase I clinical trials are an essential step in the development of anticancer drugs. The main goal of these studies is to establish the recommended dose and/or schedule of new drugs or drug combinations for phase II trials. The guiding principle for dose escalation in phase I trials is to avoid exposing too many patients to subtherapeutic doses while preserving safety and maintaining rapid accrual. Here we review dose escalation methods for phase I trials, including the rule-based and model-based dose escalation methods that have been developed to evaluate new anticancer agents. Toxicity has traditionally been the primary endpoint for phase I trials involving cytotoxic agents. However, with the emergence of molecularly targeted anticancer agents, potential alternative endpoints to delineate optimal biological activity, such as plasma drug concentration and target inhibition in tumor or surrogate tissues, have been proposed along with new trial designs. We also describe specific methods for drug combinations as well as methods that use a time-to-event endpoint or both toxicity and efficacy as endpoints. Finally, we present the advantages and drawbacks of the various dose escalation methods and discuss specific applications of the methods in developmental oncotherapeutics. 2009 The Author(s).2009This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/2.0/uk/), which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited. {\textcopyright} 2009 The Author(s).},
author = {{Le Tourneau}, Christophe and Lee, J. Jack and Siu, Lillian L.},
doi = {10.1093/jnci/djp079},
file = {::},
issn = {00278874},
journal = {Journal of the National Cancer Institute},
number = {10},
pages = {708--720},
pmid = {19436029},
title = {{Dose escalation methods in phase i cancer clinical trials}},
volume = {101},
year = {2009}
}
@article{Efird:2011kn,
author = {Efird, Jimmy},
journal = {International Journal of Environmental Research and Public Health},
month = {jan},
number = {1},
pages = {15--20},
title = {{Blocked Randomization with Randomly Selected Block Sizes}},
volume = {8},
year = {2011}
}
@article{wangge2013,
abstract = {The active-controlled trial with a non-inferiority design has gained popularity in recent years. However, non-inferiority trials present some methodological challenges, especially in determining the non-inferiority margin. Regulatory guidelines provide some general statements on how a non-inferiority trial should be conducted. Moreover, in a scientific advice procedure, regulators give companies the opportunity to discuss critical trial issues prior to the start of the trial. The aim of this study was to identify potential issues that may benefit from more explicit guidance by regulators. To achieve this, we collected and analyzed questions about non-inferiority trials posed by applicants for scientific advice in Europe in 2008 and 2009, as well as the responses given by the European Medicines Agency (EMA). In our analysis we included 156 final letters of advice from 2008 and 2009, addressed to 94 different applicants (manufacturers). Our analysis yielded two major findings: (1) applicants frequently asked questions 'whether' and 'how' to conduct a non-inferiority trial, 26{\%} and 74{\%}, respectively, and (2) the EMA regulators seem mainly concerned about the choice of the non-inferiority margin in non-inferiority trials (36{\%} of total regulatory answers). In 40{\%} of the answers, the EMA recommended using a stricter margin, and in 10{\%} of the answers regarding non-inferiority margins, the EMA questioned the justification of the proposed non-inferiority margin.We conclude that there are still difficulties in selecting the appropriate methodology for non-inferiority trials. Straightforward and harmonized guidance regarding non-inferiority trials is required, for example on whether it is necessary to conduct such a trial and how the non-inferiority margin is determined. It is unlikely that regulatory guidelines can cover all therapeutic areas; therefore, in some cases regulatory scientific advice may be used as an opportunity for tailored advice. {\textcopyright} 2013 Wangge et al.},
author = {Wangge, Grace and Putzeist, Michelle and Knol, Mirjam J. and Klungel, Olaf H. and {Gispen-De Wied}, Christine C. and de Boer, Antonius and Hoes, Arno W. and Leufkens, Hubert G. and Mantel-Teeuwisse, Aukje K.},
doi = {10.1371/journal.pone.0074818},
issn = {19326203},
journal = {PLoS ONE},
number = {9},
pmid = {24040346},
title = {{Regulatory Scientific Advice on Non-Inferiority Drug Trials}},
volume = {8},
year = {2013}
}
@article{Royall:2003gc,
author = {Royall, Richard and Tsou, Tsung Shan},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
month = {may},
number = {2},
pages = {391--404},
title = {{Interpreting statistical evidence by using imperfect models: robust adjusted likelihood functions}},
volume = {65},
year = {2003}
}
@article{Viele2016,
author = {Viele, Kert and McGlothlin, Anna and Broglio, Kristine},
doi = {10.1001/jama.2016.2628},
issn = {15383598},
journal = {JAMA - Journal of the American Medical Association},
number = {15},
pages = {1646--1647},
pmid = {27092832},
title = {{Interpretation of clinical trials that stopped early}},
volume = {315},
year = {2016}
}
@article{Scott:2002ix,
author = {Scott, Neil W and McPherson, Gladys C and Ramsay, Craig R and Campbell, Marion K},
journal = {Controlled Clinical Trials},
month = {dec},
number = {6},
pages = {662--674},
title = {{The method of minimization for allocation to clinical trials}},
volume = {23},
year = {2002}
}
@article{Suresh:2011hia,
author = {Suresh, K P},
journal = {Journal of Human Reproductive Sciences},
number = {1},
pages = {8},
title = {{An overview of randomization techniques: An unbiased assessment of outcome in clinical research}},
volume = {4},
year = {2011}
}
@article{Greenland:2007go,
author = {Greenland, S},
journal = {American Journal of Epidemiology},
month = {dec},
number = {5},
pages = {523--529},
title = {{Invited Commentary: Variable Selection versus Shrinkage in the Control of Multiple Confounders}},
volume = {167},
year = {2007}
}
@article{Kaibel2021,
abstract = {In experiments, researchers commonly allocate subjects randomly and equally to the different treatment conditions before the experiment starts. While this approach is intuitive, it means that new information gathered during the experiment is not utilized until after the experiment has ended. Based on methodological approaches from other scientific disciplines such as computer science and medicine, we suggest machine learning algorithms for subject allocation in experiments. Specifically, we discuss a Bayesian multi-armed bandit algorithm for randomized controlled trials and use Monte Carlo simulations to compare its efficiency with randomized controlled trials that have a fixed and balanced subject allocation. Our findings indicate that a randomized allocation based on Bayesian multi-armed bandits is more efficient and ethical in most settings. We develop recommendations for researchers and discuss the limitations of our approach.},
author = {Kaibel, Chris and Biemann, Torsten},
doi = {10.1177/1094428119854153},
file = {::},
issn = {15527425},
journal = {Organizational Research Methods},
keywords = {ethics in research,experiments,exploration versus exploitation,machine learning,multi-armed bandit,randomized controlled trial},
number = {1},
pages = {78--103},
title = {{Rethinking the Gold Standard With Multi-armed Bandits: Machine Learning Allocation Algorithms for Experiments}},
volume = {24},
year = {2021}
}
@article{RN3,
author = {Zviedrite, N and Hodis, J D and Jahan, F and Gao, H and Uzicanin, A},
doi = {10.1371/journal.pone.0248925},
issn = {1932-6203 (Electronic) 1932-6203 (Linking)},
journal = {PLoS One},
keywords = {Adolescent COVID-19/*epidemiology/prevention {\&} con},
number = {9},
pages = {e0248925},
title = {{COVID-19-associated school closures and related efforts to sustain education and subsidized meal programs, United States, February 18-June 30, 2020}},
type = {Journal Article},
url = {https://www.ncbi.nlm.nih.gov/pubmed/34520475},
volume = {16},
year = {2021}
}
@article{Simon:1979co,
author = {Simon, Richard},
journal = {Biometrics},
month = {jun},
number = {2},
pages = {503},
title = {{Restricted Randomization Designs in Clinical Trials}},
volume = {35},
year = {1979}
}
@article{Hacking:1988cn,
author = {Hacking, I},
journal = {Isis},
title = {{Telepathy: Origins of randomization in experimental design}},
year = {1988}
}
@article{Kawaguchi2011,
abstract = {Methodology for comparing two randomly assigned treatments for strictly ordinal response variables has been discussed throughout the literature on multivariate Mann-Whitney estimators with stratification adjustment. Although such estimators can be computed directly as weighted linear combinations of within-stratum Mann-Whitney estimators, consistent estimation of their covariance matrix is done using methods for multivariate U-statistics. The scope of these methods includes ways of managing randomly missing data and ways to invoke randomization-based covariance adjustment for no differences between treatments for background or baseline covariables. The assessment of treatment differences can be done using confidence intervals or statistical tests for the adjusted Mann-Whitney estimators. The methods in this article are illustrated using three examples. The first example is a randomized clinical trial with eight strata and a univariate ordinal response variable. The second example is a randomized clinical trial with four strata, two covariables, and four ordinal response variables. The third example is a randomized two-period crossover clinical trial with four strata, three covariables (as age, screening, first baseline), three response variables (as first period response, second baseline, second period response), and missing data. For these examples, the results are interpretable through the probability of better outcomes for one treatment over the other. {\textcopyright} American Statistical Association Statistics in Biopharmaceutical Research.},
author = {Kawaguchi, Atsushi and Koch, Gary G. and Wang, Xiaofei},
doi = {10.1198/sbr.2010.10007},
issn = {19466315},
journal = {Statistics in Biopharmaceutical Research},
keywords = {Randomization-based nonparametric covariance adjus,Rank measures of association for pairwise comparis,Strictly ordinal response variable,U-statistics,Weighted least squares estimation},
number = {2},
pages = {217--231},
title = {{Stratified multivariate Mann-Whitney estimators for the comparison of two treatments with randomization based covariance adjustment}},
volume = {3},
year = {2011}
}
@article{bhatt2016adaptive,
author = {Bhatt, Deepak L and Mehta, Cyrus},
journal = {New England Journal of Medicine},
number = {1},
pages = {65--74},
publisher = {Mass Medical Soc},
title = {{Adaptive designs for clinical trials}},
volume = {375},
year = {2016}
}
@article{Mihalcik2018,
author = {Mihalcik, Stephen A and Chipman, Jonathan J and Sanda, Martin G and Regan, Meredith M and Kaplan, Irving D and Wagner, Andrew A and Crociani, Catrina M and Chang, Peter},
doi = {10.1016/j.prro.2018.04.007},
institution = {PROST-QA Consortium},
issn = {1879-8519 (Electronic)},
journal = {Practical radiation oncology},
keywords = {Age Factors,Aged,Body Mass Index,Brachytherapy,Erectile Dysfunction,Follow-Up Studies,Humans,Kallikreins,Male,Middle Aged,Nomograms,Patient Reported Outcome Measures,Prostate-Specific Antigen,Prostatic Neoplasms,Quality of Life,adverse effects,blood,diagnosis,epidemiology,etiology,radiotherapy},
language = {eng},
month = {nov},
number = {6},
pages = {445--451},
pmid = {29935957},
title = {{Predicting erectile function following external beam radiation therapy or brachytherapy for prostate cancer using EPIC-CP.}},
volume = {8},
year = {2018}
}
@article{RN11,
author = {Wetter, D W and Mazas, C and Daza, P and Nguyen, L and Fouladi, R T and Li, Y and Cofta-Woerpel, L},
doi = {10.1002/cncr.22360},
issn = {0008-543X (Print) 0008-543x},
journal = {Cancer},
keywords = {Adult Counseling/*methods Female Follow-Up Studies},
number = {2 Suppl},
pages = {406--413},
title = {{Reaching and treating Spanish-speaking smokers through the National Cancer Institute's Cancer Information Service. A randomized controlled trial}},
type = {Journal Article},
url = {https://acsjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cncr.22360?download=true},
volume = {109},
year = {2007}
}
@article{Greevy:2004ke,
author = {Greevy, R and Lu, B and Silber, J H and Rosenbaum, P},
journal = {Biostatistics (Oxford, England)},
title = {{Optimal multivariate matching before randomization}},
year = {2004}
}
@article{Hobbs:2008ce,
author = {Hobbs, Brian P and Carlin, Bradley P},
journal = {Journal of biopharmaceutical statistics},
number = {1},
pages = {54--80},
title = {{Practical Bayesian design and analysis for drug and device clinical trials.}},
volume = {18},
year = {2008}
}
@article{Guo:1995df,
author = {Guo, J and Geng, Z},
journal = {Journal of the Royal Statistical Society Series B ( {\ldots}},
title = {{Collapsibility of logistic regression coefficients}},
year = {1995}
}
@article{Lebowitsch2012,
abstract = {Dynamic allocation has received considerable attention since it was first proposed in the 1970s as an alternative means of allocating treatments in clinical trials which helps to secure the balance of prognostic factors across treatment groups. The purpose of this paper is to present a generalized multidimensional dynamic allocation method that simultaneously balances treatment assignments at three key levels: within the overall study, within each level of each prognostic factor, and within each stratum, that is, combination of levels of different factors Further it offers capabilities for unbalanced and adaptive designs for trials. The treatment balancing performance of the proposed method is investigated through simulations which compare multidimensional dynamic allocation with traditional stratified block randomization and the Pocock-Simon method. On the basis of these results, we conclude that this generalized multidimensional dynamic allocation method is an improvement over conventional dynamic allocation methods and is flexible enough to be applied for most trial settings including PhasesI, II and III trials. {\textcopyright} 2012 John Wiley {\&} Sons, Ltd.},
annote = {Many names for same thing: minimization, dynamic allocation (DA), and covariate adaptive randomization.

References for:
- Growing use in Phase III oncology trials (Pond) 
- Controversies in DA methods (Pond)
- Ideal balanced coin probability (Tymofyeyev)
- Rerandomization should be used for primary analysis or secondary analysis to support conventional (model-based) tests (Berger)
For minimization criteria, uses marginal imbalance (overall allocation imbalance) on overall, strata, site, and factor level imbalances.

Proposes a first choice and second choice allocation ratio. Cites 0.80-0.85 as a desireable balanced coin with reference.

Note, I was not able to replicate these results of Table 1. Also,},
author = {Lebowitsch, Jonathan and Ge, Yan and Young, Benjamin and Hu, Feifang},
doi = {10.1002/sim.5418},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Covariate adaptive randomization,Dynamic allocation,Minimization,Unbalanced design},
number = {28},
pages = {3537--3544},
pmid = {22736449},
title = {{Generalized multidimensional dynamic allocation method}},
volume = {31},
year = {2012}
}
@article{Gu:2010km,
author = {Gu, W and Pepe, M S},
journal = {Biostatistics (Oxford, England)},
month = {dec},
number = {1},
pages = {87--101},
title = {{Estimating the diagnostic likelihood ratio of a continuous marker}},
volume = {12},
year = {2010}
}
@article{Saville2013,
abstract = {In the context of randomized clinical trials with time-to-event outcomes, estimates of covariate-adjusted log hazard ratios for comparing two treatments are obtained via nonparametric analysis of covariance by forcing the difference in means for covariables to zero. The method avoids the assumption of proportional hazards for each of the covariates, and it provides an adjusted analysis for the same population average treatment effect that the unadjusted analysis addresses. It is primarily useful in regulatory clinical trials that require analyses to be specified a priori. To illustrate, the method is applied to a study of lung disease with multivariate time-to-event outcomes. {\textcopyright} 2013 Copyright Taylor and Francis Group, LLC.},
author = {Saville, Benjamin R. and Koch, Gary G.},
doi = {10.1080/10543406.2012.755692},
issn = {10543406},
journal = {Journal of Biopharmaceutical Statistics},
keywords = {Analysis of covariance,Cox proportional hazards,Hazard ratio,Linear models equating covariate means,Lung disease,Multivariate survival,Weighted least squares},
number = {2},
pages = {477--490},
pmid = {23437952},
title = {{Estimating covariate-adjusted log hazard ratios in randomized clinical trials using cox proportional hazards models and nonparametric randomization based analysis of covariance}},
volume = {23},
year = {2013}
}
@article{siegmund2013sequential,
author = {Schmee, Josef and Siegmund, David},
journal = {Technometrics},
month = {feb},
number = {1},
pages = {123},
title = {{Sequential Analysis, Tests and Confidence Intervals}},
volume = {29},
year = {1987}
}
@misc{InternationalCouncilforHarmonisationofTechnicalRequirementsforPharmaceuticalsforHumanuse,
author = {{International Council for Harmonisation of Technical Requirements for Pharmaceuticals for Human use}},
booktitle = {https://www.ema.europa.eu/documents/scientific-guideline/draftich- e9-r1-addendum-estimands-sensitivity-analysis-clinical-trialsguideline- statistical{\_}en.pdf},
title = {{ICH Harmonized Guideline E9 (R1) Estimands and Sensitivity analysis in Clinical Trials}},
year = {2017}
}
@article{Frane:1998ch,
author = {Frane, J W},
journal = {Therapeutic Innovation {\&} Regulatory Science},
month = {apr},
number = {2},
pages = {423--432},
title = {{A Method of Biased Coin Randomization, its Implementation, and its Validation}},
volume = {32},
year = {1998}
}
@article{Zhao:2011gh,
author = {Zhao, Wenle and Weng, Yanqiu},
journal = {Contemporary Clinical Trials},
month = {nov},
number = {6},
pages = {953--961},
title = {{Block urn design {\{}$\backslash$textemdash{\}} A new randomization algorithm for sequential trials with two or more treatments and balanced or unbalanced allocation}},
volume = {32},
year = {2011}
}
@article{Vickers:2008fu,
author = {Vickers, Andrew J},
journal = {The American statistician},
month = {nov},
number = {4},
pages = {314--320},
title = {{Decision Analysis for the Evaluation of Diagnostic Tests, Prediction Models, and Molecular Markers}},
volume = {62},
year = {2008}
}
@article{Aronow2014a,
abstract = {We propose a consistent estimator of sharp bounds on the variance of the difference-in-means estimator in completely randomized experiments. Generalizing Robins [Stat. Med. 7 (1988) 773-785], our results resolve a wellknown identification problem in causal inference posed by Neyman [Statist. Sci. 5 (1990) 465-472. Reprint of the original 1923 paper]. A practical implication of our results is that the upper bound estimator facilitates the asymptotically narrowest conservative Wald-type confidence intervals, with applications in randomized controlled and clinical trials. {\textcopyright} Institute of Mathematical Statistics, 2014.},
author = {Aronow, Peter M. and Green, Donald P. and Lee, Donald K.K.},
doi = {10.1214/13-AOS1200},
file = {::},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Causal inference,Finite populations,Potential outcomes,Randomized experiments,Variance estimation},
number = {3},
pages = {850--871},
title = {{Sharp bounds on the variance in randomized experiments}},
volume = {42},
year = {2014}
}
@article{Vickers:2012he,
author = {Vickers, Andrew J},
journal = {The Journal of Urology},
month = {may},
number = {5},
pages = {1638},
title = {{Editorial Comment}},
volume = {187},
year = {2012}
}
@article{korn2017,
abstract = {There is a wide range of adaptive elements of clinical trial design (some old and some new), with differing advantages and disadvantages. Classical interim monitoring, which adapts the design based on early evidence of superiority or futility of a treatment arm, has long been known to be extremely useful. A more recent application of interim monitoring is in the use of phase II/III designs, which can be very effective (especially in the setting of multiple experimental treatments and a reliable intermediate end point) but do have the cost of having to commit earlier to the phase III question than if separate phase II and phase III trials were performed. Outcome-adaptive randomization is an older technique that has recently regained attention; it increases trial complexity and duration without offering substantial benefits to the patients in the trial. The use of adaptive trials with biomarkers is new and has great potential for efficiently identifying patients who will be helped most by specific treatments. Master protocols in which trial arms and treatment questions are added to an ongoing trial can be especially efficient in the biomarker setting, where patients are screened for entry into different subtrials based on evolving knowledge about targeted therapies. A discussion of three recent adaptive clinical trials (BATTLE-2, I-SPY 2, and FOCUS4) highlights the issues.},
author = {Korn, Edward L. and Freidlin, Boris},
doi = {10.1093/jnci/djx013},
file = {::},
issn = {14602105},
journal = {Journal of the National Cancer Institute},
number = {6},
pages = {1--6},
pmid = {28376148},
title = {{Adaptive Clinical Trials: Advantages and Disadvantages of Various Adaptive Design Elements}},
volume = {109},
year = {2017}
}
@article{Parmar:1994wo,
author = {Parmar, M K and Spiegelhalter, D J and Freedman, L S},
journal = {Statistics in medicine},
month = {jul},
number = {13-14},
pages = {1297--1312},
title = {{The CHART trials: Bayesian design and monitoring in practice. CHART Steering Committee.}},
volume = {13},
year = {1994}
}
@article{Biostatistics2005,
author = {of Biostatistics), John D Cook (UT MD Anderson Cancer Center/Department},
file = {::},
title = {{Fast approximation of Beta inequalities}},
year = {2005}
}
@article{Stout:2015fe,
author = {Stout, R L and Wirtz, P W and Carbonari, J P and {Del Boca}, F K},
journal = {Journal of Studies on Alcohol, Supplement},
month = {jan},
number = {s12},
pages = {70--75},
title = {{Ensuring balanced distribution of prognostic factors in treatment outcome research.}},
year = {2015}
}
@article{Bruhn2009,
author = {Bruhn, By Miriam and Mckenzie, David},
file = {::},
number = {4},
pages = {200--232},
title = {{In Pursuit of Balance : Randomization in Practice in Development Field Experiments Author ( s ): Miriam Bruhn and David McKenzie Source : American Economic Journal : Applied Economics , October 2009 , Vol . 1 , No . 4 Published by : American Economic Asso}},
volume = {1},
year = {2009}
}
@book{lohr2009sampling,
author = {Lohr, S},
title = {{Sampling: design and analysis}},
year = {2009}
}
@article{Farooq:2011kd,
author = {Farooq, Vasim and Brugaletta, Salvatore and Vranckx, Pascal and Serruys, Patrick},
journal = {EuroIntervention},
month = {mar},
number = {8},
pages = {909--912},
title = {{A guide to interpreting and assessing the performance of prediction models}},
volume = {6},
year = {2011}
}
@article{Haroz2022,
author = {Haroz, Emily E and Kalb, Luther G and Newland, Jason G and Goldman, Jennifer L and Mast, Dana Keener and Ko, Linda K and Grass, Ryan and Shah, Parth and Walsh, Tyler and Schuster, Jennifer E},
doi = {10.1542/peds.2021-054268G},
issn = {0031-4005},
journal = {Pediatrics},
number = {Supplement{\_}2},
title = {{Implementation of School-Based COVID-19 Testing Programs in Underserved Populations}},
volume = {149},
year = {2022}
}
@article{Heagerty:2005ia,
author = {Heagerty, Patrick J and Zheng, Yingye},
journal = {Biometrics},
month = {mar},
number = {1},
pages = {92--105},
title = {{Survival model predictive accuracy and ROC curves.}},
volume = {61},
year = {2005}
}
@article{Houlston2004a,
abstract = {Much of the familial aggregation of common cancer results from inherited susceptibility, but highly penetrant mutations in known genes cannot account for most of the excess. Some of the unexplained familial risk is presumably due to high-penetrance mutations in as yet unidentified genes, but polygenic mechanisms are likely to account for a greater proportion, particularly in breast cancer. This inference, coupled with technological developments, has led to a renaissance in association studies. Most such studies have evaluated small numbers of single-nucleotide polymorphisms (SNPs) in a few candidate genes, but reliable high-density oligonucleoticle arrays and other novel techniques will allow genome-wide allelic association studies to be conducted. High-density genome-wide SNP analysis will include targets identified by structural considerations, as well as the growing list of candidate genes. In the longer term, high-throughput resequencing will be required to identify the rare pathogenic variants that may constitute the majority of low-penetrance alleles. The detection of low-penetrance cancer susceptibility genes will then be restricted mainly by the availability of large numbers of well-characterized cases and controls. Cancer patients with affected relatives are considerably more informative than unselected cases for such studies.},
author = {Houlston, Richard S. and Peto, Julian},
doi = {10.1038/sj.onc.1207951},
file = {::},
issn = {09509232},
journal = {Oncogene},
keywords = {Cancer,Low-penetrance genes,Risk},
number = {38},
pages = {6471--6476},
pmid = {15322517},
title = {{The search for low-penetrance cancer susceptibility alleles}},
volume = {23},
year = {2004}
}
@article{Vickers:2014jg,
author = {Vickers, Andrew J and Pepe, Margaret},
journal = {Annals of Internal Medicine},
month = {jan},
number = {2},
pages = {136--137},
title = {{Does the Net Reclassification Improvement Help Us Evaluate Models and Markers?}},
volume = {160},
year = {2014}
}
@article{Renfro2017a,
abstract = {Traditionally, site of disease and anatomic staging have been used to define patient populations to be studied in individual cancer clinical trials. In the past decade, however, oncology has become increasingly understood on a cellular and molecular level, with many cancer subtypes being described as a function of biomarkers or tumor genetic mutations. With these changes in the science of oncology have come changes to the way we design and perform clinical trials. Increasingly common are trials tailored to detect enhanced efficacy in a patient subpopulation, e.g. patients with a known biomarker value or whose tumors harbor a specific genetic mutation. Here, we provide an overview of traditional and newer biomarker-based trial designs, and highlight lessons learned through implementation of several ongoing and recently completed trials.},
author = {Renfro, Lindsay A. and An, Ming Wen and Mandrekar, Sumithra J.},
doi = {10.1016/j.canlet.2016.03.015},
file = {::},
issn = {18727980},
journal = {Cancer Letters},
keywords = {Adaptive design,Biomarker-based design,Clinical trial,Oncology},
pages = {121--126},
pmid = {26987624},
publisher = {Elsevier Ireland Ltd},
title = {{Precision oncology: A new era of cancer clinical trials}},
url = {http://dx.doi.org/10.1016/j.canlet.2016.03.015},
volume = {387},
year = {2017}
}
@article{Berchialla:2018bk,
author = {Berchialla, Paola and Gregori, Dario and Baldi, Ileana},
journal = {Topoi},
month = {feb},
number = {4},
pages = {479},
title = {{The Role of Randomization in Bayesian and Frequentist Design of Clinical Trial}},
volume = {76},
year = {2018}
}
@article{Cro2020,
abstract = {Missing data due to loss to follow-up or intercurrent events are unintended, but unfortunately inevitable in clinical trials. Since the true values of missing data are never known, it is necessary to assess the impact of untestable and unavoidable assumptions about any unobserved data in sensitivity analysis. This tutorial provides an overview of controlled multiple imputation (MI) techniques and a practical guide to their use for sensitivity analysis of trials with missing continuous outcome data. These include $\delta$- and reference-based MI procedures. In $\delta$-based imputation, an offset term, $\delta$, is typically added to the expected value of the missing data to assess the impact of unobserved participants having a worse or better response than those observed. Reference-based imputation draws imputed values with some reference to observed data in other groups of the trial, typically in other treatment arms. We illustrate the accessibility of these methods using data from a pediatric eczema trial and a chronic headache trial and provide Stata code to facilitate adoption. We discuss issues surrounding the choice of $\delta$ in $\delta$-based sensitivity analysis. We also review the debate on variance estimation within reference-based analysis and justify the use of Rubin's variance estimator in this setting, since as we further elaborate on within, it provides information anchored inference.},
author = {Cro, Suzie and Morris, Tim P. and Kenward, Michael G. and Carpenter, James R.},
doi = {10.1002/sim.8569},
file = {::},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {clinical trials,controlled multiple imputation,missing data,multiple imputation,sensitivity analysis},
number = {21},
pages = {2815--2842},
pmid = {32419182},
title = {{Sensitivity analysis for clinical trials with missing continuous outcome data using controlled multiple imputation: A practical guide}},
volume = {39},
year = {2020}
}
@article{Ross:2004gd,
author = {Ross, Judith L and Sandberg, David E and Rose, Susan R and Leschek, Ellen Werber and Baron, Jeffrey and Chipman, John J and Cassorla, Fernando G and Quigley, Charmian A and Crowe, Brenda J and Roberts, Kristen and {Cutler Jr.}, Gordon B},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {oct},
number = {10},
pages = {4873--4878},
title = {{Psychological Adaptation in Children with Idiopathic Short Stature Treated with Growth Hormone or Placebo}},
volume = {89},
year = {2004}
}
@article{Ding2018,
abstract = {Inferring causal effects of treatments is a central goal in many disciplines. The potential outcomes framework is a main statistical approach to causal inference, in which a causal effect is defined as a comparison of the potential outcomes of the same units under different treatment conditions. Because for each unit at most one of the potential outcomes is observed and the rest are missing, causal inference is inherently a missing data problem. Indeed, there is a close analogy in the terminology and the inferential framework between causal inference and missing data. Despite the intrinsic connection between the two subjects, statistical analyses of causal inference and missing data also have marked differences in aims, settings and methods. This article provides a systematic review of causal inference from the missing data perspective. Focusing on ignorable treatment assignment mechanisms, we discuss a wide range of causal inference methods that have analogues in missing data analysis, such as imputation, inverse probability weighting and doubly robust methods. Under each of the three modes of inference- Frequentist, Bayesian and Fisherian randomization-we present the general structure of inference for both finite-sample and super-population estimands, and illustrate via specific examples. We identify open questions to motivate more research to bridge the two fields.},
archivePrefix = {arXiv},
arxivId = {1712.06170},
author = {Ding, Peng and Li, Fan},
doi = {10.1214/18-STS645},
eprint = {1712.06170},
file = {::},
issn = {08834237},
journal = {Statistical Science},
keywords = {Assignment mechanism,Ignorability,Imputation,Missing data mechanism,Observational studies,Potential outcome,Propensity score,Randomization,Weighting},
number = {2},
pages = {214--237},
title = {{Causal inference: A missing data perspective}},
volume = {33},
year = {2018}
}
@article{rouder2018,
abstract = {In the psychological literature, there are two seemingly different approaches to inference: that from estimation of posterior intervals and that from Bayes factors. We provide an overview of each method and show that a salient difference is the choice of models. The two approaches as commonly practiced can be unified with a certain model specification, now popular in the statistics literature, called spike-and-slab priors. A spike-and-slab prior is a mixture of a null model, the spike, with an effect model, the slab. The estimate of the effect size here is a function of the Bayes factor, showing that estimation and model comparison can be unified. The salient difference is that common Bayes factor approaches provide for privileged consideration of theoretically useful parameter values, such as the value corresponding to the null hypothesis, while estimation approaches do not. Both approaches, either privileging the null or not, are useful depending on the goals of the analyst.},
author = {Rouder, Jeffrey N. and Haaf, Julia M. and Vandekerckhove, Joachim},
doi = {10.3758/s13423-017-1420-7},
isbn = {1342301714},
issn = {15315320},
journal = {Psychonomic Bulletin and Review},
keywords = {Bayesian inference and parameter estimation,Bayesian statistics,Model selection},
number = {1},
pages = {102--113},
pmid = {29441460},
publisher = {Psychonomic Bulletin {\&} Review},
title = {{Bayesian inference for psychology, part IV: parameter estimation and Bayes factors}},
volume = {25},
year = {2018}
}
@article{Cook:2008ij,
author = {Cook, N R},
journal = {Clinical chemistry},
month = {nov},
number = {1},
pages = {17--23},
title = {{Statistical Evaluation of Prognostic versus Diagnostic Models: Beyond the ROC Curve}},
volume = {54},
year = {2007}
}
@article{Moore2020a,
abstract = {Objectives Little is routinely disclosed about the costs of the pivotal clinical trials that provide the key scientific evidence of the treatment benefits of new therapeutic agents. We expand our earlier research to examine why the estimated costs may vary 100-fold. Design A cross-sectional study of the estimated costs of the pivotal clinical trials supporting the approval of 101 new therapeutic agents approved by the US Food and Drug Administration from 2015 to 2017. Methods We licensed a software tool used by the pharmaceutical industry to estimate the likely costs of clinical trials to be conducted by contract research organisations. For each trial we collected 52 study characteristics. Linear regression was used to assess the most important factors affecting costs. Primary and secondary outcome measures The mean and 95{\%} CI of 225 pivotal clinical trials using varying assumptions. We also assessed median estimated costs per patient, per clinic visit and per drug. Results Measured as pivotal trials cost per approved drug, the 101 new molecular entities had an estimated median cost of US{\$}48 million (IQR US{\$}20 million-US{\$}102 million). The 225 individual clinical trials had a median estimate of US{\$}19 million (IQR US{\$}12 million-US{\$}33 million) per trial and US{\$}41 413 (IQR, US{\$}29 894-US{\$}75 047) per patient. The largest single factor driving cost was the number of patients required to establish the treatment effects and varied from 4 patients to 8442. Next was the number of trial clinic visits, which ranged from 2 to 166. Our statistical model showed trial costs rose exponentially with these two variables (R 2 =0.696, F=257.9, p{\textless}0.01). Conclusions The estimated costs are modest for measuring the benefits of new therapeutic agents but rise exponentially as more patients and clinic visits are required to establish a drug effect.},
author = {Moore, Thomas J. and Heyward, James and Anderson, Gerard and Alexander, G. Caleb},
doi = {10.1136/bmjopen-2020-038863},
issn = {20446055},
journal = {BMJ Open},
keywords = {clinical pharmacology,clinical trials,epidemiology,medical law,public health},
number = {6},
pages = {1--5},
pmid = {32532786},
title = {{Variation in the estimated costs of pivotal clinical benefit trials supporting the US approval of new therapeutic agents, 2015-2017: A cross-sectional study}},
volume = {10},
year = {2020}
}
@article{Broglio:2014fr,
author = {Broglio, Kristine R and Connor, Jason T and Berry, Scott M},
journal = {Journal of biopharmaceutical statistics},
number = {3},
pages = {685--705},
title = {{Not too big, not too small: a goldilocks approach to sample size selection.}},
volume = {24},
year = {2014}
}
@article{Landwehr:1984fa,
author = {Landwehr, James M and Pregibon, Daryl and Shoemaker, Anne C},
journal = {Journal of the American Statistical Association},
month = {mar},
number = {385},
pages = {61--71},
title = {{Graphical Methods for Assessing Logistic Regression Models}},
volume = {79},
year = {1984}
}
@article{RN4,
author = {Chu, I Y and Alam, P and Larson, H J and Lin, L},
doi = {10.1093/jtm/taaa192},
issn = {1708-8305 (Electronic) 1195-1982 (Print) 1195-1982 (Linking)},
journal = {J Travel Med},
keywords = {Covid-19 Communicable Disease Control/*methods Cor,Viral/epidemiology/*prevention {\&} control Public H},
number = {7},
title = {{Social consequences of mass quarantine during epidemics: a systematic review with implications for the COVID-19 response}},
type = {Journal Article},
url = {https://www.ncbi.nlm.nih.gov/pubmed/33051660},
volume = {27},
year = {2020}
}
@article{Zhu:2012ix,
author = {Zhu, Xiaoye and Albertsen, Peter C and Andriole, Gerald L and Roobol, Monique J and Schr{\"{o}}der, Fritz H and Vickers, Andrew J},
journal = {European urology},
month = {apr},
number = {4},
pages = {652--661},
title = {{Risk-Based Prostate Cancer Screening}},
volume = {61},
year = {2012}
}
@article{pencina2008evaluating,
author = {Pencina, Michael J and {D'Agostino Sr}, Ralph B and {D'Agostino Jr}, Ralph B and Vasan, Ramachandran S},
journal = {Statistics in medicine},
number = {2},
pages = {157--172},
publisher = {Wiley Online Library},
title = {{Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond}},
volume = {27},
year = {2008}
}
@article{Stamey:2013ei,
author = {Stamey, James D and Natanegara, Fanni and Seaman, John W},
journal = {Journal of biopharmaceutical statistics},
number = {4},
pages = {790--803},
title = {{Bayesian sample size determination for a clinical trial with correlated continuous and binary outcomes.}},
volume = {23},
year = {2013}
}
@article{Vickers:2014bh,
author = {Vickers, Andrew J and Kent, Matthew},
journal = {Urology},
month = {jul},
number = {1},
pages = {163},
title = {{Reply}},
volume = {84},
year = {2014}
}
@article{Carlin:1996dm,
author = {Carlin, B P and Sargent, D J},
journal = {Statistics in medicine},
month = {jun},
number = {11},
pages = {1093--1106},
title = {{Robust Bayesian approaches for clinical trial monitoring.}},
volume = {15},
year = {1996}
}
@article{Fine1999,
abstract = {With explanatory covariates, the standard analysis for competing risks data involves modeling the cause-specific hazard functions via a proportional hazards assumption. Unfortunately, the cause-specific hazard function does not have a direct interpretation in terms of survival probabilities for the particular failure type. In recent years many clinicians have begun using the cumulative incidence function, the marginal failure probabilities for a particular cause, which is intuitively appealing and more easily explained to the nonstatistician. The cumulative incidence is especially relevant in cost-effectiveness analyses in which the survival probabilities are needed to determine treatment utility. Previously, authors have considered methods for combining estimates of the cause-specific hazard functions under the proportional hazards formulation. However, these methods do not allow the analyst to directly assess the effect of a covariate on the marginal probability function. In this article we propose a novel semiparametric proportional hazards model for the subdistribution. Using the partial likelihood principle and weighting techniques, we derive estimation and inference procedures for the finite-dimensional regression parameter under a variety of censoring scenarios. We give a uniformly consistent estimator for the predicted cumulative incidence for an individual with certain covariates; confidence intervals and bands can be obtained analytically or with an easy-to-implement simulation technique. To contrast the two approaches, we analyze a dataset from a breast cancer clinical trial under both models.},
author = {Fine, Jason P. and Gray, Robert J.},
doi = {10.1080/01621459.1999.10474144},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Hazard of subdistribution,Martingale,Partial likelihood,Transformation model},
number = {446},
pages = {496--509},
title = {{A Proportional Hazards Model for the Subdistribution of a Competing Risk}},
volume = {94},
year = {1999}
}
@article{Box:2012fg,
author = {Box, Joan Fisher},
journal = {The American statistician},
month = {mar},
number = {1},
pages = {1--7},
title = {{R.A. Fisher and the Design of Experiments, 1922{\{}$\backslash$textendash{\}}1926}},
volume = {34},
year = {2012}
}
@article{Krull2001,
abstract = {This article combines procedures for single-level mediational analysis with multilevel modeling techniques in order to appropriately test mediational effects in clustered data. A simulation study compared the performance of these multilevel mediational models with that of single-level mediational models in clustered data with individual- or group-level initial independent variables, individual- or group-level mediators, and individual level outcomes. The standard errors of mediated effects from the multilevel solution were generally accurate, while those from the single-level procedure were downwardly biased, often by 20{\%} or more. The multilevel advantage was greatest in those situations involving group-level variables, larger group sizes, and higher intraclass correlations in mediator and outcome variables. Multilevel mediational modeling methods were also applied to data from a preventive intervention designed to reduce intentions to use steroids among players on high school football teams. This example illustrates differences between single-level and multilevel mediational modeling in real-world clustered data and shows how the multilevel technique may lead to more accurate results.},
author = {Krull, Jennifer L. and MacKinnon, David P.},
doi = {10.1207/S15327906MBR3602_06},
file = {::},
issn = {00273171},
journal = {Multivariate Behavioral Research},
number = {2},
pages = {249--277},
title = {{Multilevel modeling of individual and group level mediated effects}},
volume = {36},
year = {2001}
}
@article{Walvoord:2009cf,
author = {Walvoord, Emily C and de la Pena, Amparo and Park, Soomin and Silverman, Bernard and Cuttler, Leona and Rose, Susan R and Cutler, Gordon and Drop, Stenvert and Chipman, John J},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {jun},
number = {6},
pages = {2052--2059},
title = {{Inhaled Growth Hormone (GH) Compared with Subcutaneous GH in Children with GH Deficiency: Pharmacokinetics, Pharmacodynamics, and Safety}},
volume = {94},
year = {2009}
}
@article{Austin2014,
abstract = {Propensity-score matching is increasingly being used to reduce the confounding that can occur in observational studies examining the effects of treatments or interventions on outcomes. We used Monte Carlo simulations to examine the following algorithms for forming matched pairs of treated and untreated subjects: optimal matching, greedy nearest neighbor matching without replacement, and greedy nearest neighbor matching without replacement within specified caliper widths. For each of the latter two algorithms, we examined four different sub-algorithms defined by the order in which treated subjects were selected for matching to an untreated subject: lowest to highest propensity score, highest to lowest propensity score, best match first, and random order. We also examined matching with replacement. We found that (i) nearest neighbor matching induced the same balance in baseline covariates as did optimal matching; (ii) when at least some of the covariates were continuous, caliper matching tended to induce balance on baseline covariates that was at least as good as the other algorithms; (iii) caliper matching tended to result in estimates of treatment effect with less bias compared with optimal and nearest neighbor matching; (iv) optimal and nearest neighbor matching resulted in estimates of treatment effect with negligibly less variability than did caliper matching; (v) caliper matching had amongst the best performance when assessed using mean squared error; (vi) the order in which treated subjects were selected for matching had at most a modest effect on estimation; and (vii) matching with replacement did not have superior performance compared with caliper matching without replacement. {\textcopyright} 2013 The Authors. Statistics in Medicine published by John Wiley {\&} Sons, Ltd.},
author = {Austin, Peter C.},
doi = {10.1002/sim.6004},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Computer algorithms,Matching,Monte Carlo simulations,Optimal matching,Propensity score,Propensity-score matching},
number = {6},
pages = {1057--1069},
pmid = {24123228},
title = {{A comparison of 12 algorithms for matching on the propensity score}},
volume = {33},
year = {2014}
}
@article{Chen:2009cq,
author = {Chen, S and Blackford, A L and Parmigiani, G},
journal = {Journal of Clinical Oncology},
month = {dec},
number = {4},
pages = {642--643},
title = {{Tailoring BRCAPRO to Asian-Americans}},
volume = {27},
year = {2008}
}
@article{Hemerik2020,
abstract = {The statistical literature is known to be inconsistent in the use of the terms ‘permutation test' and ‘randomisation test'. Several authors successfully argue that these terms should be used to refer to two distinct classes of tests and that there are major conceptual differences between these classes. The present paper explains an important difference in mathematical reasoning between these classes: a permutation test fundamentally requires that the set of permutations has a group structure, in the algebraic sense; the reasoning behind a randomisation test is not based on such a group structure, and it is possible to use an experimental design that does not correspond to a group. In particular, we can use a randomisation scheme where the number of possible treatment patterns is larger than in standard experimental designs. This leads to exact p values of improved resolution, providing increased power for very small significance levels, at the cost of decreased power for larger significance levels. We discuss applications in randomised trials and elsewhere. Further, we explain that Fisher's famous Lady Tasting Tea experiment, which is commonly referred to as the first permutation test, is in fact a randomisation test. This distinction is important to avoid confusion and invalid tests.},
annote = {Permutatin tests are based on random sampling from populations.

Randomization tests are based upon experimental randomization of treatments.

Group invariance test [not sure about this] but the test statistic T(g(X)) with g in G is in invariant under all transformation of X in G.},
author = {Hemerik, Jesse and Goeman, Jelle J.},
doi = {10.1111/insr.12431},
issn = {17515823},
journal = {International Statistical Review},
keywords = {group invariance test,lady tasting tea,permutation test,randomisation test},
number = {January},
title = {{Another Look at the Lady Tasting Tea and Differences Between Permutation Tests and Randomisation Tests}},
year = {2020}
}
@article{Wei:1977js,
author = {Wei, Lee-Jen},
journal = {Journal of the American Statistical Association},
number = {358},
pages = {382},
title = {{A Class of Designs for Sequential Clinical Trials}},
volume = {72},
year = {1977}
}
@article{Ware:2006kf,
author = {Ware, James H},
journal = {New England Journal of Medicine},
month = {dec},
number = {25},
pages = {2615--2617},
title = {{The Limitations of Risk Factors as Prognostic Tools}},
volume = {355},
year = {2006}
}
@article{Murray2022,
author = {Murray, Megan Hollister},
file = {::},
title = {{On second-generation p -values for equivalence testing and study planning , and flexible false discovery rate computation for classical p -values By}},
year = {2022}
}
@article{Anonymous:-PUN4GRb,
author = {{Van Hoorde}, K and {Van Huffel}, S and Timmerman, D and Bourne, T and {Van Calster}, B},
journal = {Journal of Biomedical Informatics},
month = {apr},
pages = {283--293},
title = {{A spline-based tool to assess and visualize the calibration of multiclass risk predictions}},
volume = {54},
year = {2015}
}
@article{RN10,
author = {Head, Katharine J and Noar, Seth M and Iannarino, Nicholas T and Harrington, Nancy Grant},
issn = {0277-9536},
journal = {Social Science {\&} Medicine},
pages = {41--48},
title = {{Efficacy of text messaging-based interventions for health promotion: a meta-analysis}},
type = {Journal Article},
volume = {97},
year = {2013}
}
@article{Talluri:2016bv,
author = {Talluri, Rajesh and Shete, Sanjay},
journal = {BMC Medical Informatics and Decision Making},
month = {jul},
number = {1},
pages = {3590},
title = {{Using the weighted area under the net benefit curve for decision curve analysis}},
volume = {16},
year = {2016}
}
@article{Hobbs2018,
abstract = {The process of screening agents one-at-a-time under the current clinical trials system suffers from several deficiencies that could be addressed in order to extend financial and patient resources. In this article, we introduce a statistical framework for designing and conducting randomized multi-arm screening platforms with binary endpoints using Bayesian modeling. In essence, the proposed platform design consolidates inter-study control arms, enables investigators to assign more new patients to novel therapies, and accommodates mid-trial modifications to the study arms that allow both dropping poorly performing agents as well as incorporating new candidate agents. When compared to sequentially conducted randomized two-arm trials, screening platform designs have the potential to yield considerable reductions in cost, alleviate the bottleneck between phase I and II, eliminate bias stemming from inter-trial heterogeneity, and control for multiplicity over a sequence of a priori planned studies. When screening five experimental agents, our results suggest that platform designs have the potential to reduce the mean total sample size by as much as 40{\%} and boost the mean overall response rate by as much as 15{\%}. We explain how to design and conduct platform designs to achieve the aforementioned aims and preserve desirable frequentist properties for the treatment comparisons. In addition, we demonstrate how to conduct a platform design using look-up tables that can be generated in advance of the study. The gains in efficiency facilitated by platform design could prove to be consequential in oncologic settings, wherein trials often lack a proper control, and drug development suffers from low enrollment, long inter-trial latency periods, and an unacceptably high rate of failure in phase III.},
author = {Hobbs, Brian P. and Chen, Nan and Lee, J. Jack},
doi = {10.1177/0962280215620696},
issn = {14770334},
journal = {Statistical Methods in Medical Research},
keywords = {Bayesian analysis,Multi-arm controlled clinical trial design,Multiple comparisons,Predictive probability,Sequential design},
number = {1},
pages = {65--78},
pmid = {26763586},
title = {{Controlled multi-arm platform design using predictive probability}},
volume = {27},
year = {2018}
}
@article{Wei:1988if,
author = {Wei, L J and Lachin, John M},
journal = {Controlled Clinical Trials},
month = {dec},
number = {4},
pages = {345--364},
title = {{Properties of the urn randomization in clinical trials}},
volume = {9},
year = {1988}
}
@article{Ma2020,
abstract = {Covariate-adaptive randomization (CAR) procedures are frequently used in comparative studies to increase the covariate balance across treatment groups. However, because randomization inevitably uses the covariate information when forming balanced treatment groups, the validity of classical statistical methods after such randomization is often unclear. In this article, we derive the theoretical properties of statistical methods based on general CAR under the linear model framework. More importantly, we explicitly unveil the relationship between covariate-adaptive and inference properties by deriving the asymptotic representations of the corresponding estimators. We apply the proposed general theory to various randomization procedures such as complete randomization, rerandomization, pairwise sequential randomization, and Atkinson's DA-biased coin design and compare their performance analytically. Based on the theoretical results, we then propose a new approach to obtain valid and more powerful tests. These results open a door to understand and analyze experiments based on CAR. Simulation studies provide further evidence of the advantages of the proposed framework and the theoretical results. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {1807.09678},
author = {Ma, Wei and Qin, Yichen and Li, Yang and Hu, Feifang},
doi = {10.1080/01621459.2019.1635483},
eprint = {1807.09678},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Rosenberger, Uschner, Wang - 2019 - Randomization The forgotten component of the randomized clinical trial.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Asymptotic normality,Balancing covariates,Conservative tests,Power,Sequential analysis},
number = {531},
pages = {1488--1497},
publisher = {Taylor {\&} Francis},
title = {{Statistical Inference for Covariate-Adaptive Randomization Procedures}},
url = {https://doi.org/10.1080/01621459.2019.1635483},
volume = {115},
year = {2020}
}
@article{Sanderson:2013cw,
author = {Sanderson, Jean and Thompson, Simon G and White, Ian R and Aspelund, Thor and Pennells, Lisa},
journal = {BMC Medical Research Methodology},
month = {sep},
number = {1},
pages = {1},
title = {{Derivation and assessment of risk prediction models using case-cohort data}},
volume = {13},
year = {2013}
}
@article{proschan2009sample,
author = {Proschan, Michael A},
journal = {Biometrical Journal: Journal of Mathematical Methods in Biosciences},
number = {2},
pages = {348--357},
publisher = {Wiley Online Library},
title = {{Sample size re-estimation in clinical trials}},
volume = {51},
year = {2009}
}
@article{Anonymous:HZkTF-Qr,
title = {{Selected Writings (Values in a Universe of Chance)}},
year = {1966}
}
@book{Anonymous:2011wi,
publisher = {Elsevier},
title = {{Acute Coronary Syndromes: A Companion to Braunwald's Heart Disease}},
year = {2011}
}
@article{thall1994practical,
annote = {Decision rule:
Efficacy: P ( effect {\textgreater} 0 ) {\textgreater}= pU
Curtailment: P ( effect {\textgreater} delta{\_}0) {\textless}= pL

pU might be 0.95 - 0.99
pL might be 0.01 - 0.05

Bayesian decision rules, evaluate design under fixed values (i.e. Frequentist)

Flat Prior yields greatest chance of inconclusive

Could generate data under fixed effect or under prior; key is to assume exchangeability so there is no drift

Suggest possibiliity to include predictive probability as early termination rule},
author = {Thall, Peter F and Simon, Richard},
file = {::},
journal = {Biometrics},
pages = {337--349},
publisher = {JSTOR},
title = {{Practical Bayesian guidelines for phase IIB clinical trials}},
year = {1994}
}
@article{Lu:2011bo,
author = {Lu, Bo and Greevy, Robert and Xu, Xinyi and Beck, Cole},
journal = {The American statistician},
month = {feb},
number = {1},
pages = {21--30},
title = {{Optimal Nonbipartite Matching and Its Statistical Applications}},
volume = {65},
year = {2011}
}
@article{Steyerberg:2011gu,
author = {Steyerberg, Ewout W and Pencina, Michael J and Lingsma, Hester F and Kattan, Michael W and Vickers, Andrew J and {Van Calster}, Ben},
journal = {European Journal of Clinical Investigation},
month = {jul},
number = {2},
pages = {216--228},
title = {{Assessing the incremental value of diagnostic and prognostic markers: a review and illustration}},
volume = {42},
year = {2011}
}
@article{freidlin2013,
author = {Freidlin, Boris and Korn, Edward L.},
doi = {10.1200/JCO.2012.45.0254},
file = {::},
issn = {0732183X},
journal = {Journal of Clinical Oncology},
number = {7},
pages = {969--970},
pmid = {23341515},
title = {{Adaptive randomization versus interim monitoring}},
volume = {31},
year = {2013}
}
@article{Zhao2016,
author = {Zhao, Wenle},
journal = {Statistics in medicine},
number = {10},
pages = {1736--1738},
publisher = {Wiley Online Library},
title = {{A better alternative to the inferior permuted block design is not necessarily complex}},
volume = {35},
year = {2016}
}
@article{meier1979terminating,
author = {Meier, Paul},
journal = {Clinical Pharmacology {\&} Therapeutics},
number = {5part2},
pages = {633--640},
publisher = {Wiley Online Library},
title = {{Terminating a trial—the ethical problem}},
volume = {25},
year = {1979}
}
@misc{Schneiderwind2020,
abstract = {Across STEM fields, the education system continues to “weed out” students from non-dominant communities. Most studies on the damaging effects of underrepresentation focus on minorities or -women in STEM fields. We examine some of the research about students with disabilities and note the limited literature on this subject. University enrollment by students with disabilities has increased in the last two decades while the amount of corresponding research published has decreased. This issue should not be siloed to disability studies- it is one that must be recognized by all educators. We conclude with some practical suggestions on how to move forward.},
author = {Schneiderwind, Joseph and Johnson, Janelle M.},
booktitle = {Journal of Higher Education Theory and Practice},
doi = {10.33423/jhetp.v20i14.3854},
issn = {21583595},
keywords = {Differentiation,Disability,Disproportionality,Equity,Inclusion,STEM,Tracking},
number = {14},
pages = {101--104},
title = {{Disability and invisibility in STEM education}},
volume = {20},
year = {2020}
}
@article{Parmigiani:2007to,
author = {Parmigiani, Giovanni},
journal = {Annals of Internal Medicine},
month = {oct},
number = {7},
pages = {441},
title = {{Validity of Models for Predicting BRCA1 and BRCA2 Mutations}},
volume = {147},
year = {2007}
}
@article{RN2,
author = {Beland, L P and Brodeur, A and Wright, T},
doi = {10.1371/journal.pone.0270341},
issn = {1932-6203 (Electronic) 1932-6203 (Linking)},
journal = {PLoS One},
keywords = {United States/epidemiology Humans *COVID-19/epidem},
number = {3},
pages = {e0270341},
title = {{The short-term economic consequences of COVID-19: Exposure to disease, remote work and government response}},
type = {Journal Article},
url = {https://www.ncbi.nlm.nih.gov/pubmed/36920940},
volume = {18},
year = {2023}
}
@article{Berger:2005ip,
author = {Berger, Vance W},
journal = {Biometrical Journal},
month = {apr},
number = {2},
pages = {119--127},
title = {{Quantifying the Magnitude of Baseline Covariate Imbalances Resulting from Selection Bias in Randomized Clinical Trials}},
volume = {47},
year = {2005}
}
@article{Hong2006,
abstract = {This article considers the policy of retaining low-achieving children in kindergarten rather than promoting them to first grade. Under the stable unit treatment value assumption (SUTVA) as articulated by Rubin, each child at risk of retention has two potential outcomes: Y(1) if retained and Y(0) if promoted. But SUTVA is questionable, because a child's potential outcomes will plausibly depend on which school that child attends and also on treatment assignments of other children. We develop a causal model that allows school assignment and peer treatments to affect potential outcomes. We impose an identifying assumption that peer effects can be summarized through a scalar function of the vector of treatment assignments in a school. Using a large, nationally representative sample, we then estimate (1) the effect of being retained in kindergarten rather than being promoted to the first grade in schools having a low retention rate, (2) the retention effect in schools having a high retention rate, and (3) the effect of being promoted in a low-retention school as compared to being promoted in a high-retention school. This third effect is not definable under SUTVA. We use multilevel propensity score stratification to approximate a two-stage experiment. At the first stage, intact schools are blocked on covariates and then, within blocks, randomly assigned to a policy of retaining comparatively more or fewer children in kindergarten. At the second stage, "at-risk" students within schools are blocked on covariates and then assigned at random to be retained. We find evidence that retainees learned less on average than did similar children who were promoted, a result found in both high-retention and low-retention schools. We do not detect a peer treatment effect on low-risk students. {\textcopyright} 2006 American Statistical Association.},
annote = {Causal inference for hierarchal structure to address SUTVA

Is there a benefit to retaining students in kindergarden?

Each individual's potential outcome (PO) may be affected by whether other students advanced or were retained. Ex: teacher may have to adjust classroom for struggling students. ... This creates 1xN potential outcomes.

Solution is to reduce to school-level scalar of whether school is high performing or not. Now 4 potential outcomes.

Assumes:

1) Intact schools - students are randomized to schools, hence we can only generalize to the set of schools studied. Each school is a reflection of its own set of demographics

2) No interference b/w schools

3) Strong ignorability of treatment assignments which occurs at 2 levels -- between students and between schools.


The scalar requires thinking of sub-populations for whom the effect may be estimated.

Issue: Causal estimand is not estimable for all students. Example, the propensity of retention is not etimable among schools with a low retention rate. Can only do conditional causal estimates.

Fit mulitlevel propensity accounting for schools and student covariates. Used PS stratification for estimation.

Good example of setting up the study under a theoretical randomized trial},
author = {Hong, Guanglei and Raudenbush, Stephen W.},
doi = {10.1198/016214506000000447},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Grade retention,Multilevel design,Potential outcomes,Propensity score,Stable unit treatment value assumption},
number = {475},
pages = {901--910},
title = {{Evaluating kindergarten retention policy: A case study of causal inference for multilevel observational data}},
volume = {101},
year = {2006}
}
@article{Efron:1971ih,
author = {Efron, Bradley},
journal = {Biometrika},
number = {3},
pages = {403--417},
title = {{Forcing a sequential experiment to be balanced}},
volume = {58},
year = {1971}
}
@article{Presley:2018ew,
author = {Presley, Caroline A and Min, Jea Young and Chipman, Jonathan and Greevy, Robert A and Grijalva, Carlos G and Griffin, Marie R and Roumie, Christianne L},
journal = {BMJ open},
month = {mar},
number = {3},
pages = {e020455},
title = {{Validation of an algorithm to identify heart failure hospitalisations in patients with diabetes within the veterans health administration.}},
volume = {8},
year = {2018}
}
@article{Ball:2011et,
author = {Ball, Greg and Piller, Linda B},
journal = {Contemporary Clinical Trials},
month = {sep},
pages = {S5----7},
title = {{Continuous safety monitoring for randomized controlled clinical trials with blinded treatment information. Part 2: Statistical considerations.}},
volume = {32 Suppl 1},
year = {2011}
}
@article{DAgostinoJr:2000js,
author = {{D'Agostino Jr.}, Ralph B and Rubin, Donald B},
journal = {Journal of the American Statistical Association},
month = {sep},
number = {451},
pages = {749--759},
title = {{Estimating and Using Propensity Scores with Partially Missing Data}},
volume = {95},
year = {2000}
}
@article{Saville2016,
abstract = {Background: A "platform trial" is a clinical trial with a single master protocol in which multiple treatments are evaluated simultaneously. Adaptive platform designs offer flexible features such as dropping treatments for futility, declaring one or more treatments superior, or adding new treatments to be tested during the course of a trial. Methods: A simulation study explores the efficiencies of various platform trial designs relative to a traditional two-arm strategy. Results: Platform trials can find beneficial treatments with fewer patients, fewer patient failures, less time, and with greater probability of success than a traditional two-arm strategy. Conclusion: In an era of personalized medicine, platform trials provide the innovation needed to efficiently evaluate modern treatments.},
author = {Saville, Benjamin R. and Berry, Scott M.},
doi = {10.1177/1740774515626362},
file = {::},
isbn = {1740774515},
issn = {17407753},
journal = {Clinical Trials},
keywords = {Bayesian,Platform trial,adaptive,clinical trial design,master protocol,multi-arm},
number = {3},
pages = {358--366},
pmid = {26908536},
title = {{Efficiencies of platform clinical trials: A vision of the future}},
volume = {13},
year = {2016}
}
@article{bhatt2013effect,
author = {Bhatt, Deepak L and Stone, Gregg W and Mahaffey, Kenneth W and Gibson, C Michael and Steg, P Gabriel and Hamm, Christian W and Price, Matthew J and Leonardi, Sergio and Gallup, Dianne and Bramucci, Ezio and Others},
journal = {New England Journal of Medicine},
number = {14},
pages = {1303--1313},
publisher = {Mass Medical Soc},
title = {{Effect of platelet inhibition with cangrelor during PCI on ischemic events}},
volume = {368},
year = {2013}
}
@article{hsiao2019optimal,
author = {Hsiao, Samuel T and Liu, Lingyun and Mehta, Cyrus R},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Hsiao, Liu, Mehta - 2019 - Optimal promising zone designs.pdf:pdf},
journal = {Biometrical Journal},
number = {5},
pages = {1175--1186},
publisher = {Wiley Online Library},
title = {{Optimal promising zone designs}},
volume = {61},
year = {2019}
}
@article{little1996pattern,
author = {Little, Roderick J A and Wang, Yongxiao},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Little, Wang - 1996 - Pattern-mixture models for multivariate incomplete data with covariates(2).pdf:pdf},
journal = {Biometrics},
pages = {98--111},
publisher = {JSTOR},
title = {{Pattern-mixture models for multivariate incomplete data with covariates}},
year = {1996}
}
@article{Anonymous:hzrDA_nE,
month = {jan},
pages = {1--9},
title = {{Neyman 1923}},
year = {2006}
}
@article{Ryan2020,
abstract = {Background: Bayesian adaptive methods are increasingly being used to design clinical trials and offer several advantages over traditional approaches. Decisions at analysis points are usually based on the posterior distribution of the treatment effect. However, there is some confusion as to whether control of type I error is required for Bayesian designs as this is a frequentist concept. Methods: We discuss the arguments for and against adjusting for multiplicities in Bayesian trials with interim analyses. With two case studies we illustrate the effect of including interim analyses on type I/II error rates in Bayesian clinical trials where no adjustments for multiplicities are made. We propose several approaches to control type I error, and also alternative methods for decision-making in Bayesian clinical trials. Results: In both case studies we demonstrated that the type I error was inflated in the Bayesian adaptive designs through incorporation of interim analyses that allowed early stopping for efficacy and without adjustments to account for multiplicity. Incorporation of early stopping for efficacy also increased the power in some instances. An increase in the number of interim analyses that only allowed early stopping for futility decreased the type I error, but also decreased power. An increase in the number of interim analyses that allowed for either early stopping for efficacy or futility generally increased type I error and decreased power. Conclusions: Currently, regulators require demonstration of control of type I error for both frequentist and Bayesian adaptive designs, particularly for late-phase trials. To demonstrate control of type I error in Bayesian adaptive designs, adjustments to the stopping boundaries are usually required for designs that allow for early stopping for efficacy as the number of analyses increase. If the designs only allow for early stopping for futility then adjustments to the stopping boundaries are not needed to control type I error. If one instead uses a strict Bayesian approach, which is currently more accepted in the design and analysis of exploratory trials, then type I errors could be ignored and the designs could instead focus on the posterior probabilities of treatment effects of clinically-relevant values.},
author = {Ryan, Elizabeth G. and Brock, Kristian and Gates, Simon and Slade, Daniel},
doi = {10.1186/s12874-020-01042-7},
file = {::},
issn = {14712288},
journal = {BMC Medical Research Methodology},
keywords = {Adaptive design,Bayesian,Interim analysis,Multiple comparisons,Multiplicities,Randomised controlled trial,Type I error},
number = {1},
pages = {1--9},
pmid = {32522284},
publisher = {BMC Medical Research Methodology},
title = {{Do we need to adjust for interim analyses in a Bayesian adaptive trial design?}},
volume = {20},
year = {2020}
}
@article{whitehead1983group,
author = {Whitehead, John and Stratton, Irene},
file = {::},
journal = {Biometrics},
pages = {227--236},
publisher = {JSTOR},
title = {{Group sequential clinical trials with triangular continuation regions}},
year = {1983}
}
@article{Li:2014bs,
author = {Li, Rongxia and Stewart, Brock and Weintraub, Eric and McNeil, Michael M},
journal = {Statistics in medicine},
month = {aug},
number = {19},
pages = {3387--3397},
title = {{Continuous sequential boundaries for vaccine safety surveillance.}},
volume = {33},
year = {2014}
}
@article{Blume:2005vj,
author = {Blume, Jeffrey D},
journal = {International Statistical Review},
month = {dec},
number = {3},
pages = {351--363},
title = {{How to Choose a Working Model for Measuring the Statistical Evidence About a Regression Parameter}},
volume = {73},
year = {2006}
}
@article{Togo2013,
abstract = {In clinical trials, interim analyses are often performed before the completion of the trial. The intention is to possibly terminate the trial early or adjust the sample size. The time of conducting an interim analysis affects the probability of the early termination and the number of subjects enrolled until the interim analysis. This influences the expected total number of subjects. In this study, we examine the optimal time for conducting interim analyses with a view to minimizing the expected total sample size. It is found that regardless of the effect size, the optimal time of one interim analysis for the early termination is approximately two-thirds of the planned observations for the O'Brien-Fleming type of spending function and approximately half of the planned observations for the Pocock type when the subject enrollment is halted for the interim analysis. When the subject enrollment is continuous throughout the trial, the optimal time for the interim analysis varies according to the follow-up duration. We also consider the time for one interim analysis including the sample size adjustment in terms of minimizing the expected total sample size. {\textcopyright} Taylor and Francis Group, LLC.},
author = {Togo, Kanae and Iwasaki, Manabu},
doi = {10.1080/10543406.2013.813522},
file = {::},
issn = {10543406},
journal = {Journal of Biopharmaceutical Statistics},
keywords = {Average sample number,Group sequential design,Interim analysis,Sample size,Subject enrollment},
number = {5},
pages = {1067--1080},
pmid = {23957516},
title = {{Optimal timing for interim analyses in clinical trials}},
volume = {23},
year = {2013}
}
@article{Yan2017,
abstract = {The primary objective of phase I oncology trials is to find the MTD. The 3 + 3 design is easy to implement but performs poorly in finding the MTD. A newer design, such as the modified toxicity probability interval (mTPI) design, provides better accuracy to identify the MTD but tends to overdose patients. We propose the keyboard design, an intuitive Bayesian design that conducts dose escalation and de-escalation based on whether the strongest key, defined as the dosing interval that most likely contains the current dose, is below or above the target dosing interval. The keyboard design can be implemented in a simple way, similar to the traditional 3 þ 3 design, but provides more flexibility for choosing the target toxicity rate and cohort size. Our simulation studies demonstrate that compared with the 3 + 3 design, the keyboard design has favorable operating characteristics in terms of identifying the MTD. Compared with the mTPI design, the keyboard design is safer, with a substantially lower risk of treating patients at overly toxic doses, and has the better precision to identify the MTD, thereby providing a useful upgrade to the mTPI design. Software freely available at http:// www.trialdesign.org facilitates the application of the keyboard design.},
author = {Yan, Fangrong and Mandrekar, Sumithra J. and Yuan, Ying},
doi = {10.1158/1078-0432.CCR-17-0220},
file = {::},
issn = {15573265},
journal = {Clinical Cancer Research},
number = {15},
pages = {3994--4003},
pmid = {28546227},
title = {{Keyboard: A novel Bayesian toxicity probability interval design for phase I clinical trials}},
volume = {23},
year = {2017}
}
@article{Shalet:2003jl,
author = {Shalet, Stephen M and Shavrikova, Elena and Cromer, Morris and Child, Christopher J and Keller, Eberhard and Zapletalova, Jirina and Moshang, Thomas and Blum, Werner F and Chipman, John J and Quigley, Charmian A and Attanasio, Andrea F},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {sep},
number = {9},
pages = {4124--4129},
title = {{Effect of Growth Hormone (GH) Treatment on Bone in Postpubertal GH-Deficient Patients: A 2-Year Randomized, Controlled, Dose-Ranging Study}},
volume = {88},
year = {2003}
}
@misc{pdufa_vi,
title = {{PDUFA VI: Fiscal Years 2018 - 2022 | FDA}},
url = {https://www.fda.gov/industry/prescription-drug-user-fee-amendments/pdufa-vi-fiscal-years-2018-2022}
}
@article{Guo:2014dm,
author = {Guo, Beibei and Li, Yisheng},
journal = {BMC Medical Research Methodology},
month = {jul},
number = {1},
pages = {95},
title = {{Bayesian designs of phase II oncology trials to select maximum effective dose assuming monotonic dose-response relationship.}},
volume = {14},
year = {2014}
}
@article{Pocock:1975wd,
author = {Pocock, Stuart J and Simon, Richard},
journal = {Biometrics},
month = {mar},
number = {1},
pages = {103--115},
title = {{Sequential Treatment Assignment with Balancing for Prognostic Factors in the Controlled Clinical Trial}},
volume = {31},
year = {1975}
}
@article{Silber:2016gm,
author = {Silber, Jeffrey H and Cnaan, Avital and Clark, Bernard J and Paridon, Stephen M and Chin, Alvin J and Rychik, Jack and Hogarty, Alexa N and Cohen, Mitchell I and Barber, Gerald and Rutkowski, Monika and Kimball, Thomas R and Delaat, Cynthia and Steinherz, Laurel J and Zhao, Huaqing},
journal = {Journal of Clinical Oncology},
month = {sep},
number = {5},
pages = {820--828},
title = {{Enalapril to Prevent Cardiac Function Decline in Long-Term Survivors of Pediatric Cancer Exposed to Anthracyclines}},
volume = {22},
year = {2016}
}
@article{Hasin2017,
abstract = {High-throughput technologies have revolutionized medical research. The advent of genotyping arrays enabled large-scale genome-wide association studies and methods for examining global transcript levels, which gave rise to the field of "integrative genetics". Other omics technologies, such as proteomics and metabolomics, are now often incorporated into the everyday methodology of biological researchers. In this review, we provide an overview of such omics technologies and focus on methods for their integration across multiple omics layers. As compared to studies of a single omics type, multi-omics offers the opportunity to understand the flow of information that underlies disease.},
author = {Hasin, Yehudit and Seldin, Marcus and Lusis, Aldons},
doi = {10.1186/s13059-017-1215-1},
isbn = {1305901712151},
issn = {1474760X},
journal = {Genome Biology},
number = {1},
pages = {1--15},
pmid = {28476144},
publisher = {Genome Biology},
title = {{Multi-omics approaches to disease}},
volume = {18},
year = {2017}
}
@article{PhD:2016ej,
author = {Gamble, John-Michael and Chibrikov, Eugene and Twells, Laurie K and Midodzi, William K and Young, Stephanie W and MacDonald, Don and Majumdar, Sumit R},
journal = {THE LANCET Diabetes {\&} Endocrinology},
month = {jan},
number = {1},
pages = {43--52},
title = {{Association of insulin dosage with mortality or major adverse cardiovascular events: a retrospective cohort study}},
volume = {5},
year = {2017}
}
@article{Wu2020,
abstract = {In developing products for rare diseases, statistical challenges arise due to the limited number of patients available for participation in drug trials and other clinical research. Bayesian adaptive clinical trial designs offer the possibility of increased statistical efficiency, reduced development cost and ethical hazard prevention via their incorporation of evidence from external sources (historical data, expert opinions, and real-world evidence), and flexibility in the specification of interim looks. In this paper, we propose a novel Bayesian adaptive commensurate design that borrows adaptively from historical information and also uses a particular payoff function to optimize the timing of the study's interim analysis. The trial payoff is a function of how many samples can be saved via early stopping and the probability of making correct early decisions for either futility or efficacy. We calibrate our Bayesian algorithm to have acceptable long-run frequentist properties (Type I error and power) via simulation at the design stage. We illustrate our approach using a pediatric trial design setting testing the effect of a new drug for a rare genetic disease. The optimIA R package available at https://github.com/wxwx1993/Bayesian{\_}IA{\_}Timing provides an easy-to-use implementation of our approach.},
author = {Wu, Xiao and Xu, Yi and Carlin, Bradley P.},
doi = {10.1002/sim.8414},
file = {::},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Bayesian adaptive design,historical data,interim analysis,rare disease,stopping rule},
number = {4},
pages = {424--437},
pmid = {31799737},
title = {{Optimizing interim analysis timing for Bayesian adaptive commensurate designs}},
volume = {39},
year = {2020}
}
@book{LeylandJones:2003kt,
author = {Leyland-Jones, B},
publisher = {The lancet oncology},
title = {{Breast cancer trial with erythropoietin terminated unexpectedly}},
year = {2003}
}
@article{ariel2018inhaled,
author = {Ariel, Amnon and Altraja, Alan and Belevskiy, Andrey and Boros, Piotr W and Danila, Edvardas and Fle{\v{z}}ar, Matjaz and Koblizek, Vladimir and Fridlender, Zvi G and Kostov, Kosta and Krams, Alvils and Others},
journal = {International journal of chronic obstructive pulmonary disease},
pages = {45},
publisher = {Dove Press},
title = {{Inhaled therapies in patients with moderate COPD in clinical practice: current thinking}},
volume = {13},
year = {2018}
}
@article{Gerds:2008ca,
author = {Gerds, Thomas A and Cai, Tianxi and Schumacher, Martin},
journal = {Biometrical Journal},
month = {aug},
number = {4},
pages = {457--479},
title = {{The Performance of Risk Prediction Models}},
volume = {50},
year = {2008}
}
@article{Raudenbush2020,
abstract = {Education research has experienced a methodological renaissance over the past two decades, with a new focus on large-scale randomized experiments. This wave of experiments has made education research an even more exciting area for statisticians, unearthing many lessons and challenges in experimental design, causal inference, and statistics more broadly. Importantly, educational research and practice almost always occur in a multilevel setting, which makes the statistics relevant to other fields with this structure, including social policy, health services research, and clinical trials in medicine. In this article we first briefly review the history that led to this new era in education research and describe the design features that dominate the modern large-scale educational experiments. We then highlight some of the key statistical challenges in this area, including endogeneity of design, heterogeneity of treatment effects, noncompliance with treatment assignment, mediation, generalizability, and spillover. Though a secondary focus, we also touch on promising trial designs that answer more nuanced questions, such as the SMART design for studying dynamic treatment regimes and factorial designs for optimizing the components of an existing treatment.},
author = {Raudenbush, Stephen W. and Schwartz, Daniel},
doi = {10.1146/annurev-statistics-031219-041205},
issn = {2326831X},
journal = {Annual Review of Statistics and Its Application},
keywords = {causal inference,educational statistics,experimental design,heterogeneous treatment effects,hierarchical linear models,multilevel data},
pages = {177--208},
title = {{Randomized experiments in education, with implications for multilevel causal inference}},
volume = {7},
year = {2020}
}
@article{Pencina:2016fm,
author = {Pencina, Michael J and Fine, Jason P and D'Agostino, Ralph B},
journal = {Statistics in medicine},
month = {jan},
number = {4},
pages = {132},
title = {{Discrimination slope and integrated discrimination improvement {\{}$\backslash$textendash{\}} properties, relationships and impact of calibration}},
volume = {30},
year = {2016}
}
@article{Yang:ty,
author = {Yang, D and Forum, J E Dalton S A S Global and 2012},
journal = {lerner.ccf.org},
title = {{A unified approach to measuring the effect size between two groups using SAS{\textregistered}}}
}
@article{Hill:1952hc,
annote = {doi: 10.1056/NEJM195207242470401},
author = {Hill, A Bradford},
journal = {New England Journal of Medicine},
month = {jul},
number = {4},
pages = {113--119},
title = {{The Clinical Trial}},
volume = {247},
year = {1952}
}
@article{Loux:2014bu,
author = {Loux, Travis M},
journal = {Statistics in medicine},
month = {nov},
number = {4},
pages = {558--570},
title = {{Randomization, matching, and propensity scores in the design and analysis of experimental studies with measured baseline covariates}},
volume = {34},
year = {2014}
}
@article{Engel2015breast,
abstract = {BRCA1/2 mutation carriers have a considerably increased risk to develop breast and ovarian cancer. The personalized clinical management of carriers and other at-risk individuals depends on precise knowledge of the cancer risks. In this report, we give an overview of the present literature on empirical cancer risks, and we describe risk prediction models that are currently used for individual risk assessment in clinical practice. Cancer risks show large variability between studies. Breast cancer risks are at 40-87{\%} for BRCA1 mutation carriers and 18-88{\%} for BRCA2 mutation carriers. For ovarian cancer, the risk estimates are in the range of 22-65{\%} for BRCA1 and 10-35{\%} for BRCA2. The contralateral breast cancer risk is high (10-year risk after first cancer 27{\%} for BRCA1 and 19{\%} for BRCA2). Risk prediction models have been proposed to provide more individualized risk prediction, using additional knowledge on family history, mode of inheritance of major genes, and other genetic and non-genetic risk factors. User-friendly software tools have been developed that serve as basis for decision-making in family counseling units. In conclusion, further assessment of cancer risks and model validation is needed, ideally based on prospective cohort studies. To obtain such data, clinical management of carriers and other at-risk individuals should always be accompanied by standardized scientific documentation.},
author = {Engel, Christoph and Fischer, Christine},
doi = {10.1159/000376600},
file = {::},
issn = {16613805},
journal = {Breast Care},
keywords = {Breast cancer,Hereditary cancer risk,Ovarian cancer,Risk prediction models},
number = {1},
pages = {7--12},
title = {{Breast cancer risks and risk prediction models}},
volume = {10},
year = {2015}
}
@article{Middleton2015,
abstract = {Many estimators of the average treatment effect, including the difference-in-means, may be biased when clusters of units are allocated to treatment. This bias remains even when the number of units within each cluster grows asymptotically large. In this paper, we propose simple, unbiased, location-invariant, and covariate-adjusted estimators of the average treatment effect in experiments with random allocation of clusters, along with associated variance estimators. We then analyze a cluster-randomized field experiment on voter mobilization in the US, demonstrating that the proposed estimators have precision that is comparable, if not superior, to that of existing, biased estimators of the average treatment effect.},
author = {Middleton, Joel A. and Aronow, Peter M.},
doi = {10.1515/spp-2013-0002},
issn = {2194-6299},
journal = {Statistics, Politics and Policy},
number = {1-2},
pages = {39--75},
title = {{Unbiased Estimation of the Average Treatment Effect in Cluster-Randomized Experiments}},
volume = {6},
year = {2015}
}
@article{Stern:2011bn,
author = {Stern, R H},
journal = {American Journal of Epidemiology},
month = {mar},
number = {6},
pages = {714},
title = {{Re: "Improvement of Risk Prediction by Genomic Profiling: Reclassification Measures Versus the Area Under the Receiver Operating Characteristic Curve"}},
volume = {173},
year = {2011}
}
@article{Pencina:2012iw,
author = {Pencina, M J and D'Agostino, R B and Demler, O V and Janssens, A C J W and Greenland, P},
journal = {American Journal of Epidemiology},
month = {sep},
number = {6},
pages = {492--494},
title = {{Pencina et al. Respond to "The Incremental Value of New Markers" and "Clinically Relevant Measures? A Note of Caution"}},
volume = {176},
year = {2012}
}
@book{Harrell:1990uq,
author = {Harrell, F E and Lee, K L},
publisher = {Division of Biometry},
title = {{Using logistic model calibration to assess the quality of probability predictions}},
year = {1990}
}
@article{Kirby:1999kl,
author = {Kirby, Simon D and Danter, Wayne and George, Charles F P and Francovic, Tanya and Ferguson, Kathleen A and Eng, P and Ruby, Ralph R F},
journal = {Chest},
month = {aug},
number = {2},
pages = {409--415},
title = {{Neural Network Prediction of Obstructive Sleep Apnea From Clinical Criteria}},
volume = {116},
year = {1999}
}
@article{Rubin1998,
abstract = {Standard randomization-based tests of sharp null hypotheses in randomized clinical trials, that is, intent-to-treat analyses, are valid without extraneous assumptions, but generally can be appropriately powerful only with alternative hypotheses that involve treatment assignment having an effect on outcome. In the context of clinical trials with non-compliance, other alternative hypotheses can be more natural. In particular, when a trial is double-blind, it is often reasonable for the alternative hypothesis to exclude any effect of treatment assignment on outcome for a unit unless the assignment affected which treatment that unit actually received. Bayesian analysis under this alternative 'exclusion' hypothesis leads to new estimates of the effect of receipt of treatment, and to a new randomization-based procedure that has frequentist validity yet can be substantially more powerful than the standard intent-to-treat procedure. The key idea is to obtain a p-value using a posterior predictive check distribution, which includes a model for non-compliance behaviour, although only under the standard sharp null hypothesis of no effect of assignment (or receipt) of treatment on outcome. It is important to note that these new procedures are distinctly different from 'as treated' and 'per protocol' analyses, which are not only badly biased in general, but generally have very low power.},
annote = {Multiple imputation for randomization based inference and for clinical trial estimands

Focus is on comparing the ITT versus CACE complier average causal effect.

References for critics of model-based inference (Berger and Berry) and of novel solutions using advanced computing. Many of these critics have been influential at FDA.

References for improved RBI estimands.

Appeal of RBI is that it uses a finite sample for a probability calculation that is no approximated nor utilizes models.

Rubin acknowledges preference of a more bayesian approach yet focuses on RBI to show an improved alternative to ITT which accounts for compliance. This uses multiple imputation and averages p-values.

Missing data issues:
E-compliance status: whether a patient would adhere to E if assigned to E. Observed on a random half of patients.

C-compliance status: similar to E-compliance but for standard of care C.

E-compliance is predicted "in a distributional sense" for all subjects.

E-compliance model relates E-compliance with outcome Y and predicts missing E-compliances in those assigned to C. Example when Y is bernoulli: Pr ( E compliance | Y = 0 ) and Pr ( E Compliance | Y = 1 ).

The statistic S depends upon: i) randomization sequence, ii) hypothethical observed values of Y under null, and iii) imputed hypothetical E-compliance values.

The incpororatin of E-compliance into the test statistic depends upon estimand:

ITT: Does not rely upon E-compliance
As Treated: Yes
Per protocol: Yes
IVE instrumental variable estimator: ITT / observed proportion of E-compliers: Yes
CACE mle under distriubtional model: Yes
CACE posterior median: Yes
CACE posterior mean: Yes},
author = {Rubin, Donald B.},
doi = {10.1002/(SICI)1097-0258(19980215)17:3<371::AID-SIM768>3.0.CO;2-O},
issn = {02776715},
journal = {Statistics in Medicine},
number = {3},
pages = {371--385},
pmid = {9493260},
title = {{More powerful randomization-based p-values in double-blind trials with non-compliance}},
volume = {17},
year = {1998}
}
@article{Austin:2009fv,
author = {Austin, Peter C},
journal = {Medical Decision Making},
month = {dec},
number = {6},
pages = {661--677},
title = {{The Relative Ability of Different Propensity Score Methods to Balance Measured Covariates Between Treated and Untreated Subjects in Observational Studies}},
volume = {29},
year = {2009}
}
@article{Atkinson:1982kt,
author = {Atkinson, A C},
journal = {Biometrika},
month = {apr},
number = {1},
pages = {61},
title = {{Optimum Biased Coin Designs for Sequential Clinical Trials with Prognostic factors}},
volume = {69},
year = {1982}
}
@article{RN8,
author = {Wu, Y P and Aspinwall, L G and Conn, B M and Stump, T and Grahmann, B and Leachman, S A},
doi = {10.1016/j.ypmed.2016.04.010},
issn = {0091-7435},
journal = {Prev Med},
keywords = {High-risk Intervention Melanoma Prevention Review},
pages = {153--167},
title = {{A systematic review of interventions to improve adherence to melanoma preventive behaviors for individuals at elevated risk}},
type = {Journal Article},
volume = {88},
year = {2016}
}
@article{Pocock:1995eh,
author = {Pocock, Stuart J},
journal = {Statistics in medicine},
month = {jan},
number = {2},
pages = {209--222},
title = {{Life as an academic medical statistician and how to survive it}},
volume = {14},
year = {1995}
}
@article{VanDerWeele2017,
abstract = {Sensitivity analysis is useful in assessing how robust an association is to potential unmeasured or uncontrolled confounding. This article introduces a new measure called the "E-value," which is related to the evidence for causality in observational studies that are potentially subject to confounding. The E-value is defined as the minimum strength of association, on the risk ratio scale, that an unmeasured confounder would need to have with both the treatment and the outcome to fully explain away a specific treatment-outcome association, conditional on the measured covariates. A large E-value implies that considerable unmeasured confounding would be needed to explain away an effect estimate. A small E-value implies little unmeasured confounding would be needed to explain away an effect estimate. The authors propose that in all observational studies intended to produce evidence for causality, the E-value be reported or some other sensitivity analysis be used. They suggest calculating the E-value for both the observed association estimate (after adjustments for measured confounders) and the limit of the confidence interval closest to the null. If this were to become standard practice, the ability of the scientific community to assess evidence from observational studies would improve considerably, and ultimately, science would be strengthened.},
author = {{Van Der Weele}, Tyler J. and Ding, Peng},
doi = {10.7326/M16-2607},
issn = {15393704},
journal = {Annals of Internal Medicine},
number = {4},
pages = {268--274},
pmid = {28693043},
title = {{Sensitivity analysis in observational research: Introducing the E-Value}},
volume = {167},
year = {2017}
}
@article{Perez2008,
abstract = {Purpose: To assess cardiac safety and potential cardiac risk factors associated with trastuzumab in the NCCTG N9831 Intergroup adjuvant breast cancer trial. Patients and Methods: Patients with HER2-positive operable breast cancer were randomly assigned to doxorubicin plus cyclophosphamide (AC) followed by either weekly paclitaxel (arm A); paclitaxel then trastuzumab (arm B); or paclitaxel plus trastuzumab then trastuzumab alone (arm C). Left ventricular ejection fraction (LVEF) was evaluated at registration and 3, 6, 9, and 18 to 21 months. Results: Of 2,992 patients completing AC, 5.0{\%} had LVEF decreases disallowing trastuzumab (decrease below normal: 2.4{\%}, decrease {\textgreater} 15{\%}: 2.6{\%}). There were 1,944 patients with satisfactory or no LVEF evaluation who proceeded to post-AC therapy. Cardiac events (congestive heart failure [CHF] or cardiac death [CD]): arm A, n = 3 (2 CHF, 1 CD); arm B, n = 19 (18 CHF, 1 CD); arm C, n = 19 (all CHF); 3-year cumulative incidence: 0.3{\%}, 2.8{\%}, and 3.3{\%}, respectively. Cardiac function improved in most CHF cases following trastuzumab discontinuation and cardiac medication. Factors associated with increased risk of a cardiac event in arms B and C: older age (P {\textless} .003), prior/current antihypertensive agents (P = .005), and lower registration LVEF (P {\textless} .033). Incidence of asymptomatic LVEF decreases requiring holding trastuzumab was 8{\%} to 10{\%}; LVEF recovered and trastuzumab was restarted in approximately 50{\%}. Conclusion: The cumulative incidence of post-AC cardiac events at 3 years was higher in the trastuzumab-containing arms versus the control arm, but by less than 4{\%}. Older age, lower registration LVEF, and antihypertensive medications are associated with increased risk of cardiac dysfunction in patients receiving trastuzumab following AC. {\textcopyright} 2008 by American Society of Clinical Oncology.},
author = {Perez, Edith A. and Suman, Vera J. and Davidson, Nancy E. and Sledge, George W. and Kaufman, Peter A. and Hudis, Clifford A. and Martino, Silvana and Gralow, Julie R. and Dakhil, Shaker R. and Ingle, James N. and Winer, Eric P. and Gelmon, Karen A. and Gersh, Bernard J. and Jaffe, Allan S. and Rodeheffer, Richard J.},
doi = {10.1200/JCO.2007.13.5467},
file = {::},
issn = {0732183X},
journal = {Journal of Clinical Oncology},
number = {8},
pages = {1231--1238},
pmid = {18250349},
title = {{Cardiac safety analysis of doxorubicin and cyclophosphamide followed by paclitaxel with or without trastuzumab in the North Central Cancer Treatment Group N9831 adjuvant breast cancer trial}},
volume = {26},
year = {2008}
}
@article{hernandez2019effect,
abstract = {Importance: Abnormal peripheral perfusion after septic shock resuscitation has been associated with organ dysfunction and mortality. The potential role of the clinical assessment of peripheral perfusion as a target during resuscitation in early septic shock has not been established. Objective: To determine if a peripheral perfusion-targeted resuscitation during early septic shock in adults is more effective than a lactate level-targeted resuscitation for reducing mortality. Design, Setting, and Participants: Multicenter, randomized trial conducted at 28 intensive care units in 5 countries. Four-hundred twenty-four patients with septic shock were included between March 2017 and March 2018. The last date of follow-up was June 12, 2018. Interventions: Patients were randomized to a step-by-step resuscitation protocol aimed at either normalizing capillary refill time (n = 212) or normalizing or decreasing lactate levels at rates greater than 20{\%} per 2 hours (n = 212), during an 8-hour intervention period. Main Outcomes and Measures: The primary outcome was all-cause mortality at 28 days. Secondary outcomes were organ dysfunction at 72 hours after randomization, as assessed by Sequential Organ Failure Assessment (SOFA) score (range, 0 [best] to 24 [worst]); death within 90 days; mechanical ventilation-, renal replacement therapy-, and vasopressor-free days within 28 days; intensive care unit and hospital length of stay. Results: Among 424 patients randomized (mean age, 63 years; 226 [53{\%}] women), 416 (98{\%}) completed the trial. By day 28, 74 patients (34.9{\%}) in the peripheral perfusion group and 92 patients (43.4{\%}) in the lactate group had died (hazard ratio, 0.75 [95{\%} CI, 0.55 to 1.02]; P =.06; risk difference, -8.5{\%} [95{\%} CI, -18.2{\%} to 1.2{\%}]). Peripheral perfusion-targeted resuscitation was associated with less organ dysfunction at 72 hours (mean SOFA score, 5.6 [SD, 4.3] vs 6.6 [SD, 4.7]; mean difference, -1.00 [95{\%} CI, -1.97 to -0.02]; P =.045). There were no significant differences in the other 6 secondary outcomes. No protocol-related serious adverse reactions were confirmed. Conclusions and Relevance: Among patients with septic shock, a resuscitation strategy targeting normalization of capillary refill time, compared with a strategy targeting serum lactate levels, did not reduce all-cause 28-day mortality. Trial Registration: ClinicalTrials.gov Identifier: NCT03078712.},
author = {Hern{\'{a}}ndez, Glenn and Ospina-Tasc{\'{o}}n, Gustavo A. and Damiani, Lucas Petri and Estenssoro, Elisa and Dubin, Arnaldo and Hurtado, Javier and Friedman, Gilberto and Castro, Ricardo and Alegr{\'{i}}a, Leyla and Teboul, Jean Louis and Cecconi, Maurizio and Ferri, Giorgio and Jibaja, Manuel and Pairumani, Ronald and Fern{\'{a}}ndez, Paula and Barahona, Diego and Granda-Luna, Vladimir and Cavalcanti, Alexandre Biasi and Bakker, Jan},
doi = {10.1001/jama.2019.0071},
issn = {15383598},
journal = {JAMA - Journal of the American Medical Association},
number = {7},
pages = {654--664},
pmid = {30772908},
publisher = {American Medical Association},
title = {{Effect of a Resuscitation Strategy Targeting Peripheral Perfusion Status vs Serum Lactate Levels on 28-Day Mortality among Patients with Septic Shock: The ANDROMEDA-SHOCK Randomized Clinical Trial}},
volume = {321},
year = {2019}
}
@article{Lange:1985gp,
author = {Lange, Nicholas and MacIntyre, John},
journal = {Controlled Clinical Trials},
month = {mar},
number = {1},
pages = {38--50},
title = {{A computerized patient registration and treatment randomization system for multi-institutional clinical trials}},
volume = {6},
year = {1985}
}
@article{Roumie2019,
abstract = {Importance: Before 2016, safety concerns limited metformin use in patients with kidney disease; however, the effectiveness of metformin on clinical outcomes in patients with reduced kidney function remains unknown. Objective: To compare major adverse cardiovascular events (MACE) among patients with diabetes and reduced kidney function who continued treatment with metformin or a sulfonylurea. Design, Setting, and Participants: Retrospective cohort study of US veterans receiving care within the national Veterans Health Administration, with data supplemented by linkage to Medicare, Medicaid, and National Death Index data from 2001 through 2016. There were 174882 persistent new users of metformin and sulfonylureas who reached a reduced kidney function threshold (estimated glomerular filtration rate {\textless}60 mL/min/1.73 m2 or creatinine {\textgreater}/=1.4 mg/dL for women or {\textgreater}/=1.5 mg/dL for men). Patients were followed up from reduced kidney function threshold until MACE, treatment change, loss to follow-up, death, or study end (December 2016). Exposures: New users of metformin or sulfonylurea monotherapy who continued treatment with their glucose-lowering medication after reaching reduced kidney function. Main Outcomes and Measures: MACE included hospitalization for acute myocardial infarction, stroke, transient ischemic attack, or cardiovascular death. The analyses used propensity score weighting to compare the cause-specific hazard of MACE between treatments and estimate cumulative risk accounting for the competing risks of changing therapy or noncardiovascular death. Results: There were 67749 metformin and 28976 sulfonylurea persistent monotherapy users; the weighted cohort included 24679 metformin and 24799 sulfonylurea users (median age, 70 years [interquartile range {\{}IQR{\}}, 62.8-77.8]; 48497 men [98{\%}]; and 40476 white individuals [82{\%}], with median estimated glomerular filtration rate of 55.8 mL/min/1.73 m2 [IQR, 51.6-58.2] and hemoglobin A1c level of 6.6{\%} [IQR, 6.1{\%}-7.2{\%}] at cohort entry). During follow-up (median, 1.0 year for metformin vs 1.2 years for sulfonylurea), there were 1048 MACE outcomes (23.0 per 1000 person-years) among metformin users and 1394 events (29.2 per 1000 person-years) among sulfonylurea users. The cause-specific adjusted hazard ratio of MACE for metformin was 0.80 (95{\%} CI, 0.75-0.86) compared with sulfonylureas, yielding an adjusted rate difference of 5.8 (95{\%} CI, 4.1-7.3) fewer events per 1000 person-years of metformin use compared with sulfonylurea use. Conclusions and Relevance: Among patients with diabetes and reduced kidney function persisting with monotherapy, treatment with metformin, compared with a sulfonylurea, was associated with a lower risk of MACE.},
author = {Roumie, Christianne L and Chipman, Jonathan and Min, Jea Young and Hackstadt, Amber J and Hung, Adriana M and Greevy, Robert A Jr and Grijalva, Carlos G and Elasy, Tom and Griffin, Marie R},
doi = {10.1001/jama.2019.13206},
issn = {1538-3598 (Electronic)},
journal = {JAMA},
language = {eng},
month = {sep},
pages = {1--11},
pmid = {31536102},
title = {{Association of Treatment With Metformin vs Sulfonylurea With Major Adverse Cardiovascular Events Among Patients With Diabetes and Reduced Kidney Function.}},
year = {2019}
}
@article{Balzer:2014he,
author = {Balzer, Laura B and Petersen, Maya L and van der Laan, Mark J and {the SEARCH Consortium}},
journal = {Statistics in Medicine},
month = {nov},
number = {6},
pages = {999--1011},
title = {{Adaptive pair-matching in randomized trials with unbiased and efficient effect estimation}},
volume = {34},
year = {2014}
}
@article{Cook:2011gk,
author = {Cook, Nancy R and Paynter, Nina P},
journal = {Statistics in medicine},
month = {feb},
number = {1},
pages = {93--95},
title = {{Comments on {\{}$\backslash$textquoteleft{\}}Extensions of net reclassification improvement calculations to measure usefulness of new biomarkers{\{}$\backslash$textquoteright{\}} by M. J. Pencina, R. B. D'Agostino, Sr. and E. W. Steyerberg}},
volume = {31},
year = {2011}
}
@article{Kurth:2006ep,
author = {Kurth, Tobias and Walker, Alexander M and Glynn, Robert J and Chan, K Arnold and Gaziano, J Michael and Berger, Klaus and Robins, James M},
journal = {American Journal of Epidemiology},
month = {feb},
number = {3},
pages = {262--270},
title = {{Results of Multivariable Logistic Regression, Propensity Matching, Propensity Adjustment, and Propensity-based Weighting under Conditions of Nonuniform Effect}},
volume = {163},
year = {2006}
}
@article{Lawrance2020,
author = {Lawrance, Rachael and Degtyarev, Evgeny and Griffiths, Philip and Trask, Peter and Lau, Helen and Alessio, Denise D and Griebsch, Ingolf and Wallenstein, Gudrun and Cocks, Kim and Rufibach, Kaspar},
file = {::},
keywords = {Estimand,Treatment effect,HRQoL,PRO,ICH,Clinical t,adelphivalues,clinical trial,com,correspondence,design,estimand,hrqol,ich,lawrance,objective,patient,pro,rachael,treatment effect},
publisher = {Journal of Patient-Reported Outcomes},
title = {{What is an estimand {\&} how does it relate to quantifying the effect of treatment on patient-reported quality of life outcomes in clinical trials ?}},
volume = {5},
year = {2020}
}
@book{Hu:2006co,
address = {Hoboken, NJ, USA},
author = {Hu, Feifang and Rosenberger, William F},
month = {apr},
publisher = {John Wiley {\&} Sons, Inc.},
series = {Hu/Response-Adaptive},
title = {{The Theory of Response-Adaptive Randomization in Clinical Trials}},
year = {2006}
}
@article{harris2009metadata,
author = {Harris, Paul A and Taylor, Robert and Thielke, Robert and Payne, Jonathon and Gonzalez, Nathaniel and Conde, Jose G and Others},
journal = {J Biomed Inform},
number = {2},
pages = {377--381},
title = {{A metadata-driven methodology and workflow process for providing translational research informatics support}},
volume = {42},
year = {2009}
}
@article{halperin1982aid,
author = {Halperin, Max and Lan, K K Gordon and Ware, James H and Johnson, Norman J and DeMets, David L},
journal = {Controlled Clinical Trials},
number = {4},
pages = {311--323},
publisher = {Elsevier},
title = {{An aid to data monitoring in long-term clinical trials}},
volume = {3},
year = {1982}
}
@article{Goodman1995,
abstract = {The Continual Reassessment Method (CRM) is a Bayesian phase I design whose purpose is to estimate the maximum tolerated dose of a drug that will be used in subsequent phase II and III studies. Its acceptance has been hindered by the greater duration of CRM designs compared to standard methods, as well as by concerns with excessive experimentation at high dosage levels, and with more frequent and severe toxicity. This paper presents the results of a simulation study in which one assigns more than one subject at a time to each dose level, and each dose increase is limited to one level. We show that these modifications address all of the most serious criticisms of the CRM, reducing the duration of the trial by 50–67 per cent, reducing toxicity incidence by 20–35 per cent, and lowering toxicity severity. These are achieved with minimal effects on accuracy. Most important, based on our experience at our institution, such modifications make the CRM acceptable to clinical investigators. Copyright {\textcopyright} 1995 John Wiley {\&} Sons, Ltd.},
author = {Goodman, Steven N. and Zahurak, Marianna L. and Piantadosi, Steven},
doi = {10.1002/sim.4780141102},
file = {::},
issn = {10970258},
journal = {Statistics in Medicine},
number = {11},
pages = {1149--1161},
pmid = {7667557},
title = {{Some practical improvements in the continual reassessment method for phase I studies}},
volume = {14},
year = {1995}
}
@article{Pencina:2014fs,
author = {Pencina, Karol M and Pencina, Michael J and {D'Agostino Sr.}, Ralph B},
journal = {Statistics in medicine},
month = {aug},
number = {28},
pages = {4975--4987},
title = {{What to expect from net reclassification improvement with three categories}},
volume = {33},
year = {2014}
}
@article{VanderWeele:2017ki,
author = {VanderWeele, Tyler J and Ding, Peng},
journal = {Annals of Internal Medicine},
month = {jul},
pages = {1--8},
title = {{Sensitivity Analysis in Observational Research: Introducing the E-Value}},
year = {2017}
}
@article{Mazzola2014,
abstract = {The recent release of version 2.0-8 of the BayesMendel package contains an updated BRCAPRO risk prediction model, which includes revised modeling of contralateral breast cancer (CBC) penetrance, provisions for pedigrees of mixed ethnicity and an adjustment for mastectomies among family members. We estimated penetrance functions for CBC by a combination of parametric survival modeling of literature data and deconvolution of SEER9 data. We then validated the resulting updated model of CBC in BRCAPRO by comparing it with the previous release (BayesMendel 2.0-7), using pedigrees from the Cancer Genetics Network (CGN) Model Validation Study. Version 2.0-8 of BRCAPRO discriminates BRCA1/BRCA2 carriers from noncarriers with similar accuracy compared with the previous version (increase in AUC, 0.0043), is slightly more precise in terms of the root-mean-square error (decrease in RMSE, 0.0108), and it significantly improves calibration (ratio of observed to expected events of 0.9765 in version 2.0-8, compared with 0.8910 in version 2.0-7). We recommend that the new version be used in clinical counseling, particularly in settings where families with CBC are common.},
author = {Mazzola, Emanuele and Chipman, Jonathan and Cheng, Su-Chun and Parmigiani, Giovanni},
doi = {10.1158/1055-9965.EPI-13-1364},
issn = {1538-7755 (Electronic)},
journal = {Cancer epidemiology, biomarkers {\&} prevention : a publication of the American Association for Cancer Research, cosponsored by the American Society of Preventive Oncology},
keywords = {Breast Neoplasms,Calibration,Female,Genes, BRCA1,Genes, BRCA2,Genetic Predisposition to Disease,Heterozygote,Humans,Models, Genetic,Neoplasms, Second Primary,Pedigree,Penetrance,genetics},
language = {eng},
month = {aug},
number = {8},
pages = {1689--1695},
pmid = {24891549},
title = {{Recent BRCAPRO upgrades significantly improve calibration.}},
volume = {23},
year = {2014}
}
@misc{obamaPMI,
title = {{Precision Medicine Initiative | The White House}},
url = {https://obamawhitehouse.archives.gov/precision-medicine}
}
@article{Bowen:2016iw,
author = {Bowen, Michael E and Cavanaugh, Kerri L and Wolff, Kathleen and Davis, Dianne and Gregory, Rebecca P and Shintani, Ayumi and Eden, Svetlana and Wallston, Ken and Elasy, Tom and Rothman, Russell L},
journal = {Patient education and counseling},
month = {aug},
number = {8},
pages = {1368--1376},
title = {{The diabetes nutrition education study randomized controlled trial: A comparative effectiveness study of approaches to nutrition in diabetes self-management education}},
volume = {99},
year = {2016}
}
@article{Simon2019,
abstract = {The discovery of somatic driver mutations in kinases and receptors has stimulated the development of molecularly targeted treatments that require companion diagnostics and new approaches to clinical development. This article reviews some of the clinical trial designs that have been developed to address these opportunities, including phase II basket and platform trials as well as phase III enrichment and biomarker adaptive designs. It also re-examines some of the conventional wisdom that previously dominated clinical trial design and discusses development and internal validation of a predictive biomarker as a new paradigm for optimizing the intended-use subset for a treatment. Statistical methods now being used in adaptive biomarker-driven clinical trials are reviewed. Some previous paradigms for clinical trial design can limit the development of more effective methods on the basis of prospectively planned adaptive methods, but useful new methods have been developed for analysis of genome-wide data and for the design of adaptively enriched studies. In many cases, the heterogeneity of populations eligible for clinical trials as traditionally defined makes it unlikely that molecularly targeted treatments will be effective for a majority of the eligible patients. New methods for dealing with patient heterogeneity in therapeutic response should be used in the design of phase III clinical trials.},
author = {Simon, Richard},
doi = {10.1200/po.18.00407},
file = {::},
issn = {24734284},
journal = {JCO Precision Oncology},
number = {3},
pages = {1--9},
title = {{Review of Statistical Methods for Biomarker-Driven Clinical Trials}},
year = {2019}
}
@article{lavange2019rejoinder,
author = {LaVange, Lisa M},
file = {::},
journal = {Statistics in Biopharmaceutical Research},
number = {1},
pages = {30--32},
publisher = {Taylor {\&} Francis},
title = {{Rejoinder to Commentaries on “Statistics at FDA: Reflections on the Past Six Years”}},
volume = {11},
year = {2019}
}
@article{Simon2013,
abstract = {Modern medicine has graduated from broad spectrum treatments to targeted therapeutics. New drugs recognize the recently discovered heterogeneity of many diseases previously considered to be fairly homogeneous. These treatments attack specific genetic pathways which are only dysregulated in some smaller subset of patients with the disease. Often this subset is only rudimentarily understood until well into largescale clinical trials. As such, standard practice has been to enroll a broad range of patients and run post hoc subset analysis to determine those who may particularly benefit. This unnecessarily exposes many patients to hazardous side effects, and may vastly decrease the efficiency of the trial (especially if only a small subset of patients benefit). In this manuscript, we propose a class of adaptive enrichment designs that allow the eligibility criteria of a trial to be adaptively updated during the trial, restricting entry to patients likely to benefit from the new treatment. We show that our designs both preserve the type 1 error, and in a variety of cases provide a substantial increase in power. {\textcopyright} The Author 2013. Published by Oxford University Press. All rights reserved.},
author = {Simon, Noah and Simon, Richard},
doi = {10.1093/biostatistics/kxt010},
file = {::},
issn = {14654644},
journal = {Biostatistics},
keywords = {Adaptive clinical trials,Biomarker,Cutpoint,Enrichment},
number = {4},
pages = {613--625},
pmid = {23525452},
title = {{Adaptive enrichment designs for clinical trials}},
volume = {14},
year = {2013}
}
@article{Anonymous:jI39uy6j,
month = {dec},
pages = {1--130},
title = {{SamuelsBOOMWeights}},
year = {2016}
}
@article{little2012prevention,
author = {Little, Roderick J and D'Agostino, Ralph and Cohen, Michael L and Dickersin, Kay and Emerson, Scott S and Farrar, John T and Frangakis, Constantine and Hogan, Joseph W and Molenberghs, Geert and Murphy, Susan A and Others},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Little et al. - 2012 - The prevention and treatment of missing data in clinical trials.pdf:pdf},
journal = {New England Journal of Medicine},
number = {14},
pages = {1355--1360},
publisher = {Mass Medical Soc},
title = {{The prevention and treatment of missing data in clinical trials}},
volume = {367},
year = {2012}
}
@article{burger2012,
author = {Burger, Robert A. and Brady, Mark F. and Bookman, Michael A. and Fleming, Gini F. and Monk, Bradley J. and Huang, Helen and Mannel, Robert S. and Homesley, Howard D. and Fowler, Jeffrey and Greer, Benjamin E. and Boente, Matthew and Birrer, Michael J. and Liang, Sharon X.},
doi = {10.1097/OGX.0b013e3182547170},
file = {::},
issn = {00297828},
journal = {Obstetrical and Gynecological Survey},
number = {5},
pages = {289--290},
pmid = {22204724},
title = {{Incorporation of bevacizumab in the primary treatment of ovarian cancer}},
volume = {67},
year = {2012}
}
@book{Anonymous:1-AM9NHE,
title = {{Chapman {\&} Hall/CRC Biostatistics Series}}
}
@article{Treasure:2012jn,
author = {Treasure, Tom and Farewell, Vern},
journal = {Journal of Clinical Epidemiology},
month = {jan},
number = {1},
pages = {7--9},
title = {{Minimization in interventional trials: great value but residual vulnerability}},
volume = {65},
year = {2012}
}
@book{cook2007introduction,
author = {Cook, Thomas D and DeMets, David L},
publisher = {CRC Press},
title = {{Introduction to statistical methods for clinical trials}},
year = {2007}
}
@article{Vickers:2009fy,
author = {Vickers, Andrew J and Elkin, Elena B and Steyerberg, Ewout},
journal = {Statistics in medicine},
month = {feb},
number = {3},
pages = {525--526},
title = {{Net reclassification improvement and decision theory}},
volume = {28},
year = {2009}
}
@article{Ding2017,
abstract = {Under the potential outcomes framework, causal effects are defined as comparisons between potential outcomes under treatment and control. To infer causal effects from randomized experiments, Neyman proposed to test the null hypothesis of zero average causal effect (Neyman's null), and Fisher proposed to test the null hypothesis of zero individual causal effect (Fisher's null). Although the subtle difference between Neyman's null and Fisher's null has caused a lot of controversies and confusions for both theoretical and practical statisticians, a careful comparison between the two approaches has been lacking in the literature for more than eighty years. We fill this historical gap by making a theoretical comparison between them and highlighting an intriguing paradox that has not been recognized by previous researchers. Logically, Fisher's null implies Neyman's null. It is therefore surprising that, in actual completely randomized experiments, rejection of Neyman's null does not imply rejection of Fisher's null for many realistic situations, including the case with constant causal effect. Furthermore, we show that this paradox also exists in other commonly-used experiments, such as stratified experiments, matched-pair experiments and factorial experiments. Asymptotic analyses, numerical examples and real data examples all support this surprising phenomenon. Besides its historical and theoretical importance, this paradox also leads to useful practical implications for modern researchers.},
annote = {Neyman and Fisher developed finite popultation tests for causal effects. Both are randomization-based inference because randomization is the source of variability (each having fixed potential outcomes).

A completely randomized experiment satistifies: P(T=T) = N1!N0! / N!.
- Conditioning on end balance allocation ratio meets definition.
- Do permuted blocks and MTI procedures meet definition??

Neymans's RBI:
- Tests for average causal effect
- Potential outcomes follow a distribution (which could be a constant causal effect)
- Tested using asymptotic results (section 3.3) which is conservative when treatment effect is non-constant

Fisher's RBI:
- Tests for 'sharp' individual effects (each potential outcome can be directly imputed)
- Uses exact randomization distribution

Asymptotic result for Fisher difference in means vs Neyman difference in means
- Compares variability of each test
- Neyman's tests is an unpooled test
- Fisher's test is a pooled test


Continue reading about matched-pairs and factorial trials},
archivePrefix = {arXiv},
arxivId = {1402.0142},
author = {Ding, Peng},
doi = {10.1214/16-STS571},
eprint = {1402.0142},
issn = {08834237},
journal = {Statistical Science},
keywords = {Average null hypothesis,Fisher randomization test,Potential outcome,Randomized experiment,Repeated sampling property,Sharp null hypothesis},
number = {3},
pages = {331--345},
title = {{A paradox from randomization-based causal inference}},
volume = {32},
year = {2017}
}
@misc{CDCdeaths2022,
title = {{FastStats - Leading Causes of Death}},
url = {https://www.cdc.gov/nchs/fastats/leading-causes-of-death.htm}
}
@article{Zheng:2017eb,
author = {Zheng, Yingye and Brown, Marshall and Lok, Anna and Cai, Tianxi},
journal = {The Annals of Applied Statistics},
month = {jun},
number = {2},
pages = {638--654},
title = {{Improving efficiency in biomarker incremental value evaluation under two-phase designs}},
volume = {11},
year = {2017}
}
@article{goodman1999toward,
author = {Goodman, Steven N and Others},
journal = {Annals of internal medicine},
pages = {995--1004},
publisher = {American College of Physicians},
title = {{Toward evidence-based medical statistics. 1: The P value fallacy}},
volume = {130},
year = {1999}
}
@article{schuirmann1987comparison,
author = {Schuirmann, Donald J},
journal = {Journal of pharmacokinetics and biopharmaceutics},
pages = {657--680},
publisher = {Springer},
title = {{A comparison of the two one-sided tests procedure and the power approach for assessing the equivalence of average bioavailability}},
volume = {15},
year = {1987}
}
@article{Cutler:2004tg,
author = {{Cutler Jr.}, Gordon B and Chipman, John J},
journal = {The Journal of Pediatrics},
month = {apr},
number = {4},
pages = {415--416},
title = {{Treatment of hypopituitary children}},
volume = {144},
year = {2004}
}
@article{Ayanlowo:2007dt,
author = {Ayanlowo, A O and Redden, D T},
journal = {Statistics in medicine},
month = {mar},
number = {7},
pages = {1462--1472},
title = {{Stochastically curtailed phase II clinical trials.}},
volume = {26},
year = {2007}
}
@article{korn2011outcome,
author = {Korn, Edward L and Freidlin, Boris},
journal = {Journal of Clinical Oncology},
number = {6},
pages = {771},
publisher = {American Society of Clinical Oncology},
title = {{Outcome-adaptive randomization: is it useful?}},
volume = {29},
year = {2011}
}
@article{Teno:2000th,
author = {Teno, Joan M and {Harrell Jr}, Frank E and Knaus, William and Phillips, Russell S and Wu, Albert W and Connors, Alfred and Wenger, Neil S and Wagner, Douglas and Galanos, Anthony and Desbiens, Norman A and Lynn, Joanne},
journal = {Journal of the American Geriatrics Society},
month = {apr},
number = {S1},
pages = {S16----S24},
title = {{Prediction of Survival for Older Hospitalized Patients: The HELP Survival Model}},
volume = {48},
year = {2015}
}
@article{Kastrinos:2013do,
author = {Kastrinos, Fay and Steyerberg, Ewout W and Balma{\~{n}}a, Judith and Mercado, Rowena and Gallinger, Steven and Haile, Robert and Casey, Graham and Hopper, John L and LeMarchand, Loic and Lindor, Noralane M and Newcomb, Polly A and Thibodeau, Stephen N and Syngal, Sapna and {the Colon Cancer Family Registry}},
journal = {Gut},
month = {jan},
number = {2},
pages = {272--279},
title = {{Comparison of the clinical prediction model PREMM 1,2,6and molecular testing for the systematic identification of Lynch syndrome in colorectal cancer}},
volume = {62},
year = {2013}
}
@article{Rosenblum2020,
abstract = {Adaptive enrichment designs involve preplanned rules for modifying enrolment criteria based on accruing data in a randomized trial. We focus on designs where the overall population is partitioned into two predefined subpopulations, e.g. based on a biomarker or risk score measured at baseline. The goal is to learn which populations benefit from an experimental treatment. Two critical components of adaptive enrichment designs are the decision rule for modifying enrolment, and the multiple-testing procedure. We provide a general method for simultaneously optimizing these components for two-stage, adaptive enrichment designs. We minimize the expected sample size under constraints on power and the familywise type I error rate. It is computationally infeasible to solve this optimization problem directly because of its non-convexity. The key to our approach is a novel, discrete representation of this optimization problem as a sparse linear program, which is large but computationally feasible to solve by using modern optimization techniques. We provide an R package that implements our method and is compatible with linear program solvers in several software languages. Our approach produces new, approximately optimal trial designs.},
author = {Rosenblum, Michael and Fang, Ethan X. and Liu, Han},
doi = {10.1111/rssb.12366},
file = {::},
issn = {14679868},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Adaptive enrichment designs,Decision rules,Multiple testing,Optimization problems,Sparse linear programs},
number = {3},
pages = {749--772},
title = {{Optimal, two-stage, adaptive enrichment designs for randomized trials, using sparse linear programming}},
volume = {82},
year = {2020}
}
@article{Kerr:2012go,
author = {Kerr, K F and Bansal, A and Pepe, M S},
journal = {American Journal of Epidemiology},
month = {sep},
number = {6},
pages = {482--487},
title = {{Further Insight Into the Incremental Value of New Markers: The Interpretation of Performance Measures and the Importance of Clinical Context}},
volume = {176},
year = {2012}
}
@article{Byington2016,
author = {Byington, Carrie L and Keenan, Heather and Phillips, John D and Childs, Rebecca and Wachs, Erin and Berzins, Mary Anne and Clark, Kim and Torres, Maria K and Abramson, Jan and Lee, Vivian and Others},
journal = {Academic Medicine},
number = {4},
pages = {497},
publisher = {Wolters Kluwer Health},
title = {{A matrix mentoring model that effectively supports clinical and translational scientists and increases inclusion in biomedical research: Lessons from the University of Utah}},
volume = {91},
year = {2016}
}
@book{Spiegelhalter:2004vw,
address = {Chichester, UK},
author = {Spiegelhalter, David J and Abrams, Keith R and Myles, Jonathan P},
month = {feb},
publisher = {John Wiley {\&} Sons, Ltd},
series = {Spiegelhalter/Clinical Trials and Health-Care Evaluation},
title = {{Bayesian Approaches to Clinical Trials and Health-Care Evaluation}},
year = {2004}
}
@article{Selkoe:2016bp,
author = {Selkoe, Dennis J and Hardy, John},
journal = {EMBO Molecular Medicine},
month = {jun},
number = {6},
pages = {595--608},
title = {{The amyloid hypothesis of Alzheimer's disease at 25{\~{}}years}},
volume = {8},
year = {2016}
}
@article{Kohli2020,
abstract = {Background: Metastatic prostate cancer is a clonally heterogeneous disease state characterized by progressive somatic perturbations. The aim of this study was to identify cell free DNA- (cfDNA-) based alterations and their associations with outcomes in progressive metastatic prostate cancer. Methods: In this longitudinal prospective cohort study plasma cfDNA/circulating tumor DNA (ctDNA) was analyzed before, during, and after androgen deprivation therapy (ADT) in 4 independent patient groups ranging from untreated metastatic hormone sensitive prostate cancer (mHSPC) to metastatic castrate resistant prostate cancer (mCRPC). Next generation sequencing was performed on ctDNA and germline DNA to characterize alterations and associations with clinical outcomes were determined for each group. Findings: cfDNA yields were different in progressive mHSPC and mCRPC states (P {\textless} .001). In mHSPC, a higher than median ctDNA fraction was predictive of shorter time to ADT failure (HR, 2.29 [95{\%} CI, 1.13–4.65]; Log-Rank P = .02). cfDNA, ctDNA taken with volume of metastatic disease in mHSPC and with alkaline phosphatase levels prognosticated survival better than clinical factors alone in mHSPC and mCRPC states (Log Rank P = 0.03). ctDNA-based AR, APC mutations were increased in mCRPC compared to mHSPC (P {\textless} {\textperiodcentered}05).TP53 mutations, RB1 loss, and AR gene amplifications correlated with poorer survival in mCRPC. Mutations in multiple DNA repair genes (ATM, BRCA1, BRCA2, CHEK2) were associated with time to ADT treatment failure and survival in mHSPC. Interpretation: ctDNA fraction can further refine clinical prognostic factors in metastatic prostate cancer. Somatic ctDNA alterations have potential prognostic, predictive, and therapeutic implications in metastatic prostate cancer management. Funding: Several funding sources have supported this study. A full list is provided in the Acknowledgments. No funding was received from Predicine, Inc. during the conduct of the study.},
author = {Kohli, Manish and Tan, Winston and Zheng, Tiantian and Wang, Amy and Montesinos, Carlos and Wong, Calven and Du, Pan and Jia, Shidong and Yadav, Siddhartha and Horvath, Lisa G. and Mahon, Kate L. and Kwan, Edmond M. and Fettke, Heidi and Yu, Jianjun and Azad, Arun A.},
doi = {10.1016/j.ebiom.2020.102728},
issn = {23523964},
journal = {EBioMedicine},
keywords = {Circulating tumor DNA,Genomic alterations,Metastatic prostate cancer},
pmid = {32268276},
publisher = {Elsevier B.V.},
title = {{Clinical and genomic insights into circulating tumor DNA-based alterations across the spectrum of metastatic hormone-sensitive and castrate-resistant prostate cancer}},
volume = {54},
year = {2020}
}
@article{Lee:2008ey,
author = {Lee, J Jack and Liu, Diane D},
journal = {Clinical Trials},
number = {2},
pages = {93--106},
title = {{A predictive probability design for phase II cancer clinical trials.}},
volume = {5},
year = {2008}
}
@article{Wathen2017,
abstract = {Randomizing patients among treatments with equal probabilities in clinical trials is the established method to obtain unbiased comparisons. In recent years, motivated by ethical considerations, many authors have proposed outcome adaptive randomization, wherein the randomization probabilities are unbalanced, based on interim data, to favor treatment arms having more favorable outcomes. While there has been substantial controversy regarding the merits and flaws of adaptive versus equal randomization, there has not yet been a systematic simulation study in the multi-arm setting. A simulation study was conducted to evaluate four different Bayesian adaptive randomization methods and compare them to equal randomization in five-arm clinical trials. All adaptive randomization methods included an initial burn-in with equal randomization and some combination of other modifications to avoid extreme randomization probabilities. Trials either with or without a control arm were evaluated, using designs that may terminate arms early for futility and select one or more experimental treatments at the end. The designs were evaluated under a range of scenarios and sample sizes. For trials with a control arm and maximum same size 250 or 500, several commonly used adaptive randomization methods have very low probabilities of correctly selecting a truly superior treatment. Of those studied, the only adaptive randomization method with desirable properties has a burn-in with equal randomization and thereafter randomization probabilities restricted to the interval 0.10-0.90. Compared to equal randomization, this method has a favorable sample size imbalance but lower probability of correctly selecting a superior treatment. In multi-arm trials, compared to equal randomization, several commonly used adaptive randomization methods give much lower probabilities of selecting superior treatments. Aside from randomization method, conducting a multi-arm trial without a control arm may lead to very low probabilities of selecting any superior treatments if differences between the treatment success probabilities are small.},
author = {Wathen, J. Kyle and Thall, Peter F.},
doi = {10.1177/1740774517692302},
file = {::},
isbn = {1740774517692},
issn = {17407753},
journal = {Clinical Trials},
keywords = {Adaptive randomization,Bayesian design,play the winner,screening trial,simulation},
number = {5},
pages = {432--440},
pmid = {28982263},
title = {{A simulation study of outcome adaptive randomization in multi-arm clinical trials}},
volume = {14},
year = {2017}
}
@article{Forastiere2018,
abstract = {In randomized experiments with noncompliance, one might wish to focus on compliers rather than on the overall sample. In this vein, Rubin (1998) argued that testing for the complier average causal effect and averaging permutationbased p-values over the posterior distribution of the compliance types could increase power as compared to general intent-to-treat tests. The general scheme is a repeated two-step process: impute missing compliance types and conduct a permutation test with the completed data. In this paper, we explore this idea further, comparing the use of discrepancy measures-which depend on unknown but imputed parameters-to classical test statistics and contrasting different approaches for imputing the unknown compliance types. We also examine consequences of model misspecification in the imputation step, and discuss to what extent this additional modeling undercuts the advantage of permutation tests being model independent. We find that, especially for discrepancy measures, modeling choices can impact both power and validity. In particular, imputing missing compliance types under the null can radically reduce power, but not doing so can jeopardize validity. Fortunately, using covariates predictive of compliance type in the imputation can mitigate these results. We also compare this overall approach to Bayesian model-based tests, that is, tests that are directly derived from posterior credible intervals, under both correct and incorrect model specification.},
annote = {Randomization with imputation},
archivePrefix = {arXiv},
arxivId = {1511.00521},
author = {Forastiere, Laura and Mealli, Fabrizia and Miratrix, Luke},
doi = {10.1214/17-BA1062},
eprint = {1511.00521},
issn = {19316690},
journal = {Bayesian Analysis},
keywords = {Complier average causal effects (CACE),Noncompliance,Permutation testing,Posterior predictive p-values (PPPV),Principal stratification},
number = {3},
pages = {681--701},
title = {{Posterior predictive p-Values with fisher randomization tests in noncompliance settings: Test statistics vs discrepancy measures}},
volume = {13},
year = {2018}
}
@article{Attanasio:2004cj,
author = {Attanasio, Andrea F and Shavrikova, Elena and Blum, Werner F and Cromer, Morris and Child, Christopher J and Paskova, Magdalena and Lebl, Jan and Chipman, John J and Shalet, Stephen M},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {oct},
number = {10},
pages = {4857--4862},
title = {{Continued Growth Hormone (GH) Treatment after Final Height Is Necessary to Complete Somatic Development in Childhood-Onset GH-Deficient Patients}},
volume = {89},
year = {2004}
}
@article{Vickers:2011eb,
author = {Vickers, Andrew J and Cronin, Angel M and Begg, Colin B},
journal = {BMC Medical Research Methodology},
month = {jan},
number = {1},
pages = {2543},
title = {{One statistical test is sufficient for assessing new predictive markers}},
volume = {11},
year = {2011}
}
@misc{darrow2017speed,
author = {Darrow, Jonathan J and Avorn, Jerry and Kesselheim, Aaron S},
booktitle = {New England Journal of Medicine},
number = {23},
pages = {2278--2286},
publisher = {Massachusetts Medical Society},
title = {{Speed, safety, and industry funding—from PDUFA I to PDUFA VI}},
volume = {377},
year = {2017}
}
@article{Copas2008,
abstract = {The additive hazards model is one of the most commonly used regression models in the analysis of failure time data and many methods have been developed for its inference under various situations. This paper discusses the situation where one faces current status data and also there exists informative censoring or when the failure time of interest and the observation process are correlated. Several authors have discussed the problem and in particular, Zhang et al. (2005) and Zhao et al. (2015) proposed an estimating equationbased approach and a copula model-based method, respectively. However, the former may not be efficient and the latter needs some restrictive assumptions. To address these, we propose a sieve maximum likelihood estimation approach that can be more efficient and also does not require the assumption above. For the implementation of the method, an EM algorithm is developed and the asymptotic properties of the resulting estimators are established. The numerical results suggest that the proposed method works well in practical situations and an application is provided.},
author = {Copas, John B and Malley, Paul F},
doi = {10.1002/sim},
file = {::},
keywords = {publication bias,selection bias,selection model,sensitivity analysis,unpublished studies},
number = {April},
pages = {4267--4278},
title = {{A robust}},
year = {2008}
}
@article{Balmana:2006ej,
author = {Balma{\~{n}}a, Judith and Stockwell, David H and Steyerberg, Ewout W and Stoffel, Elena M and Deffenbaugh, Amie M and Reid, Julia E and Ward, Brian and Scholl, Thomas and Hendrickson, Brant and Tazelaar, John and Burbidge, Lynn Anne and Syngal, Sapna},
journal = {JAMA},
month = {sep},
number = {12},
pages = {1469},
title = {{Prediction of MLH1 and MSH2 Mutations in Lynch Syndrome}},
volume = {296},
year = {2006}
}
@article{Lachin:1988ja,
author = {Lachin, John M},
journal = {Controlled Clinical Trials},
month = {dec},
number = {4},
pages = {312--326},
title = {{Properties of simple randomization in clinical trials}},
volume = {9},
year = {1988}
}
@article{Martin2018,
abstract = {Medication adherence represents an inefficiency and ongoing challenge within medical care. The problem has been long-recognized - indeed, the research literature contains thousands of articles on the topic. Nonetheless, because of the complex nature of the problem, it still cannot be considered to be solved. Reasons for nonadherence are myriad but psychological barriers to adherence are most difficult to mitigate and, thus, are the focus of this paper. The present narrative review sketches a summary of theoretical models commonly utilized to understand and help address medication nonadherence; uses a patient-centered care approach to contextualize the problem of nonadherence to drug therapies; and then outlines a set of best-practice recommendations based on the extant data and framed from the perspective of the Information-Motivation-Strategy model. Copyright {\textcopyright} 2018 Martin et al.},
author = {Martin, Leslie R. and Feig, Cheyenne and Maksoudian, Chloe R. and Wysong, Kenrick and Faasse, Kate},
doi = {10.2147/PPA.S155971},
issn = {1177889X},
journal = {Patient Preference and Adherence},
keywords = {Adherence barriers,Improving adherence,Medication nonadherence,Nonadherence},
pages = {1527--1535},
title = {{A perspective on nonadherence to drug therapy: Psychological barriers and strategies to overcome nonadherence}},
volume = {12},
year = {2018}
}
@book{vexler2018empirical,
author = {Vexler, Albert and Yu, Jihnhee},
file = {::},
publisher = {CRC Press},
title = {{Empirical likelihood methods in biomedicine and health}},
year = {2018}
}
@article{Shao2010,
abstract = {The covariate-adaptive randomization method was proposed for clinical trials long ago but little theoretical work has been done for statistical inference associated with it. Practitioners often apply test procedures available for simple randomization, which is controversial since procedures valid under simple randomization may not be valid under other randomization schemes. In this paper, we provide some theoretical results for testing hypotheses after covariate-adaptive randomization. We show that one way to obtain a valid test procedure is to use a correct model between outcomes and covariates, including those used in randomization. We also show that the simple two sample t-test, without using any covariate, is conservative under covariate-adaptive biased coin randomization in terms of its Type I error, and that a valid bootstrap t-test can be constructed. The powers of several tests are examined theoretically and empirically. Our study provides guidance for applications and sheds light on further research in this area. {\textcopyright} 2010 Biometrika Trust.},
author = {Shao, Jun and Yu, Xinxin and Zhong, Bob},
doi = {10.1093/biomet/asq014},
issn = {00063444},
journal = {Biometrika},
number = {2},
pages = {347--360},
title = {{A theory for testing hypotheses under covariate-adaptive randomization}},
volume = {97},
year = {2010}
}
@article{Leening:2013ks,
author = {Leening, Maarten J G and Cook, Nancy R},
journal = {European Journal of Epidemiology},
month = {jan},
number = {1},
pages = {21--23},
title = {{Net reclassification improvement: a link between statistics and clinical practice}},
volume = {28},
year = {2013}
}
@article{Lipkovich2020,
abstract = {The National Research Council's report on the prevention and treatment of missing data highlighted the need to clearly specify causal estimands. This focus fundamentally changed how the missing data problem was perceived and addressed in clinical trials. The recent ICH E9(R1) addendum is another major step in promoting the use of the causal estimands framework that should further influence how clinical trial protocols and statistical analysis plans are written and implemented. The language of potential outcomes that is widely accepted in the causal inference literature is not widely recognized in the clinical trialists community and was not used in defining causal estimands in the NRC report or the ICH E9(R1). In this article, we attempt to bridge the gap between the causal inference community and clinical trialists to further advance the use of causal estimands in clinical trial settings. We illustrate how concepts from causal literature, such as potential outcomes and dynamic treatment regimens, can facilitate defining and implementing causal estimands and may provide a unifying language to describing the targets for both observational and randomized clinical trials.},
annote = {Historical statements on randomization

Population-based model is not appropriate for randomized trials because patients who participate are not random. Randomization based inference (RBI) is appropriate.

Today randomization is generally not used for inference but more random sampling from population model and then use of neyman pearson inference. RBI fixes observed outcomes and constructs RBI testing.

Ironically, RBI was not done originally because too computationally infeasible. Not that feasible it's still not done much even though computationally feasible.

Monte-Carlo procedure for rerandomization. 15,000 sufficient for small p-values.

Missing data: "model based imputation methods and the usual concepts of missing data mechanisms are based on the likehood theory and have no analogs in randomization-based inference."

... Still need to continue reading.},
author = {Lipkovich, Ilya and Ratitch, Bohdana and Mallinckrodt, Craig H.},
doi = {10.1080/19466315.2019.1697739},
issn = {19466315},
journal = {Statistics in Biopharmaceutical Research},
keywords = {Causal inference,Estimands,Intercurrent events,Potential outcomes},
number = {1},
pages = {54--67},
title = {{Causal Inference and Estimands in Clinical Trials}},
volume = {12},
year = {2020}
}
@article{Pencina:C8s_wgVf,
author = {Pencina, Michael J and {D'Agostino Sr.}, Ralph B and Demler, Olga V},
journal = {Statistics in medicine},
month = {dec},
number = {2},
pages = {101--113},
title = {{Novel metrics for evaluating improvement in discrimination: net reclassification and integrated discrimination improvement for normal variables and nested models}},
volume = {31},
year = {2011}
}
@article{Imbens2021,
abstract = {The bootstrap, introduced by The Jackknife, the Bootstrap and Other Resampling Plans ((1982), SIAM), has become a very popular method for estimating variances and constructing confidence intervals. A key insight is that one can approximate the properties of estimators by using the empirical distribution function of the sample as an approximation for the true distribution function. This approach views the uncertainty in the estimator as coming exclusively from sampling uncertainty. We argue that for causal estimands the uncertainty arises entirely, or partially, from a different source, corresponding to the stochastic nature of the treatment received. We develop a bootstrap procedure for inference regarding the average treatment effect that accounts for this uncertainty, and compare its properties to that of the classical bootstrap. We consider completely randomized and observational designs as well as designs with imperfect compliance.},
archivePrefix = {arXiv},
arxivId = {1807.02737},
author = {Imbens, Guido and Menzel, Konrad},
doi = {10.1214/20-AOS2009},
eprint = {1807.02737},
issn = {21688966},
journal = {Annals of Statistics},
keywords = {Bootstrap,Causal inference,Partial identification},
number = {3},
pages = {1460--1488},
title = {{A causal bootstrap}},
volume = {49},
year = {2021}
}
@article{Binder:1983ft,
author = {Binder, David A},
journal = {International Statistical Review / Revue Internationale de Statistique},
month = {dec},
number = {3},
pages = {279},
title = {{On the Variances of Asymptotically Normal Estimators from Complex Surveys}},
volume = {51},
year = {1983}
}
@article{fu2016estimating,
author = {Fu, Haoda and Zhou, Jin and Faries, Douglas E},
journal = {Statistics in medicine},
number = {19},
pages = {3285--3302},
publisher = {Wiley Online Library},
title = {{Estimating optimal treatment regimes via subgroup identification in randomized control trials and observational studies}},
volume = {35},
year = {2016}
}
@article{Kishi2019,
abstract = {OBJECTIVE: Circulating endothelial cells (CECs), von Willebrand Factor (VWF) antigen, P-selectin and thrombomodulin are released from damaged endothelium, while decreases in circulating endothelial progenitor cells (CEPCs) have been associated with poor vascular outcomes. We examined these markers in the peripheral blood of juvenile dermatomyositis (JDM) patients and their correlations with disease assessments. METHODS: Peripheral blood endothelial cells and biomarkers were assessed in 20 JDM patients, and matched healthy controls. CECs and CEPCs were quantitated by flow cytometry, while VWF antigen and activity, Factor VIII, P-selectin and thrombomodulin were measured in plate-based assays. Disease activity and damage, nailfold capillary (NFC) density, and brachial artery flow dilation were assessed. Serum cytokines/chemokines were measured by Luminex. RESULTS: CECs, VWF antigen, Factor VIII, thrombomodulin, but not VWF activity, CEPCs or P-selectin, were elevated in the peripheral blood of JDM patients. CECs correlated with pulmonary activity (rs= 0.56). VWF antigen correlated with Patient/Parent Global, cutaneous and Extra-muscular Activity (rs= 0.47-0.59). CEPCs negatively correlated with muscle activity and physical function (rs= -0.52- -0.53). CEPCs correlated inversely with endocrine damage. VWF antigen and activity correlated with IL-10 and IP-10 (rs= 0.64-0.82),. CONCLUSION: Markers of endothelial injury are increased in JDM patients and correlate with extramuscular activity. CEPCs correlate inversely with muscle activity, suggesting a functional disturbance in repair mechanisms.},
author = {Kishi, Takayuki and Chipman, Jonathan and Evereklian, Melvina and Nghiem, Khanh and Stetler-Stevenson, Maryalice and Rick, Margaret E and Centola, Michael and Miller, Frederick W and Rider, Lisa G},
doi = {10.3899/jrheum.181275},
issn = {0315-162X (Print)},
journal = {The Journal of rheumatology},
language = {eng},
month = {aug},
pmid = {31371656},
title = {{Endothelial Activation Markers as Disease Activity and Damage Measures in Juvenile Dermatomyositis.}},
year = {2019}
}
@article{Tan:1996ig,
author = {Tan, M and Xiong, X},
journal = {Statistics in medicine},
month = {oct},
number = {19},
pages = {2037--2051},
title = {{Continuous and group sequential conditional probability ratio tests for phase II clinical trials.}},
volume = {15},
year = {1996}
}
@article{Zhang:2010ip,
author = {Zhang, Zhiwei},
journal = {International Statistical Review},
month = {apr},
number = {1},
pages = {102--116},
title = {{Profile Likelihood and Incomplete Data}},
volume = {78},
year = {2010}
}
@incollection{Robins:2000iu,
address = {New York, NY},
author = {Robins, James M},
booktitle = {Statistical Models in Epidemiology, the Environment, and Clinical Trials},
pages = {95--133},
publisher = {Springer New York},
title = {{Marginal Structural Models versus Structural nested Models as Tools for Causal inference}},
year = {2000}
}
@article{McEntegart:2003ey,
author = {McEntegart, D J},
journal = {Drug Information Journal},
month = {jul},
number = {3},
pages = {293--308},
title = {{The Pursuit of Balance Using Stratified and Dynamic Randomization Techniques: An Overview}},
volume = {37},
year = {2003}
}
@article{Feynman1963118,
author = {Feynman, R P and {Vernon Jr.}, F L},
doi = {10.1016/0003-4916(63)90068-X},
journal = {Annals of Physics},
pages = {118--173},
title = {{The theory of a general quantum system interacting with a linear dissipative system}},
volume = {24},
year = {1963}
}
@article{Hu2012,
abstract = {Balancing treatment allocation for influential covariates is critical in clinical trials. This has become increasingly important as more and more biomarkers are found to be associated with different diseases in translational research (genomics, proteomics and metabolomics). Stratified permuted block randomization and minimization methods [Pocock and Simon Biometrics 31 (1975) 103-115, etc.] are the two most popular approaches in practice. However, stratified permuted block randomization fails to achieve good overall balance when the number of strata is large, whereas traditional minimization methods also suffer from the potential drawback of large within-stratum imbalances. Moreover, the theoretical bases of minimization methods remain largely elusive. In this paper, we propose a new covariateadaptive design that is able to control various types of imbalances. We show that the joint process of within-stratum imbalances is a positive recurrent Markov chain under certain conditions. Therefore, this new procedure yields more balanced allocation. The advantages of the proposed procedure are also demonstrated by extensive simulation studies. Our work provides a theoretical tool for future research in this area. {\textcopyright} Institute of Mathematical Statistics, 2012.},
author = {Hu, Yanqing and Hu, Feifang},
doi = {10.1214/12-AOS983},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Balancing covariates,Clinical trial,Marginal balance,Markov chain,Pocock and Simon's design,Stratified permuted block},
number = {3},
pages = {1794--1815},
title = {{Asymptotic properties of covariate-adaptive randomization}},
volume = {40},
year = {2012}
}
@article{Yang:2005cl,
author = {Yang, S},
journal = {Biometrika},
month = {mar},
number = {1},
pages = {1--17},
title = {{Semiparametric analysis of short-term and long-term hazard ratios with two-sample survival data}},
volume = {92},
year = {2005}
}
@article{mcpherson2012use,
author = {McPherson, Gladys C and Campbell, Marion K and Elbourne, Diana R},
file = {::},
journal = {Trials},
number = {1},
pages = {1--7},
publisher = {BioMed Central},
title = {{Use of randomisation in clinical trials: a survey of UK practice}},
volume = {13},
year = {2012}
}
@article{Anonymous:6jLA-dfo,
annote = {In code:

SCRSSN: Scrambled social security number (at a national level)

Hypoglycemia {\{}$\backslash$textasciitilde{\}} 55 probably okayish (asymptomatic)
50 feeling kind of squeemish
40 delarium

C003: All met In code: SCRSSN: Scrambled social security number (at a national level) Hypoglycemia},
title = {{No Title}}
}
@article{Dorresteijn2011,
abstract = {Objectives: To predict treatment effects for individual patients based on data from randomised trials, taking rosuvastatin treatment in the primary prevention of cardiovascular disease as an example, and to evaluate the net benefit of making treatment decisions for individual patients based on a predicted absolute treatment effect. Setting: As an example, data were used from the Justification for the Use of Statins in Prevention (JUPITER) trial, a randomised controlled trial evaluating the effect of rosuvastatin 20 mg daily versus placebo on the occurrence of cardiovascular events (myocardial infarction, stroke, arterial revascularisation, admission to hospital for unstable angina, or death from cardiovascular causes). Population: 17 802 healthy men and women who had low density lipoprotein cholesterol levels of less than 3.4 mmol/L and high sensitivity C reactive protein levels of 2.0 mg/L or more. Methods: Data from the Justification for the Use of Statins in Prevention trial were used to predict rosuvastatin treatment effect for individual patients based on existing risk scores (Framingham and Reynolds) and on a newly developed prediction model. We compared the net benefit of prediction based rosuvastatin treatment (selective treatment of patients whose predicted treatment effect exceeds a decision threshold) with the net benefit of treating either everyone or no one. Results: The median predicted 10 year absolute risk reduction for cardiovascular events was 4.4{\%} (interquartile range 2.6-7.0{\%}) based on the Framingham risk score, 4.2{\%} (2.5-7.1{\%}) based on the Reynolds score, and 3.9{\%} (2.5-6.1{\%}) based on the newly developed model (optimal fit model). Prediction based treatment was associated with more net benefit than treating everyone or no one, provided that the decision threshold was between 2{\%} and 7{\%}, and thus that the number willing to treat (NWT) to prevent one cardiovascular event over 10 years was between 15 and 50. Conclusions: Data from randomised trials can be used to predict treatment effect in terms of absolute risk reduction for individual patients, based on a newly developed model or, if available, existing risk scores. The value of such prediction of treatment effect for medical decision making is conditional on the NWT to prevent one outcome event. Trial registration number: Clinicaltrials.gov NCT00239681.},
author = {Dorresteijn, Johannes A.N. and Visseren, Frank L.J. and Ridker, Paul M. and Wassink, Annemarie M.J. and Paynter, Nina P. and Steyerberg, Ewout W. and {Van Der Graaf}, Yolanda and Cook, Nancy R.},
doi = {10.1136/bmj.d5888},
file = {::},
issn = {09598146},
journal = {BMJ (Online)},
keywords = {dorresteijn2011ite},
number = {7828},
pages = {1--13},
pmid = {21968126},
title = {{Estimating treatment effects for individual patients based on the results of randomised clinical trials}},
volume = {343},
year = {2011}
}
@article{duan2009,
abstract = {Doubly adaptive biased coin design (DBCD) is an important family of response-adaptive randomization procedures for clinical trials. It uses sequentially updated estimation to skew the allocation probability to favor the treatment that has performed better thus far. An important assumption for the DBCD is the homogeneity assumption for the patient responses. However, this assumption may be violated in many sequential experiments. Here we prove the robustness of the DBCD against certain time trends in patient responses. Strong consistency and asymptotic normality of the design are obtained under some widely satisfied conditions. Also, we propose a general weighted likelihood method to reduce the bias caused by the heterogeneity in the inference after a trial. Some numerical studies are also presented to illustrate the finite sample properties of DBCD. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Duan, Liangliang and Hu, Feifang},
doi = {10.1016/j.jspi.2009.03.004},
file = {::},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Asymptotic normality,Clinical trial,Doubly adaptive biased coin design,Heterogeneity,Response-adaptive randomization,Treatment allocation},
number = {9},
pages = {3220--3230},
title = {{Doubly adaptive biased coin designs with heterogeneous responses}},
volume = {139},
year = {2009}
}
@article{Chi:2008he,
author = {Chi, Yunchan and Chen, Chia-Min},
journal = {Statistics in medicine},
month = {dec},
number = {29},
pages = {6175--6189},
title = {{Curtailed two-stage designs in Phase II clinical trials.}},
volume = {27},
year = {2008}
}
@article{Kapelner:2014cu,
author = {Kapelner, Adam and Krieger, Abba},
journal = {Biometrics},
month = {jan},
number = {2},
pages = {378--388},
title = {{Matching on-the-fly: Sequential allocation with higher power and efficiency}},
volume = {70},
year = {2014}
}
@article{Vickers:2014fs,
author = {Vickers, Andrew and Carlsson, Sigrid and Laudone, Vincent and Lilja, Hans},
journal = {European urology},
month = {aug},
number = {2},
pages = {188--190},
title = {{It Ain{\{}$\backslash$textquoteright{\}}t What You Do, It's the Way You Do It: Five Golden Rules for Transforming Prostate-Specific Antigen Screening}},
volume = {66},
year = {2014}
}
@article{GUIDANCE:2010wf,
author = {{GUIDANCE, D}},
journal = {Biotechnology Law Report},
month = {apr},
number = {2},
pages = {197--215},
title = {{Guidance for Industry: Adaptive Design Clinical Trials for Drugs and Biologics [excerpts]}},
volume = {29},
year = {2010}
}
@article{anderson1960modification,
author = {Anderson, Todd W},
file = {::},
journal = {The Annals of Mathematical Statistics},
pages = {165--197},
publisher = {JSTOR},
title = {{A modification of the sequential probability ratio test to reduce the sample size}},
year = {1960}
}
@article{Senn:2010bg,
author = {Senn, Stephen and Anisimov, Vladimir V and Fedorov, Valerii V},
journal = {Statistics in medicine},
month = {mar},
number = {7-8},
pages = {721--730},
title = {{Comparisons of minimization and Atkinson's algorithm}},
volume = {29},
year = {2010}
}
@article{Daniel:2013jm,
author = {Daniel, R M and Cousens, S N and {De Stavola}, B L and Kenward, M G and Sterne, J A C},
journal = {Statistics in medicine},
month = {apr},
number = {9},
pages = {1584--1618},
title = {{Methods for dealing with time-dependent confounding.}},
volume = {32},
year = {2013}
}
@article{Nerenz2021,
abstract = {Risk adjustment of quality measures using clinical risk factors is widely accepted; risk adjustment using social risk factors remains controversial. We argue here that social risk adjustment is appropriate and necessary in defined circumstances and that social risk adjustment should be the default option when there are valid empirical arguments for and against adjustment for a given measure. Social risk adjustment is an important way to avoid exacerbating inequity in the health care system.},
author = {Nerenz, David R. and Austin, J. Matthew and Deutscher, Daniel and Maddox, Karen E.Joynt and Nuccio, Eugene J. and Teigland, Christie and Weinhandl, Eric and Glance, Laurent G.},
doi = {10.1377/hlthaff.2020.01764},
issn = {15445208},
journal = {Health Affairs},
number = {4},
pages = {637--644},
pmid = {33819097},
title = {{Adjusting quality measures for social risk factors can promote equity in health care}},
volume = {40},
year = {2021}
}
@article{Tan:2011gu,
author = {Tan, Ming T and Xiong, Xiaoping},
journal = {Pharmaceutical Statistics},
month = {jul},
number = {4},
pages = {369--373},
title = {{A flexible multi-stage design for phase II oncology trials.}},
volume = {10},
year = {2011}
}
@article{Greenland:2008kna,
author = {Greenland, Sander},
journal = {Statistics in medicine},
number = {2},
pages = {199--206},
title = {{The need for reorientation toward cost-effective prediction: Comments on {\{}$\backslash$textquoteleft{\}}Evaluating the added predictive ability of a new marker: From area under the ROC curve to reclassification and beyond{\{}$\backslash$textquoteright{\}} by M. J. Pencinaet al.,Statisti}},
volume = {27},
year = {2007}
}
@misc{Chipman2019,
author = {Chipman, Jonathan Joseph},
publisher = {Vanderbilt University},
title = {{Sequential Rematched Randomization and Adaptive Monitoring with the Second-Generation p-Value to increase the efficiency and efficacy of Randomized Clinical Trials}},
year = {2019}
}
@article{little2006calibrated,
author = {Little, Roderick J},
journal = {The American Statistician},
number = {3},
pages = {213--223},
publisher = {Taylor {\&} Francis},
title = {{Calibrated Bayes: a Bayes/frequentist roadmap}},
volume = {60},
year = {2006}
}
@article{zhang2007asymptotic,
author = {Zhang, Li-Xin and Hu, Feifang and Cheung, Siu Hung and Chan, Wai Sum},
file = {::},
title = {{Asymptotic properties of covariate-adjusted response-adaptive designs}},
year = {2007}
}
@book{lehmann2005testing,
author = {Lehmann, Erich Leo and Romano, Joseph P and Casella, George},
publisher = {Springer},
title = {{Testing statistical hypotheses}},
volume = {3},
year = {2005}
}
@article{Imai:2009du,
annote = {This paper commented in: [arXiv:0910.3754], [arXiv:0910.3756]. Rejoinder in [arXiv:0910.3758]. Published in at http://dx.doi.org/10.1214/08-STS274 the Statistical Science (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics (http://www.imstat.org)},
author = {Imai, Kosuke and King, Gary and Nall, Clayton},
journal = {Statistical Science},
month = {feb},
number = {1},
pages = {29--53},
title = {{The Essential Role of Pair Matching in Cluster-Randomized Experiments, with Application to the Mexican Universal Health Insurance Evaluation}},
volume = {24},
year = {2009}
}
@article{Peek:2007ho,
author = {Peek, N and Arts, D G T and Bosman, R J and van der Voort, P H J and de Keizer, N F},
journal = {Journal of Clinical Epidemiology},
month = {may},
number = {5},
pages = {491.e1----491.e13},
title = {{External validation of prognostic models for critically ill patients required substantial sample sizes}},
volume = {60},
year = {2007}
}
@article{Blume:2007iq,
author = {Blume, Jeffrey D and Su, Li and Olveda, Remigio M and McGarvey, Stephen T},
journal = {Statistics in medicine},
number = {15},
pages = {2919--2936},
title = {{Statistical evidence for GLM regression parameters: A robust likelihood approach}},
volume = {26},
year = {2007}
}
@article{Albanese2018,
abstract = {Background: The ability of finding complex associations in large omics datasets, assessing their significance, and prioritizing them according to their strength can be of great help in the data exploration phase. Mutual information-based measures of association are particularly promising, in particular after the recent introduction of the TICe and MICe estimators, which combine computational efficiency with superior bias/variance properties. An open-source software implementation of these two measures providing a complete procedure to test their significance would be extremely useful. Findings: Here, we present MICtools, a comprehensive and effective pipeline that combines TICe and MICe into a multistep procedure that allows the identification of relationships of various degrees of complexity. MICtools calculates their strength assessing statistical significance using a permutation-based strategy. The performances of the proposed approach are assessed by an extensive investigation in synthetic datasets and an example of a potential application on a metagenomic dataset is also illustrated. Conclusions: We show that MICtools, combining TICe and MICe, is able to highlight associations that would not be captured by conventional strategies.},
author = {Albanese, Davide and Riccadonna, Samantha and Donati, Claudio and Franceschi, Pietro},
doi = {10.1093/gigascience/giy032},
file = {::},
issn = {2047217X},
journal = {GigaScience},
keywords = {equitability,false discovery rate,fdr,maximal information coefficient,mic,multiple testing,permutation test,power of statistical,significance,tic},
number = {4},
pages = {1--8},
pmid = {29617783},
publisher = {Oxford University Press},
title = {{A practical tool for maximal information coefficient analysis}},
volume = {7},
year = {2018}
}
@article{Austin:2011cu,
author = {Austin, Peter C},
journal = {Multivariate Behavioral Research},
month = {may},
number = {3},
pages = {399--424},
title = {{An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies}},
volume = {46},
year = {2011}
}
@article{Hu:2014jm,
annote = {Refined version of Pocock Simon

Weights balances of categorized covariates
- Balances overall, marginal, and within-strata covariates
- Test provided to check criteria met for positive recurrence

Markov chain proof to show positive recurrenc and fast balancing convergence

References on:
- Popular use of stratified randomization with increasing strata
- Model-based allocations and conditional permutation test (?)
- Balanced allocation increases credibility
- Continuous allocation function and taylor series expansion (?)
- Different measures of covariate balance
- Different arguments for biased coin value starting with Efron p=2/3 and mor strong p = 0.95 --- Note to self: this is nearly pure minization; how much biased coin induces risk for confounding},
author = {Hu, Feifang and Hu, Yanqing and Ma, Zhenjun and Rosenberger, William F},
file = {::},
journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
month = {jul},
number = {4},
pages = {288--303},
title = {{Adaptive randomization for balancing over covariates}},
volume = {6},
year = {2014}
}
@article{Hulsen2019,
abstract = {For over a decade the term "Big data" has been used to describe the rapid increase in volume, variety and velocity of information available, not just in medical research but in almost every aspect of our lives. As scientists, we now have the capacity to rapidly generate, store and analyse data that, only a few years ago, would have taken many years to compile. However, "Big data" no longer means what it once did. The term has expanded and now refers not to just large data volume, but to our increasing ability to analyse and interpret those data. Tautologies such as "data analytics" and "data science" have emerged to describe approaches to the volume of available information as it grows ever larger. New methods dedicated to improving data collection, storage, cleaning, processing and interpretation continue to be developed, although not always by, or for, medical researchers. Exploiting new tools to extract meaning from large volume information has the potential to drive real change in clinical practice, from personalized therapy and intelligent drug design to population screening and electronic health record mining. As ever, where new technology promises "Big Advances," significant challenges remain. Here we discuss both the opportunities and challenges posed to biomedical research by our increasing ability to tackle large datasets. Important challenges include the need for standardization of data content, format, and clinical definitions, a heightened need for collaborative networks with sharing of both data and expertise and, perhaps most importantly, a need to reconsider how and when analytic methodology is taught to medical researchers. We also set "Big data" analytics in context: recent advances may appear to promise a revolution, sweeping away conventional approaches to medical science. However, their real promise lies in their synergy with, not replacement of, classical hypothesis-driven methods. The generation of novel, data-driven hypotheses based on interpretable models will always require stringent validation and experimental testing. Thus, hypothesis-generating research founded on large datasets adds to, rather than replaces, traditional hypothesis driven science. Each can benefit from the other and it is through using both that we can improve clinical practice.},
author = {Hulsen, Tim and Jamuar, Saumya S. and Moody, Alan R. and Karnes, Jason H. and Varga, Orsolya and Hedensted, Stine and Spreafico, Roberto and Hafler, David A. and McKinney, Eoin F.},
doi = {10.3389/fmed.2019.00034},
issn = {2296858X},
journal = {Frontiers in Medicine},
number = {MAR},
pages = {1--14},
pmid = {30881956},
title = {{From big data to precision medicine}},
volume = {6},
year = {2019}
}
@article{Kernan:2000hm,
author = {Kernan, W N and Viscoli, C M and Brass, L M and Makuch, R W and Sarrel, P M and Roberts, R S and Gent, M and Rothwell, P and Sacco, R L and Liu, R C and Boden-Albala, B and Horwitz, R I},
journal = {Stroke},
month = {feb},
number = {2},
pages = {456--462},
title = {{The Stroke Prognosis Instrument II (SPI-II) : A Clinical Prediction Instrument for Patients With Transient Ischemia and Nondisabling Ischemic Stroke}},
volume = {31},
year = {2000}
}
@article{Kang:2008eq,
author = {Kang, Minsoo and Ragan, Brian G and Park, Jae-Hyeon},
journal = {Journal of Athletic Training},
month = {mar},
number = {2},
pages = {215--221},
title = {{Issues in Outcomes Research: An Overview of Randomization Techniques for Clinical Trials}},
volume = {43},
year = {2008}
}
@misc{TheFallacyofPlaci:il,
author = {Morey, Richard and Wagenmakers, Eric-Jan and Hoekstra, Rink and Rouder, Jeffrey and Lee, Michael D},
title = {{The Fallacy of Placing Confidence in Confidence Intervals}}
}
@article{Liu2015a,
abstract = {In phase I trials, effectively treating patients and minimizing the chance of exposing them to subtherapeutic and overly toxic doses are clinicians' top priority. Motived by this practical consideration, we propose Bayesian optimal interval (BOIN) designs to find the maximum tolerated dose and to minimize the probability of inappropriate dose assignments for patients. We show, both theoretically and numerically, that the BOIN design not only has superior finite and large sample properties but also can be easily implemented in a simple way similar to the traditional '3+3' design. Compared with the well-known continual reassessment method, the BOIN design yields comparable average performance to select the maximum tolerated dose but has a substantially lower risk of assigning patients to subtherapeutic and overly toxic doses. We apply the BOIN design to two cancer clinical trials.},
author = {Liu, Suyu and Yuan, Ying},
doi = {10.1111/rssc.12089},
file = {::},
issn = {14679876},
journal = {Journal of the Royal Statistical Society. Series C: Applied Statistics},
keywords = {Bayesian adaptive design,Decision error,Dose finding,Maximum tolerated dose},
number = {3},
pages = {507--523},
title = {{Bayesian optimal interval designs for phase I clinical trials}},
volume = {64},
year = {2015}
}
@article{zhou2008bayesian,
author = {Zhou, Xian and Liu, Suyu and Kim, Edward S and Herbst, Roy S and Lee, J Jack},
file = {::},
journal = {Clinical Trials},
number = {3},
pages = {181--193},
publisher = {SAGE Publications Sage UK: London, England},
title = {{Bayesian adaptive design for targeted therapy development in lung cancer—a step toward personalized medicine}},
volume = {5},
year = {2008}
}
@article{Berry2006,
abstract = {Bayesian statistical methods are being used increasingly in clinical research because the Bayesian approach is ideally suited to adapting to information that accrues during a trial, potentially allowing for smaller more informative trials and for patients to receive better treatment. Accumulating results can be assessed at any time, including continually, with the possibility of modifying the design of the trial, for example, by slowing (or stopping) or expanding accrual, imbalancing randomization to favour better-performing therapies, dropping or adding treatment arms, and changing the trial population to focus on patient subsets that are responding better to the experimental therapies. Bayesian analyses use available patient-outcome information, including biomarkers that accumulating data indicate might be related to clinical outcome. They also allow for the use of historical information and for synthesizing results of relevant trials. Here, I explain the rationale underlying Bayesian clinical trials, and discuss the potential of such trials to improve the effectiveness of drug development.},
author = {Berry, Donald A.},
doi = {10.1038/nrd1927},
file = {::},
issn = {14741776},
journal = {Nature Reviews Drug Discovery},
number = {1},
pages = {27--36},
pmid = {16485344},
title = {{A guide to drug discovery: Bayesian clinical trials}},
volume = {5},
year = {2006}
}
@article{Sundstrom:2011gs,
author = {Sundstrom, J and Byberg, L and Gedeborg, R and Michaelsson, K and Berglund, L},
journal = {Scandinavian Journal of Public Health},
month = {may},
number = {4},
pages = {439--441},
title = {{Useful tests of usefulness of new risk factors: Tools for assessing reclassification and discrimination}},
volume = {39},
year = {2011}
}
@article{Krieger2019,
abstract = {In an order-of-addition experiment, each treatment is a permutation of m components. It is often unaffordable to test all the m! possible treatments, and thus the design problem arises.We consider a flexible model that incorporates the order of each pair of components and can also account for the distance between the two components in every such pair. Under this model, the optimality of the uniform design measure is established, via the approximate theory, for a broad range of criteria. Coupled with an eigenanalysis, this result serves as a benchmark that paves he way for assessing the efficiency and robustness of any exact design. The closed-form construction of a class of robust optimal fractional designs that can also facilitate model selection is explored and illustrated.},
archivePrefix = {arXiv},
arxivId = {1612.02315},
author = {Krieger, A. M. and Azriel, D. and Kapelner, A.},
doi = {10.1093/biomet/asz026},
eprint = {1612.02315},
issn = {14643510},
journal = {Biometrika},
keywords = {Experimental design,Optimal experimental design,Optimization,Restricted randomization},
number = {3},
pages = {695--701},
title = {{Nearly random designs with greatly improved balance}},
volume = {106},
year = {2019}
}
@article{Yates:1982hi,
author = {Yates, J Frank},
journal = {Organizational Behavior and Human Performance},
month = {aug},
number = {1},
pages = {132--156},
title = {{External correspondence: Decompositions of the mean probability score}},
volume = {30},
year = {1982}
}
@article{McGeechan:2008ie,
author = {McGeechan, Kevin and Macaskill, Petra and Irwig, Les and Liew, Gerald and Wong, Tien Y},
journal = {Archives of Internal Medicine},
month = {nov},
number = {21},
pages = {2304},
title = {{Assessing New Biomarkers and Predictive Models for Use in Clinical Practice}},
volume = {168},
year = {2008}
}
@article{Connor2020,
author = {Connor, Jason},
file = {::},
title = {{Statistical Design {\&} Conduct of Platform Trials}},
year = {2020}
}
@article{Uno:2011hf,
author = {Uno, Hajime and Cai, Tianxi and Pencina, Michael J and D'Agostino, Ralph B and Wei, L J},
journal = {Statistics in medicine},
month = {jan},
pages = {n/a----n/a},
title = {{On the C-statistics for evaluating overall adequacy of risk prediction procedures with censored survival data}},
year = {2011}
}
@article{Royston2003,
abstract = {With the increasing pace of drug development, it is not unusual for several promising treatment regimens to be ready simultaneously for testing in a randomized phase III setting. Various limiting factors, including the time needed to transfer research results to clinical practice and a narrow 'window of opportunity', may make it unfeasible to perform trials to test such regimens sequentially against a control treatment in a traditional two-arm parallel group design. We present an approach to trial design based on eliminating inferior contenders at an early stage, allowing through to a second stage only treatments that show a predefined degree of advantage against a control treatment. The first stage of testing utilizes a marker known to be a valid intermediate outcome measure or surrogate for the definitive outcome. The experimental arms are compared pairwise with control according to this intermediate outcome measure. Arms that survive the comparison enter a second stage of patient accrual culminating in comparisons against control on the outcome measure of primary interest. We show how the design may be realized in practice by considering hypothetically distinct trials at stages 1 and 2, each with their own operating characteristics. The overall operating characteristics are computed from the stage 1 and 2 size and power and the correlation between the treatment effects on the intermediate and primary outcome measures according to a bivariate Normal approximation. The correlation is estimated by bootstrapping individual patient data from previous trials. We illustrate the general approach in a design of a real trial of four new chemotherapy regimens for advanced ovarian cancer. The intermediate outcome measure is progression-free survival. An international randomized controlled trial using the new design is already under way. Copyright {\textcopyright} 2003 John Wiley {\&} Sons, Ltd.},
author = {Royston, Patrick and Parmar, Mahesh K.B. and Qian, Wendi},
doi = {10.1002/sim.1430},
file = {::},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Multi-arm trials,Ovarian cancer,Surrogate markers,Survival time,Two-stage trials},
number = {14},
pages = {2239--2256},
pmid = {12854091},
title = {{Novel designs for multi-arm clinical trials with survival outcomes with an application in ovarian cancer}},
volume = {22},
year = {2003}
}
@article{Bossuyt:2006cw,
author = {Bossuyt, P M},
journal = {BMJ},
month = {may},
number = {7549},
pages = {1089--1092},
title = {{Comparative accuracy: assessing new tests against existing diagnostic pathways}},
volume = {332},
year = {2006}
}
@article{Greenland:2008kn,
author = {Greenland, Philip},
journal = {Statistics in medicine},
number = {2},
pages = {188--190},
title = {{Comments on {\{}$\backslash$textquoteleft{\}}Evaluating the added predictive ability of a new marker: From area under the ROC curve to reclassification and beyond{\{}$\backslash$textquoteright{\}} by M. J. Pencina, R. B. D'Agostino Sr, R. B. D'Agostino Jr, R. S. Vasan,Statistics in Medici}},
volume = {27},
year = {2007}
}
@article{Wu2016,
author = {Wu, Y P and Aspinwall, L G and Conn, B M and Stump, T and Grahmann, B and Leachman, S A},
doi = {10.1016/j.ypmed.2016.04.010},
issn = {0091-7435},
journal = {Prev Med},
pages = {153--167},
title = {{A systematic review of interventions to improve adherence to melanoma preventive behaviors for individuals at elevated risk}},
volume = {88},
year = {2016}
}
@article{sebille2001comparison,
author = {S{\'{e}}bille, V{\'{e}}ronique and Bellissant, Eric},
file = {::},
journal = {Controlled Clinical Trials},
number = {5},
pages = {503--514},
publisher = {Elsevier},
title = {{Comparison of the two-sided single triangular test to the double triangular test}},
volume = {22},
year = {2001}
}
@article{Parmigiani:1998uy,
author = {Parmigiani, Giovanni and Berry, Donald A and Aguilar, Omar},
journal = {The American Journal of Human Genetics},
month = {jan},
number = {1},
pages = {145--158},
title = {{Determining Carrier Probabilities for Breast Cancer{\{}$\backslash$textendash{\}}Susceptibility Genes BRCA1 and BRCA2}},
volume = {62},
year = {1998}
}
@book{siegmund1985sequential,
author = {Siegmund, David},
publisher = {Springer Science {\&} Business Media},
title = {{Sequential analysis: tests and confidence intervals}},
year = {1985}
}
@article{Xu:2009cc,
author = {Xu, Zhenzhen and Kalbfleisch, John D},
journal = {Biometrics},
month = {nov},
number = {3},
pages = {813--823},
title = {{Propensity Score Matching in Randomized Clinical Trials}},
volume = {66},
year = {2009}
}
@article{Lin2017,
abstract = {Platforms trials are clinical trials that allow for concurrent evaluations of multiple treatments, thus allowing for more efficient and ethical studies compared to traditional two-arm trials. Conventional group-sequential multi-arm multi-stage (MAMS) designs use pre-specified stopping boundaries and treatment selection rules to determine if experimental treatments should be dropped. Flexible MAMS designs allow for interim modifications to the design plan without compromising error rates. Bayesian response adaptive randomization (BRAR) designs increase patient allocation to treatment arms that are performing well during the course of the trial. In this paper, we compare these two major methods and their extensions under several scenarios in the platform trials setting. Results show that BRAR and flexible MAMS designs have comparable power and type 1 error rate under varying simulated scenarios, allowing for addition of flexible treatment selection. BRAR outperforms flexible MAMS when there is a single effective treatment. Flexible MAMS designs are more efficient compared to BRAR when there are no effective treatments. BRAR performance increases as the probability of a treatment arm being dropped increases.},
author = {Lin, Jianchang and Bunn, Veronica},
doi = {10.1016/j.cct.2017.01.003},
file = {::},
issn = {15592030},
journal = {Contemporary Clinical Trials},
keywords = {Adaptive randomization,Bayesian adaptive design,MAMS,Multi-arm multi-stage (MAMS),Platform trials,RAR},
mendeley-tags = {MAMS,RAR},
number = {March},
pages = {48--59},
pmid = {28089763},
publisher = {Elsevier Inc.},
title = {{Comparison of multi-arm multi-stage design and adaptive randomization in platform clinical trials}},
url = {http://dx.doi.org/10.1016/j.cct.2017.01.003},
volume = {54},
year = {2017}
}
@article{Angrist:1996df,
author = {Angrist, Joshua D and Imbens, Guido W and Rubin, Donald B},
journal = {Journal of the American Statistical Association},
month = {jun},
number = {434},
pages = {444--455},
title = {{Identification of Causal Effects Using Instrumental Variables}},
volume = {91},
year = {1996}
}
@article{Anonymous:pln-KA5W,
month = {aug},
pages = {1--17},
title = {{TUTORIAL IN BIOSTATISTICS PROPENSITY SCORE METHODS FOR BIAS REDUCTION IN THE COMPARISON OF A TREATMENT TO A NON-RANDOMIZED CONTROL GROUP}},
year = {1998}
}
@article{Carter2019,
abstract = {BACKGROUND: Mutations in DNA repair genes are associated with aggressive prostate cancer (PCa). OBJECTIVE: To assess whether germline mutations are associated with grade reclassification (GR) in patients undergoing active surveillance (AS). DESIGN, SETTING, AND PARTICIPANTS: Two independent cohorts of PCa patients undergoing AS; 882 and 329 patients from Johns Hopkins and North Shore, respectively. OUTCOME MEASUREMENTS AND STATISTICAL ANALYSIS: Germline DNA was sequenced for DNA repair genes, including BRCA1/2 and ATM (three-gene panel). Pathogenicity of mutations was defined according to the American College of Medical Genetics guidelines. Association of mutation carrier status and GR was evaluated by a competing risk analysis. RESULTS AND LIMITATIONS: Of 1211, 289 patients experienced GR; 11 of 26 with mutations in a three-gene panel and 278 of 1185 noncarriers; adjusted hazard ratio (HR)=1.96 (95{\%} confidence interval [CI]=1.004-3.84, p=0.04). Reclassification occurred in six of 11 carriers of BRCA2 mutations and 283 of 1200 noncarriers; adjusted HR=2.74 (95{\%} CI=1.26-5.96, p=0.01). The carrier rates of pathogenic mutations in the three-gene panel, and BRCA2 alone, were significantly higher in those reclassified (3.8{\%} and 2.1{\%}, respectively) than in those not reclassified (1.6{\%} and 0.5{\%}, respectively; p=0.04 and 0.03, respectively). Carrier rates for BRCA2 were greater for those reclassified from Gleason score (GS) 3+3 at diagnosis to GS {\textgreater}/=4+3 (4.1{\%} vs 0.7{\%}, p=0.01) versus GS 3+4 (2.1{\%} vs 0.6{\%}; p=0.03). Results are limited by the small number of mutation carriers and an intermediate end point. CONCLUSIONS: Mutation status of BRCA1/2 and ATM is associated with GR among men undergoing AS. PATIENT SUMMARY: Men on active surveillance with inherited mutations in BRCA1/2 and ATM are more likely to harbor aggressive prostate cancer.},
author = {Carter, H Ballentine and Helfand, Brian and Mamawala, Mufaddal and Wu, Yishuo and Landis, Patricia and Yu, Hongjie and Wiley, Kathleen and Na, Rong and Shi, Zhuqing and Petkewicz, Jacqueline and Shah, Sameep and Fantus, Richard J and Novakovic, Kristian and Brendler, Charles B and Zheng, S Lilly and Isaacs, William B and Xu, Jianfeng},
doi = {10.1016/j.eururo.2018.09.021},
issn = {1873-7560 (Electronic)},
journal = {European urology},
language = {eng},
month = {may},
number = {5},
pages = {743--749},
pmid = {30309687},
title = {{Germline Mutations in ATM and BRCA1/2 Are Associated with Grade Reclassification in Men on Active Surveillance for Prostate Cancer.}},
volume = {75},
year = {2019}
}
@misc{Beck2016,
author = {Beck, Cole and Lu, Bo and Greevy, Robert and Beck, Maintainer Cole},
publisher = {CRAN},
title = {{Package ‘nbpMatching'}},
year = {2016}
}
@article{Quigley:2005ep,
author = {Quigley, Charmian A and Gill, Anne M and Crowe, Brenda J and Robling, Kristen and Chipman, John J and Rose, Susan R and Ross, Judith L and Cassorla, Fernando G and Wolka, Anne M and Wit, Jan M and Rekers-Mombarg, Lyset T M and {Cutler Jr.}, Gordon B},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {sep},
number = {9},
pages = {5188--5196},
title = {{Safety of Growth Hormone Treatment in Pediatric Patients with Idiopathic Short Stature}},
volume = {90},
year = {2005}
}
@article{Vickers:2013ev,
author = {Vickers, Andrew J and for the {Acupuncture Trialists' Collaboration}},
journal = {JAMA Internal Medicine},
month = {apr},
number = {8},
pages = {713},
title = {{Placing Acupuncture in Perspective{\{}$\backslash$textemdash{\}}Reply}},
volume = {173},
year = {2013}
}
@article{Peirce:1884wr,
author = {Peirce, C S and Jastrow, J},
journal = {Memoirs of the National Academy of Sciences},
pages = {73--83},
title = {{On small differences in sensation}},
volume = {III},
year = {1884}
}
@article{anscombe1954fixed,
author = {Anscombe, Francis J},
journal = {Biometrics},
number = {1},
pages = {89--100},
publisher = {JSTOR},
title = {{Fixed-sample-size analysis of sequential observations}},
volume = {10},
year = {1954}
}
@article{Anonymous:jjVLtlRp,
month = {dec},
pages = {1--33},
title = {{Statistical Modeling: The Two Cultures}},
year = {2001}
}
@book{harrell2015regression,
address = {Cham},
author = {Harrell, Frank E},
publisher = {Springer International Publishing},
series = {Springer Series in Statistics},
title = {{Regression Modeling Strategies}},
year = {2015}
}
@article{Head2013,
author = {Head, Katharine J and Noar, Seth M and Iannarino, Nicholas T and Harrington, Nancy Grant},
issn = {0277-9536},
journal = {Social Science {\&} Medicine},
pages = {41--48},
title = {{Efficacy of text messaging-based interventions for health promotion: a meta-analysis}},
volume = {97},
year = {2013}
}
@article{Chipman2014,
abstract = {PURPOSE: We expanded the clinical usefulness of EPIC-CP (Expanded Prostate Cancer Index Composite for Clinical Practice) by evaluating its responsiveness to health related quality of life changes, defining the minimally important differences for an individual patient change in each domain and applying it to a sexual outcome prediction model. MATERIALS AND METHODS: In 1,201 subjects from a previously described multicenter longitudinal cohort we modeled the EPIC-CP domain scores of each treatment group before treatment, and at short-term and long-term followup. We considered a posttreatment domain score change from pretreatment of 0.5 SD or greater clinically significant and p {\textless}/= 0.01 statistically significant. We determined the domain minimally important differences using the pooled 0.5 SD of the 2, 6, 12 and 24-month posttreatment changes from pretreatment values. We then recalibrated an EPIC-CP based nomogram model predicting 2-year post-prostatectomy functional erection from that developed using EPIC-26. RESULTS: For each health related quality of life domain EPIC-CP was sensitive to similar posttreatment health related quality of life changes with time, as was observed using EPIC-26. The EPIC-CP minimally important differences in changes in the urinary incontinence, urinary irritation/obstruction, bowel, sexual and vitality/hormonal domains were 1.0, 1.3, 1.2, 1.6 and 1.0, respectively. The EPIC-CP based sexual prediction model performed well (AUC 0.76). It showed robust agreement with its EPIC-26 based counterpart with 10{\%} or less predicted probability differences between models in 95{\%} of individuals and a mean +/- SD difference of 0.0 +/- 0.05 across all individuals. CONCLUSIONS: EPIC-CP is responsive to health related quality of life changes during convalescence and it can be used to predict 2-year post-prostatectomy sexual outcomes. It can facilitate shared medical decision making and patient centered care.},
author = {Chipman, Jonathan J and Sanda, Martin G and Dunn, Rodney L and Wei, John T and Litwin, Mark S and Crociani, Catrina M and Regan, Meredith M and Chang, Peter},
doi = {10.1016/j.juro.2013.09.040},
institution = {PROST-QA Consortium},
issn = {1527-3792 (Electronic)},
journal = {The Journal of urology},
keywords = {Humans,Intestinal Diseases,Longitudinal Studies,Male,Middle Aged,Postoperative Complications,Predictive Value of Tests,Prospective Studies,Prostatectomy,Prostatic Neoplasms,Quality of Life,Sexual Dysfunction, Physiological,Surveys and Questionnaires,Urologic Diseases,physiopathology,psychology,radiotherapy,surgery},
language = {eng},
month = {mar},
number = {3},
pages = {638--645},
pmid = {24076307},
title = {{Measuring and predicting prostate cancer related quality of life changes using EPIC for clinical practice.}},
volume = {191},
year = {2014}
}
@article{Rao:1992ii,
author = {Rao, C Radhakrishna},
journal = {Statistical Science},
month = {feb},
number = {1},
pages = {34--48},
title = {{R. A. Fisher: The Founder of Modern Statistics}},
volume = {7},
year = {1992}
}
@article{Proschan2011,
author = {Proschan, Michael and Brittain, Erica and Kammerman, Lisa and Proschan, Michael and Brittain, Erica and Kammerman, Lisa},
doi = {10.1111/j.l541-0420.2010.01545.x},
file = {::},
keywords = {1,adaptive randomization,an eye opening experience,analyze as you randomize,asymptotics,junction with a rerandomization,minimization,permutation test,permuted block randomiza-,randomization,rerandomization test,temporal trend,test,the rerandomization,tion,unequal allocation},
number = {3},
pages = {1135--1141},
title = {{Minimize the Use of Minimization with Unequal Allocation Published by : International Biometric Society REFERENCES Linked references are available on JSTOR for this article : You may need to log in to JSTOR to access the linked references . Minimize the U}},
volume = {67},
year = {2011}
}
@article{,
title = {{No Title}},
url = {https://obamawhitehouse.archives.gov/precision-medicine}
}
@article{kapelner2020matching,
author = {Kapelner, Adam and Krieger, Abba},
journal = {arXiv preprint arXiv:2010.05980},
title = {{A Matching Procedure for Sequential Experiments that Iteratively Learns which Covariates Improve Power}},
year = {2020}
}
@article{Steyerberg:2010cz,
author = {Steyerberg, Ewout W and Vickers, Andrew J and Cook, Nancy R and Gerds, Thomas and Gonen, Mithat and Obuchowski, Nancy and Pencina, Michael J and Kattan, Michael W},
journal = {Epidemiology},
month = {jan},
number = {1},
pages = {128--138},
title = {{Assessing the Performance of Prediction Models}},
volume = {21},
year = {2010}
}
@article{Spiegelhalter:1994cn,
author = {Spiegelhalter, David J and Freedman, Laurence S and Parmar, Mahesh K B},
journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
number = {3},
pages = {357},
title = {{Bayesian Approaches to Randomized Trials}},
volume = {157},
year = {1994}
}
@article{BenVanCalster:2016im,
author = {Calster, Ben Van and Nieboer, Daan and Vergouwe, Yvonne and {De Cock}, Bavo and Pencina, Michael J and Steyerberg, Ewout W},
journal = {Journal of Clinical Epidemiology},
month = {jun},
number = {C},
pages = {167--176},
title = {{A calibration hierarchy for risk models was defined: from utopia to empirical data}},
volume = {74},
year = {2016}
}
@article{Chipman2022,
abstract = {Background: Sequential Matched Randomization (SMR) is one of multiple recent covariate-adaptive randomization (CAR) procedures that utilize a distance matrix to improve covariate-balance and estimation efficiency. Randomization occurs within mates whose distance meet an a-priori, fixed similarity quantile of random distances. Methods: We extend SMR to allow multiple participants to be randomized simultaneously, to allow matches to break and rematch if a better match later enrolls (Sequential Rematched Randomization; SRR), and to use a dynamic threshold. In simplified settings which vary covariate distribution and association upon outcome, we compare end-study covariate-balance and estimator efficiency in SMR before and after extensions. In a real-world application, we compare covariate-balance, power, and estimator efficiency of SMR before and after extensions when adjusting for priority covariates and all covariates of interest. We compare with Complete Randomization (CR) and CR followed by a flexible, covariate-adjusted regression model. As side-by-side comparisons, we include stratified randomization, D{\$}{\_}A{\$} optimality biased coin design (D{\$}{\_}A{\$}-BCD), and Pairwise Sequential Randomization (PSR). Results: In both the simplified and real-world application, we observe benefits of each extension upon covariate balance and estimator efficiency. In the real-world application, SRR with a dynamic threshold, D{\$}{\_}A{\$}-BCD, and PSR provide greater power than CR followed by a covariate-adjusted regression model. Matching methods achieved greater covariate-balance when adjusting for all covariates yet greater power and efficiency when adjusting for priority covariates. Conclusion: We improve upon SMR and show the potential for CAR methods -- that adjusting for covariates in randomization can outperform covariate adjustment in a flexible regression model.},
archivePrefix = {arXiv},
arxivId = {2203.13797},
author = {Chipman, Jonathan J. and Mayberry, Lindsay and Greevy, Robert A.},
eprint = {2203.13797},
pages = {1--13},
title = {{Sequential matched randomization and a case for covariate-adaptive randomization}},
url = {http://arxiv.org/abs/2203.13797},
year = {2022}
}
@article{Wald:1973vc,
author = {Koell, Christophe},
journal = {Sequential Analysis},
month = {jan},
number = {4},
pages = {341--360},
title = {{Asymptotic optimality of the wald sequential test}},
volume = {14},
year = {1995}
}
@article{Goodman:2011bb,
author = {Goodman, S N and Royall, R},
journal = {American Journal of Public Health},
month = {dec},
number = {12},
pages = {1568--1574},
title = {{Evidence and scientific research.}},
volume = {78},
year = {1988}
}
@article{Pepe:2013er,
author = {Pepe, Margaret Sullivan and Kerr, Kathleen F and Longton, Gary and Wang, Zheyu},
journal = {Statistics in medicine},
month = {jan},
number = {9},
pages = {1467--1482},
title = {{Testing for improvement in prediction model performance}},
volume = {32},
year = {2013}
}
@article{Chipman2013,
abstract = {Cancer risk prediction tools provide valuable information to clinicians but remain computationally challenging. Many clinics find that CaGene or HughesRiskApps fit their needs for easy- and ready-to-use software to obtain cancer risks; however, these resources may not fit all clinics' needs. The HughesRiskApps Group and BayesMendel Lab therefore developed a web service, called "Risk Service", which may be integrated into any client software to quickly obtain standardized and up-to-date risk predictions for BayesMendel tools (BRCAPRO, MMRpro, PancPRO, and MelaPRO), the Tyrer-Cuzick IBIS Breast Cancer Risk Evaluation Tool, and the Colorectal Cancer Risk Assessment Tool. Software clients that can convert their local structured data into the HL7 XML-formatted family and clinical patient history (Pedigree model) may integrate with the Risk Service. The Risk Service uses Apache Tomcat and Apache Axis2 technologies to provide an all Java web service. The software client sends HL7 XML information containing anonymized family and clinical history to a Dana-Farber Cancer Institute (DFCI) server, where it is parsed, interpreted, and processed by multiple risk tools. The Risk Service then formats the results into an HL7 style message and returns the risk predictions to the originating software client. Upon consent, users may allow DFCI to maintain the data for future research. The Risk Service implementation is exemplified through HughesRiskApps. The Risk Service broadens the availability of valuable, up-to-date cancer risk tools and allows clinics and researchers to integrate risk prediction tools into their own software interface designed for their needs. Each software package can collect risk data using its own interface, and display the results using its own interface, while using a central, up-to-date risk calculator. This allows users to choose from multiple interfaces while always getting the latest risk calculations. Consenting users contribute their data for future research, thus building a rich multicenter resource.},
author = {Chipman, Jonathan and Drohan, Brian and Blackford, Amanda and Parmigiani, Giovanni and Hughes, Kevin and Bosinoff, Phil},
doi = {10.1007/s10549-013-2605-z},
issn = {1573-7217 (Electronic)},
journal = {Breast cancer research and treatment},
keywords = {Algorithms,Breast Neoplasms,Female,Humans,Internet,Pedigree,Risk Assessment,Software,User-Computer Interface,genetics,methods},
language = {eng},
month = {jul},
number = {1},
pages = {187--193},
pmid = {23793601},
title = {{Providing access to risk prediction tools via the HL7 XML-formatted risk web service.}},
volume = {140},
year = {2013}
}
@article{lachin1981introduction,
author = {Lachin, John M},
journal = {Controlled clinical trials},
number = {2},
pages = {93--113},
publisher = {Elsevier},
title = {{Introduction to sample size determination and power analysis for clinical trials}},
volume = {2},
year = {1981}
}
@article{VanHouwelingen:1990js,
author = {{Van Houwelingen}, J C and {Le Cessie}, S},
journal = {Statistics in medicine},
month = {nov},
number = {11},
pages = {1303--1325},
title = {{Predictive value of statistical models}},
volume = {9},
year = {1990}
}
@article{Renfro2014,
abstract = {Background: Frequently a biomarker capable of defining a patient population with enhanced response to an experimental agent is not fully validated with a known threshold at the start of a phase II trial. When such candidate predictive markers are evaluated and/or validated retrospectively, over-accrual of patients less likely to benefit from the regimen may result, leading to underpowered analyses or sub-optimal patient care. Purpose: We propose an adaptive randomized phase II study design incorporating prospective biomarker threshold identification (or non-identification), possible early futility stopping, potential mid-trial accrual restriction to marker-positive subjects, and final marker and treatment evaluation in the patient population identified as most likely to benefit. Methods: An interim analysis is used to determine whether an initially unselected trial should stop early for futility, continue without a promising marker, or adapt accrual and resize (up to a pre-determined maximum) according to a promising biomarker. Final efficacy analyses are performed in the target population identified at the interim as most likely to benefit from the experimental regimen. Simulation studies demonstrate control of false-positive error rates, power, reduced average sample size, and other favorable aspects. Results: The design performs well at identifying a truly predictive biomarker at interim analysis, and subsequently restricting accrual to patients most likely to benefit from the experimental treatment. Type I and type II error rates are adequately controlled by restricting the range of marker prevalence via the candidate thresholds, and by careful consideration of the timing of interim analysis. Conclusions: In situations where identification and validation of a naturally continuous biomarker are desired within a randomized phase II trial, the design presented herein offers a potential solution.},
author = {Renfro, Lindsay A. and Coughlin, Christina M. and Grothey, Axel M. and Sargent, Daniel J.},
doi = {10.3978/j.issn.2304-3865.2013.12.04},
file = {::},
issn = {23043873},
journal = {Chinese Clinical Oncology},
keywords = {Adaptive design,Interim futility analysis,Phase II trial,Predictive biomarker,Randomized clinical trial,Threshold identification},
number = {1},
pages = {1--14},
title = {{Adaptive randomized phase II design for biomarker threshold selection and independent evaluation}},
volume = {3},
year = {2014}
}
@article{Nick:1999dz,
author = {Nick, T G and Hardin, J M},
journal = {American Journal of Occupational Therapy},
month = {sep},
number = {5},
pages = {459--470},
title = {{Regression Modeling Strategies: An Illustrative Case Study From Medical Rehabilitation Outcomes Research}},
volume = {53},
year = {1999}
}
@article{TheSPRINTResearchGroup:2015dw,
author = {{The SPRINT Research Group}},
journal = {New England Journal of Medicine},
month = {nov},
number = {22},
pages = {2103--2116},
title = {{A Randomized Trial of Intensive versus Standard Blood-Pressure Control}},
volume = {373},
year = {2015}
}
@article{Bang:2005gx,
author = {Bang, Heejung and Robins, James M},
journal = {Biometrics},
month = {dec},
number = {4},
pages = {962--973},
title = {{Doubly Robust Estimation in Missing Data and Causal Inference Models}},
volume = {61},
year = {2005}
}
@article{Hoch:2008ck,
author = {Hoch, Jeffrey S and Blume, Jeffrey D},
journal = {Journal of Health Economics},
month = {mar},
number = {2},
pages = {476--495},
title = {{Measuring and illustrating statistical evidence in a cost-effectiveness analysis}},
volume = {27},
year = {2008}
}
@article{DeLaurentiis:1999uh,
author = {{De Placido}, Sabino and Carlomagno, Chiara and {De Laurentiis}, Michelino and Bianco, Angelo Raffaele},
journal = {Breast Cancer Research and Treatment},
month = {nov},
number = {1-3},
pages = {55--64},
title = {{c-erbB2 expression predicts tamoxifen efficacy in breast cancer patients}},
volume = {52},
year = {1998}
}
@article{low2018fitbit,
abstract = {Background Postoperative ambulation is encouraged to promote timely recovery but is rarely monitored objectively or examined as a predictor of clinical outcomes, despite growing availability of wearable devices that allow passive quantification and remote real-time monitoring of the number of steps taken during recovery. Purpose To determine whether the number of steps taken during inpatient recovery predicts 30- and 60-day readmission risk after metastatic cancer surgery. Methods Patients diagnosed with metastatic peritoneal cancer and scheduled for surgical resection were enrolled in this observational cohort study at their preoperative clinic visit. Fitbits were placed on patients' wrists upon transfer from the ICU following surgery and worn for the duration of their inpatient stay. Information about hospital readmission was extracted from electronic medical records. Results Seventy-one patients participated in the study (mean age = 57.14, range = 31–80 years; 42{\%} female; 51{\%} diagnosed with appendiceal cancer). Mean steps per day were calculated for each participant over the entire inpatient recovery period (mean stay = 12.12 days, 4–37 days). Readmission within 30 and 60 days was medically indicated for 34{\%} and 39{\%} of patients, respectively. After statistically adjusting for age, body mass index, comorbidity, and length of postoperative stay, higher mean steps per day predicted lower 30-day and 60-day readmission risk. Conclusions Higher Fitbit step counts during inpatient recovery predicted lower risk of 30- and 60-day readmission after surgery for metastatic peritoneal cancer. Results suggest that passively monitoring perioperative ambulation may identify patients at risk for readmission and highlight opportunities for behavioral intervention.},
author = {Low, Carissa A. and Bovbjerg, Dana H. and Ahrendt, Steven and {Haroon Choudry}, M. and Holtzman, Matthew and Jones, Heather L. and Pingpank, James F. and Ramalingam, Lekshmi and Zeh, Herbert J. and Zureikat, Amer H. and Bartlett, David L.},
doi = {10.1093/abm/kax022},
file = {::},
issn = {15324796},
journal = {Annals of Behavioral Medicine},
keywords = {Cancer,Physical activity,Readmission,Surgical oncology},
number = {1},
pages = {88--92},
pmid = {29538623},
title = {{Fitbit step counts during inpatient recovery from cancer surgery as a predictor of readmission}},
volume = {52},
year = {2018}
}
@article{Rosenberger:2008cm,
author = {Rosenberger, W F and Sverdlov, O},
title = {{Handling covariates in the design of clinical trials}},
year = {2008}
}
@book{cook2007introduction,
author = {Cook, Thomas D and DeMets, David L},
publisher = {CRC Press},
title = {{Introduction to statistical methods for clinical trials}},
year = {2007}
}
@article{Dimakopoulou2021,
author = {Dimakopoulou, Maria and Kallus, Nathan and Chambaz, Antoine},
number = {NeurIPS},
title = {{Post-Contextual-Bandit Inference}},
year = {2021}
}
@article{fleiss1981statistical,
author = {Fleiss, J L and Levin, B and Paik, M C},
journal = {New York},
title = {{Statistical methods for rates and proportions. John Wiley {\&} Sons}},
volume = {870},
year = {1981}
}
@article{little1993pattern,
author = {Little, Roderick J A},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Little - 1993 - Pattern-mixture models for multivariate incomplete data.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {421},
pages = {125--134},
publisher = {Taylor {\&} Francis},
title = {{Pattern-mixture models for multivariate incomplete data}},
volume = {88},
year = {1993}
}
@article{Zou:2006du,
author = {Zou, Hui},
journal = {Journal of the American Statistical Association},
month = {nov},
number = {476},
pages = {1--13},
title = {{Journal of the American Statistical Association}},
volume = {101},
year = {2006}
}
@article{Li:2010cq,
author = {Li, Lingling and Kulldorff, Martin},
journal = {Statistics in medicine},
month = {jan},
number = {2},
pages = {284--295},
title = {{A conditional maximized sequential probability ratio test for pharmacovigilance.}},
volume = {29},
year = {2010}
}
@article{Hilden:ITVsQx52,
author = {Hilden, Jorgen and Gerds, Thomas A},
journal = {Statistics in medicine},
month = {apr},
number = {19},
pages = {3405--3414},
title = {{A note on the evaluation of novel biomarkers: do not rely on integrated discrimination improvement and net reclassification index}},
volume = {33},
year = {2013}
}
@article{Calverley2021,
author = {Calverley, Peter},
doi = {10.1164/rccm.202012-4300ED},
isbn = {2020124300},
issn = {15354970},
journal = {American Journal of Respiratory and Critical Care Medicine},
number = {5},
pages = {531--532},
pmid = {33326362},
title = {{Reigniting the TORCH: Chronic obstructive pulmonary disease mortality and inhaled corticosteroids revisited}},
volume = {203},
year = {2021}
}
@book{Anonymous:2016tp,
address = {Hoboken, NJ, USA},
month = {sep},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Introduction to Bayesian Statistics, Third Edition}},
year = {2016}
}
@article{Mercado:2012kg,
author = {Mercado, Rowena C and Hampel, Heather and Kastrinos, Fay and Steyerberg, Ewout and Balma{\~{n}}a, Judith and Stoffel, Elena and Cohn, David E and Backes, Floor J and Hopper, John L and Jenkins, Mark A and Lindor, Noralane M and Casey, Graham and Haile, Robert and Madhavan, Subha and de la Chapelle, Albert and Syngal, Sapna},
journal = {Genetics in Medicine},
month = {mar},
number = {7},
pages = {670--680},
title = {{Performance of PREMM1,2,6, MMRpredict, and MMRpro in detecting Lynch syndrome among endometrial cancer cases}},
volume = {14},
year = {2012}
}
@article{Anonymous:ri91laqx,
author = {Lakens, D and Adolfi, F G and Albers, C J and Human, F Anvari Nature and 2018},
journal = {nature.com},
title = {{Justify your alpha}}
}
@techreport{Anonymous:2016tz,
title = {{ACCRE: SLURM}},
year = {2016}
}
@article{Ding2019,
abstract = {Understanding and characterizing treatment effect variation in randomized experiments has become essential for going beyond the “black box” of the average treatment effect. Nonetheless, traditional statistical approaches often ignore or assume away such variation. In the context of randomized experiments, this article proposes a framework for decomposing overall treatment effect variation into a systematic component explained by observed covariates and a remaining idiosyncratic component. Our framework is fully randomization-based, with estimates of treatment effect variation that are entirely justified by the randomization itself. Our framework can also account for noncompliance, which is an important practical complication. We make several contributions. First, we show that randomization-based estimates of systematic variation are very similar in form to estimates from fully interacted linear regression and two-stage least squares. Second, we use these estimators to develop an omnibus test for systematic treatment effect variation, both with and without noncompliance. Third, we propose an R 2 -like measure of treatment effect variation explained by covariates and, when applicable, noncompliance. Finally, we assess these methods via simulation studies and apply them to the Head Start Impact Study, a large-scale randomized experiment. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {1605.06566},
author = {Ding, Peng and Feller, Avi and Miratrix, Luke},
doi = {10.1080/01621459.2017.1407322},
eprint = {1605.06566},
file = {::},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Heterogeneous treatment effect,Idiosyncratic treatment effect variation,Noncompliance,Randomization inference,Systematic treatment effect variation},
number = {525},
pages = {304--317},
publisher = {Taylor {\&} Francis},
title = {{Decomposing Treatment Effect Variation}},
url = {https://doi.org/10.1080/01621459.2017.1407322},
volume = {114},
year = {2019}
}
@article{diener1989identification,
author = {Diener-West, Marie and Dobbins, Thomas W and Phillips, Theodore L and Nelson, Diana F},
journal = {International Journal of Radiation Oncology* Biology* Physics},
number = {3},
pages = {669--673},
publisher = {Elsevier},
title = {{Identification of an optimal subgroup for treatment evaluation of patients with brain metastases using RTOG study 7916}},
volume = {16},
year = {1989}
}
@article{Lawless:2009ff,
author = {Lawless, Jerald F and Yuan, Yan},
journal = {Statistics in medicine},
pages = {n/a----n/a},
title = {{Estimation of prediction error for survival models}},
year = {2009}
}
@article{Daulton2019,
abstract = {Recent advances in contextual bandit optimization and reinforcement learning have garnered interest in applying these methods to real-world sequential decision making problems. Real-world applications frequently have constraints with respect to a currently deployed policy. Many of the existing constraint-aware algorithms consider problems with a single objective (the reward) and a constraint on the reward with respect to a baseline policy. However, many important applications involve multiple competing objectives and auxiliary constraints. In this paper, we propose a novel Thompson sampling algorithm for multi-outcome contextual bandit problems with auxiliary constraints. We empirically evaluate our algorithm on a synthetic problem. Lastly, we apply our method to a real world video transcoding problem and provide a practical way for navigating the trade-off between safety and performance using Bayesian optimization.},
archivePrefix = {arXiv},
arxivId = {1911.00638},
author = {Daulton, Samuel and Singh, Shaun and Avadhanula, Vashist and Dimmery, Drew and Bakshy, Eytan},
eprint = {1911.00638},
file = {::},
number = {NeurIPS},
title = {{Thompson Sampling for Contextual Bandit Problems with Auxiliary Safety Constraints}},
url = {http://arxiv.org/abs/1911.00638},
year = {2019}
}
@article{Kerr:2011ta,
author = {Kerr, Kathleen F and Pepe, Margaret S},
journal = {Epidemiology},
month = {nov},
number = {6},
pages = {805--812},
title = {{Joint Modeling, Covariate Adjustment, and Interaction}},
volume = {22},
year = {2011}
}
@article{Clinic,
author = {Clinic, Mayo and D, Manish Kohli M},
number = {507},
pages = {1--28},
title = {{Title : Pharmacogenetics and Pharmacogenomics Based Rational Clinical Trial Designs in Oncology}}
}
@article{Barquet:1997fg,
author = {Barquet, N},
journal = {JAMA: The Journal of the American Medical Association},
month = {aug},
number = {6},
pages = {491--496},
title = {{Prognostic factors in meningococcal disease. Development of a bedside predictive model and scoring system. Barcelona Meningococcal Disease Surveillance Group}},
volume = {278},
year = {1997}
}
@article{Dorresteijn2011,
abstract = {Objectives: To predict treatment effects for individual patients based on data from randomised trials, taking rosuvastatin treatment in the primary prevention of cardiovascular disease as an example, and to evaluate the net benefit of making treatment decisions for individual patients based on a predicted absolute treatment effect. Setting: As an example, data were used from the Justification for the Use of Statins in Prevention (JUPITER) trial, a randomised controlled trial evaluating the effect of rosuvastatin 20 mg daily versus placebo on the occurrence of cardiovascular events (myocardial infarction, stroke, arterial revascularisation, admission to hospital for unstable angina, or death from cardiovascular causes). Population: 17 802 healthy men and women who had low density lipoprotein cholesterol levels of less than 3.4 mmol/L and high sensitivity C reactive protein levels of 2.0 mg/L or more. Methods: Data from the Justification for the Use of Statins in Prevention trial were used to predict rosuvastatin treatment effect for individual patients based on existing risk scores (Framingham and Reynolds) and on a newly developed prediction model. We compared the net benefit of prediction based rosuvastatin treatment (selective treatment of patients whose predicted treatment effect exceeds a decision threshold) with the net benefit of treating either everyone or no one. Results: The median predicted 10 year absolute risk reduction for cardiovascular events was 4.4{\%} (interquartile range 2.6-7.0{\%}) based on the Framingham risk score, 4.2{\%} (2.5-7.1{\%}) based on the Reynolds score, and 3.9{\%} (2.5-6.1{\%}) based on the newly developed model (optimal fit model). Prediction based treatment was associated with more net benefit than treating everyone or no one, provided that the decision threshold was between 2{\%} and 7{\%}, and thus that the number willing to treat (NWT) to prevent one cardiovascular event over 10 years was between 15 and 50. Conclusions: Data from randomised trials can be used to predict treatment effect in terms of absolute risk reduction for individual patients, based on a newly developed model or, if available, existing risk scores. The value of such prediction of treatment effect for medical decision making is conditional on the NWT to prevent one outcome event. Trial registration number: Clinicaltrials.gov NCT00239681.},
author = {Dorresteijn, Johannes A.N. and Visseren, Frank L.J. and Ridker, Paul M. and Wassink, Annemarie M.J. and Paynter, Nina P. and Steyerberg, Ewout W. and {Van Der Graaf}, Yolanda and Cook, Nancy R.},
doi = {10.1136/bmj.d5888},
issn = {09598146},
journal = {BMJ (Online)},
number = {7828},
pages = {1--13},
pmid = {21968126},
title = {{Estimating treatment effects for individual patients based on the results of randomised clinical trials}},
volume = {343},
year = {2011}
}
@article{Pepe:2011bf,
author = {Pepe, M S},
journal = {American Journal of Epidemiology},
month = {may},
number = {11},
pages = {1327--1335},
title = {{Problems With Risk Reclassification Methods for Evaluating Prediction Models}},
volume = {173},
year = {2011}
}
@article{Pencina:2011kl,
author = {Pencina, Michael J and {D'Agostino Sr.}, Ralph B and Steyerberg, Ewout W},
journal = {Statistics in medicine},
month = {nov},
number = {1},
pages = {11--21},
title = {{Extensions of net reclassification improvement calculations to measure usefulness of new biomarkers}},
volume = {30},
year = {2010}
}
@article{Wasserstein:2016jo,
author = {Wasserstein, Ronald L and Lazar, Nicole A},
journal = {The American statistician},
month = {jun},
number = {2},
pages = {129--133},
title = {{The ASA's Statement on p-Values: Context, Process, and Purpose}},
volume = {70},
year = {2016}
}
@article{grommes2019phase,
author = {Grommes, Christian and Tang, Sarah S and Wolfe, Julia and Kaley, Thomas J and Daras, Mariza and Pentsova, Elena I and Piotrowski, Anna F and Stone, Jacqueline and Lin, Andrew and Nolan, Craig P and Others},
journal = {Blood},
number = {5},
pages = {436--445},
publisher = {American Society of Hematology},
title = {{Phase 1b trial of an ibrutinib-based combination therapy in recurrent/refractory CNS lymphoma}},
volume = {133},
year = {2019}
}
@article{Hayward2021,
abstract = {Introduction There is an urgent need to idenfy treatments for COVID-19 that reduce illness duration and hospital admission in those at higher risk of a longer illness course and complications. Methods and analysis The Platform Randomised trial of INterventions against COVID-19 In older peoPLE trial is an open-label, multiarm, prospective, adaptive platform, randomised clinical trial to evaluate potential treatments for COVID-19 in the community. A master protocol governs the addition of new interventions as they become available, as well as the inclusion and cessation of existing intervention arms via frequent interim analyses. The first three interventions are hydroxychloroquine, azithromycin and doxycycline. Eligible participants must be symptomatic in the community with possible or confirmed COVID-19 that started in the preceding 14 days and either (1) aged 65 years and over or (2) aged 50-64 years with comorbidities. Recruitment is through general practice, health service helplines, COVID-19 'hot hubs' and directly through the trial website. Participants are randomised to receive either usual care or a study drug plus usual care, and outcomes are collected via daily online symptom diary for 28 days from randomisation. The research team contacts participants and/or their study partner following days 7, 14 and 28 if the online diary is not completed. The trial has two coprimary endpoints: time to first self-report of feeling recovered from possible COVID-19 and hospital admission or death from possible COVID-19 infection, both within 28 days from randomisation. Prespecified interim analyses assess efficacy or futility of interventions and to modify randomisation probabilities that allocate more participants to interventions with better outcomes. Ethics and dissemination Ethical approval Ref: 20/SC/0158 South Central - Berkshire Research Ethics Committee; IRAS Project ID: 281958; EudraCT Number: 2020-001209-22. Results will be presented to policymakers and at conferences and published in peer-reviewed journals. Trial registration number ISRCTN86534580.},
author = {Hayward, Gail and Butler, Christopher C. and Yu, Ly Mee and Saville, Benjamin R. and Berry, Nicholas and Dorward, Jienchi and Gbinigie, Oghenekome and {Van Hecke}, Oliver and Ogburn, Emma and Swayze, Hannah and Bongard, Emily and Allen, Julie and Tonner, Sharon and Rutter, Heather and Tonkin-Crine, Sarah and Borek, Aleksandra and Judge, David and Grabey, Jenna and {De Lusignan}, Simon and Thomas, Nicholas P.B. and Evans, Philip H. and Andersson, Monique I. and Llewelyn, Martin and Patel, Mahendra and Hopkins, Susan and Hobbs, F. D.Richard},
doi = {10.1136/bmjopen-2020-046799},
file = {::},
isbn = {2020001209},
issn = {20446055},
journal = {BMJ Open},
keywords = {COVID-19,clinical trials,infectious diseases,primary care},
number = {6},
pmid = {34145016},
title = {{Platform Randomised trial of INterventions against COVID-19 in older peoPLE (PRINCIPLE): Protocol for a randomised, controlled, open-label, adaptive platform, trial of community treatment of COVID-19 syndromic illness in people at higher risk}},
volume = {11},
year = {2021}
}
@article{Wang:2011kr,
author = {Wang, Sue-Jane and Blume, Jeffrey D},
journal = {Pharmaceutical Statistics},
month = {sep},
number = {5},
pages = {440--447},
title = {{An evidential approach to non-inferiority clinical trials}},
volume = {10},
year = {2011}
}
@article{Kerr:2014de,
author = {Kerr, Kathleen F and Wang, Zheyu and Janes, Holly and McClelland, Robyn L and Psaty, Bruce M and Pepe, Margaret S},
journal = {Epidemiology},
month = {jan},
number = {1},
pages = {114--121},
title = {{Net Reclassification Indices for Evaluating Risk Prediction Instruments}},
volume = {25},
year = {2014}
}
@article{Sirohi2022,
abstract = {Introduction: Genomic and morphologic heterogeneity in clear cell renal cell carcinoma (ccRCC) presents a barrier to prognostication and treatment decisions. Data from pathology are used with clinical markers to predict disease progression after nephrectomy. However, determining the risk of cancer recurrence, and survival with metastatic cancer remains challenging. Recently, analysis of histologic growth patterns (HGP) in ccRCC revealed promising associations with survival outcomes. Methods: To investigate whether HGPs can be used to predict overall survival (OS) after nephrectomy, we examined 24 HGPs in primary tumors of 147 patients that included 107 patients with metastatic disease. Results: The median number of HGPs per case was 5 and was greater in metastatic and larger tumors. After adjustment for 6 pathologic and demographic variables, HGPs were significantly associated with OS post nephrectomy. Small nests, expansile nests and nests with high nuclear to cytoplasmic ratio were associated with favorable outcomes; while spindled low grade, fused nests/solid sheets, rhabdoid, and sarcomatoid patterns were associated with unfavorable outcomes. A 3-tiered and a 2-tiered risk model were developed based on combinations of HGPs. The models performed equally well as WHO/ISUP nucleolar plus necrosis grade (necrosis grade), and better than WHO/ISUP nucleolar grade alone in predicting OS at the median OS of 6 years. Pairwise correlations between HGPs revealed 2 tumor evolutionary branches that differed in risk of metastatic disease: one with mesenchymal differentiation, and other with epithelial tubulopapillary differentiation. While 44 of 107 (41{\%}) patients with metastatic ccRCC displayed evidence of mesenchymal differentiation, mesenchymal features were only observed in 1 of 40 (3{\%}) patients without evidence of metastatic disease. Conclusion: These findings suggest that HGPs may provide a novel path to refine the estimation of OS after nephrectomy and to determine the molecular basis of tumor evolution.},
author = {Sirohi, Deepika and Chipman, Jonathan and Barry, Marc and Albertson, Daniel and Mahlow, Jon and Liu, Ting and Raps, Evan and Haaland, Ben and Sayegh, Nicolas and Li, Haoran and Rathi, Nityam and Sharma, Prayushi and Agarwal, Neeraj and Knudsen, Beatrice},
doi = {10.1016/j.clgc.2022.01.005},
issn = {19380682},
journal = {Clinical Genitourinary Cancer},
keywords = {Clear Cell,Evolution,Grading,Metastatic,Survival},
pages = {1--11},
publisher = {Elsevier Inc.},
title = {{Histologic Growth Patterns in Clear Cell Renal Cell Carcinoma Stratify Patients into Survival Risk Groups}},
url = {https://doi.org/10.1016/j.clgc.2022.01.005},
year = {2022}
}
@article{Atkinson:1999hq,
annote = {From Duplicate 2 (Optimum biased-coin designs for sequential treatment allocation with covariate information (With Discussion) - Medicine, A C Atkinson Statistics in; 1999)

doi: 10.1002/(SICI)1097-0258(19990730)18:143.0.CO;2-5},
author = {in Medicine, A C Atkinson Statistics and 1999 and Atkinson, Anthony C},
journal = {Journal of the Royal Statistical Society Series B},
month = {jul},
number = {14},
pages = {1753--1755},
title = {{Optimum biased-coin designs for sequential treatment allocation with covariate information (With Discussion)}},
volume = {18},
year = {1999}
}
@article{Chu2020,
author = {Chu, I Y and Alam, P and Larson, H J and Lin, L},
doi = {10.1093/jtm/taaa192},
issn = {1708-8305 (Electronic) 1195-1982 (Print) 1195-1982 (Linking)},
journal = {J Travel Med},
number = {7},
title = {{Social consequences of mass quarantine during epidemics: a systematic review with implications for the COVID-19 response}},
volume = {27},
year = {2020}
}
@article{Kazer2013,
abstract = {UNLABELLED: Study Type - Therapy (attitude prevalence) Level of Evidence 2a What's known on the subject? and What does the study add? Marked differences in uncertainty among patients have been found relating to race and social environment indicating that as uncertainty increases, social functioning declines. Correlations have been found between uncertainty and patients' coping, psychological adjustment and perceptions of their health and illness. Studies suggest the detrimental effect of uncertainty among patients with prostate cancer in the perception of their quality of life. These studies underline the potential benefit of targeted intervention. The study provides a unique insight into the impact of uncertainty and perception of danger on overall satisfaction with treatment outcomes in men with prostate cancer. Its results suggest that possible disparities related to patient racial background and education may exist in the perception of cancer-related uncertainty. Racial and educational disparities, coupled with a mild to moderate association of uncertainty or danger perception and overall outcome satisfaction, suggest an unmet need for healthcare and nursing services for men undergoing treatment for prostate cancer. OBJECTIVES: To investigate patient uncertainty and perception of danger regarding prospects for clinical prostate cancer control. To determine the impact of these factors on satisfaction with overall prostate cancer treatment outcome. PATIENTS AND METHODS: Men who had undergone primary treatment for early stage prostate cancer and who were participants in the Prostate Cancer Outcomes and Satisfaction with Treatment Quality Assessment (PROSTQA) prospective cohort study of prostate cancer outcomes (the parent study) were offered the opportunity to participate in the present study. Centralized phone interviews were conducted to determine patient-reported uncertainty regarding cancer status (measured by the Mishel Uncertainty in Illness Scale-Community Form), perception of danger (measured by Folkman and Lazarus' Appraisal Scale) and satisfaction with treatment outcome (measured by the Service Satisfaction Scale for Cancer Care). The study used the same centralized telephone interview centre as was used in the parent study. Data were collected at 48, 60 or 72 months after the completion of prostate cancer treatment. Relationships among measures were characterized by Spearman rank correlation coefficients (r). RESULTS: A total of 338 agreed to participate, representing 76{\%} of those who were invited. Younger patients experienced less uncertainty (r = 0.20, P {\textless} 0.001), yet reported greater perception of danger (r = -0.12; P = 0.03) concerning their previously treated prostate cancer. African-American patients showed greater uncertainty than other ethnic groups (P = 0.005) but did not have a greater perception of danger (P = 0.36). Education played a major role in uncertainty; patients with lower levels of education tended to report higher degrees of uncertainty (r = -0.25; P {\textless} 0.001). There was a mild to moderate general association between the three outcomes. A greater sense of uncertainty was associated with a greater perception of danger (r = 0.34, P {\textless} 0.001), and as danger and uncertainty increased, satisfaction with treatment outcome tended to decrease (r was between -0.30 and -0.34, P {\textless} 0.001). CONCLUSIONS: Results suggest that possible disparities related to patient racial background and education may exist in the perception of cancer-related uncertainty. Racial and educational disparities, coupled with a mild to moderate association of uncertainty or danger perception and overall outcome satisfaction, suggest an unmet need for healthcare and nursing services for men undergoing treatment for prostate cancer.},
author = {Kazer, Meredith Wallace and Bailey, Donald E Jr and Chipman, Jonathan and Psutka, Sarah P and Hardy, Jill and Hembroff, Larry and Regan, Meredith and Dunn, Rodney L and Crociani, Catrina and Sanda, Martin G},
doi = {10.1111/j.1464-410X.2012.11439.x},
institution = {PROSTQA Consortium Study Group},
issn = {1464-410X (Electronic)},
journal = {BJU international},
keywords = {Aged,Aged, 80 and over,Attitude to Health,Humans,Male,Middle Aged,Prostatic Neoplasms,Uncertainty,psychology,therapy},
language = {eng},
month = {mar},
number = {3 Pt B},
pages = {E84--91},
pmid = {22985348},
title = {{Uncertainty and perception of danger among patients undergoing treatment for prostate cancer.}},
volume = {111},
year = {2013}
}
@article{Simpson1951,
author = {Lewis, B N},
journal = {Journal of the Royal Statistical Society. Series A (General)},
number = {1},
pages = {88},
title = {{On the Analysis of Interaction in Multi-Dimensional Contingency Tables}},
volume = {125},
year = {1962}
}
@article{Oaks1999,
author = {Oaks, Dallin H},
journal = {Ensign},
number = {March},
pages = {1--9},
title = {{‘Judge Not' and Judging}},
url = {https://www.lds.org/ensign/1999/08/judge-not-and-judging?lang=eng},
year = {1999}
}
@article{Xu:2013dl,
author = {Xu, Zhenzhen and Kalbfleisch, John D},
journal = {Biometrics},
month = {oct},
number = {4},
pages = {949--959},
title = {{Repeated Randomization and Matching in Multi-Arm Trials}},
volume = {69},
year = {2013}
}
@article{Simon:2003ce,
author = {Simon, R and Radmacher, M D and Dobbin, K and McShane, L M},
journal = {JNCI Journal of the National Cancer Institute},
month = {jan},
number = {1},
pages = {14--18},
title = {{Pitfalls in the Use of DNA Microarray Data for Diagnostic and Prognostic Classification}},
volume = {95},
year = {2003}
}
@article{Hansen2014,
abstract = {Clustered treatment assignment occurs when individuals are grouped into clusters prior to treatment and whole clusters, not individuals, are assigned to treatment or control. In randomized trials, clustered assignments may be required because the treatment must be applied to all children in a classroom, or to all patients at a clinic, or to all radio listeners in the same media market. The most common cluster randomized design pairs 2S clusters into S pairs based on similar pretreatment covariates, then picks one cluster in each pair at random for treatment, the other cluster being assigned to control. Typically, group randomization increases sampling variability and so is less efficient, less powerful, than randomization at the individual level, but it may be unavoidable when it is impractical to treat just a few people within each cluster. Related issues arise in nonrandomized, observational studies of treatment effects, but in this case one must examine the sensitivity of conclusions to bias from nonrandom selection of clusters for treatment. Although clustered assignment increases sampling variability in observational studies, as it does in randomized experiments, it also tends to decrease sensitivity to unmeasured biases, and as the number of cluster pairs increases the latter effect overtakes the former, dominating it when allowance is made for nontrivial biases in treatment assignment. Intuitively, a given magnitude of departure from random assignment can do more harm if it acts on individual students than if it is restricted to act on whole classes, because the bias is unable to pick the strongest individual students for treatment, and this is especially true if a serious effort is made to pair clusters that appeared similar prior to treatment. We examine this issue using an asymptotic measure, the design sensitivity, some inequalities that exploit convexity, simulation, and an application concerned with the flooding of villages in Bangladesh. {\textcopyright} 2014 American Statistical Association.},
author = {Hansen, Ben B. and Rosenbaum, Paul R. and Small, Dylan S.},
doi = {10.1080/01621459.2013.863157},
file = {::},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Community intervention,Design sensitivity,Group randomization,Multi-level study,Quasi-experiment,Sensitivity analysis},
number = {505},
pages = {133--144},
title = {{Clustered treatment assignments and sensitivity to unmeasured biases in observational studies}},
volume = {109},
year = {2014}
}
@article{Cook:2011em,
author = {Cook, N R},
journal = {American Journal of Epidemiology},
month = {sep},
number = {7},
pages = {874--875},
title = {{Re: "Problems With Risk Reclassification Methods for Evaluating Prediction Models"}},
volume = {174},
year = {2011}
}
@article{Greenland:2005fz,
author = {Greenland, Philip and O'Malley, Patrick G},
journal = {Archives of Internal Medicine},
month = {nov},
number = {21},
pages = {2454},
title = {{When Is a New Prediction Marker Useful?}},
volume = {165},
year = {2005}
}
@article{wang2023model,
author = {Wang, Bingkai and Susukida, Ryoko and Mojtabai, Ramin and Amin-Esmaeili, Masoumeh and Rosenblum, Michael},
journal = {Journal of the American Statistical Association},
number = {542},
pages = {1152--1163},
publisher = {Taylor $\backslash${\&} Francis},
title = {{Model-robust inference for clinical trials that improve precision by stratified randomization and covariate adjustment}},
volume = {118},
year = {2023}
}
@article{Molinaro:2005jw,
author = {Molinaro, A M and Simon, R and Pfeiffer, R M},
journal = {Bioinformatics},
month = {jul},
number = {15},
pages = {3301--3307},
title = {{Prediction error estimation: a comparison of resampling methods}},
volume = {21},
year = {2005}
}
@article{broglio2014not,
author = {Broglio, Kristine R and Connor, Jason T and Berry, Scott M},
journal = {Journal of biopharmaceutical statistics},
number = {3},
pages = {685--705},
publisher = {Taylor $\backslash${\&} Francis},
title = {{Not too big, not too small: a goldilocks approach to sample size selection}},
volume = {24},
year = {2014}
}
@article{posch2003issues,
author = {Posch, Martin and Bauer, Peter and Brannath, Werner},
journal = {Statistics in medicine},
number = {6},
pages = {953--969},
publisher = {Wiley Online Library},
title = {{Issues in designing flexible trials}},
volume = {22},
year = {2003}
}
@article{VanCalster:2014bo,
author = {{Van Calster}, Ben and Vickers, Andrew J},
journal = {Medical Decision Making},
month = {feb},
number = {2},
pages = {162--169},
title = {{Calibration of Risk Prediction Models}},
volume = {35},
year = {2015}
}
@book{Anonymous:2000wq,
address = {New York, NY},
editor = {Halloran, M Elizabeth and Berry, Donald},
publisher = {Springer New York},
series = {The IMA Volumes in Mathematics and its Applications},
title = {{Statistical Models in Epidemiology, the Environment, and Clinical Trials}},
volume = {116},
year = {2000}
}
@article{Chambless:2011hn,
author = {Chambless, Lloyd E and Cummiskey, Christopher P and Cui, Gang},
journal = {Statistics in medicine},
month = {sep},
number = {1},
pages = {22--38},
title = {{Several methods to assess improvement in risk prediction models: Extension to survival analysis}},
volume = {30},
year = {2010}
}
@book{Anonymous:NJHE7Xi9,
title = {{R package version }}
}
@article{Steyerberg:2001fd,
author = {Steyerberg, Ewout W and {Harrell Jr}, Frank E and Borsboom, Gerard J J M and Eijkemans, M J C and Vergouwe, Yvonne and Habbema, J Dik F},
journal = {Journal of Clinical Epidemiology},
month = {aug},
number = {8},
pages = {774--781},
title = {{Internal validation of predictive models}},
volume = {54},
year = {2001}
}
@article{Shao2010a,
abstract = {The covariate-adaptive randomization method was proposed for clinical trials long ago but little theoretical work has been done for statistical inference associated with it. Practitioners often apply test procedures available for simple randomization, which is controversial since procedures valid under simple randomization may not be valid under other randomization schemes. In this paper, we provide some theoretical results for testing hypotheses after covariate-adaptive randomization. We show that one way to obtain a valid test procedure is to use a correct model between outcomes and covariates, including those used in randomization. We also show that the simple two sample t-test, without using any covariate, is conservative under covariate-adaptive biased coin randomization in terms of its Type I error, and that a valid bootstrap t-test can be constructed. The powers of several tests are examined theoretically and empirically. Our study provides guidance for applications and sheds light on further research in this area. {\textcopyright} 2010 Biometrika Trust.},
annote = {For least squares regression:

For a valid statistical test following covariate-adjusted randomization, condition the model on the covariates used in restricted randomization. This assumes the model is correctly specified for E(Y|X).

This is true for fixed treatment allocation. And, it is true when treatment allocation and outcome are conditionally independent given X. (Eq 3).

Biased coin without conditioning on X still hold true.

Covariate-adaptive randomization, allocation and outcome are conditionally independent given (X, Z). But, with X only allocation and outcome may be dependent. But when Z is a function of X, the test is still valid.

If model E(Y|X) does not fully account for Z, then test is conservative.

Bootstrap test statistic following randomization is valid. Details in article.},
author = {Shao, Jun and Yu, Xinxin and Zhong, Bob},
doi = {10.1093/biomet/asq014},
issn = {00063444},
journal = {Biometrika},
keywords = {Adaptive allocation,Biased coin,Clinical trial,Minimization,Power,Type I error},
number = {2},
pages = {347--360},
title = {{A theory for testing hypotheses under covariate-adaptive randomization}},
volume = {97},
year = {2010}
}
@techreport{fryer2012enhancing,
author = {{Fryer Jr}, Roland G and Levitt, Steven D and List, John and Sadoff, Sally},
institution = {National Bureau of Economic Research},
title = {{Enhancing the efficacy of teacher incentives through loss aversion: A field experiment}},
year = {2012}
}
@article{Tai:2008gt,
author = {Tai, Yu Chuan and Chen, Sining and Parmigiani, Giovanni and Klein, Alison P},
journal = {Breast Cancer Research},
month = {mar},
number = {2},
pages = {5175},
title = {{Incorporating tumor immunohistochemical markers in BRCA1 and BRCA2 carrier prediction}},
volume = {10},
year = {2008}
}
@article{Zink,
author = {Zink, Richard C and Life, J M P},
pages = {1--33},
title = {{Advanced Randomization-based Methods}}
}
@article{chen2004increasing,
author = {Chen, Y H Joshua and DeMets, David L and {Gordon Lan}, K K},
journal = {Statistics in medicine},
number = {7},
pages = {1023--1038},
publisher = {Wiley Online Library},
title = {{Increasing the sample size when the unblinded interim result is promising}},
volume = {23},
year = {2004}
}
@article{Ballman2015,
abstract = {The goal of this article is to explain the differences between prognostic and predictive markers and to describe how to make this distinction based on clinical data and formal statistical testing. The term biomarker refers to a measurement variable that is associated with disease outcome. It can be a single measurement, such as prostate-specific antigen (PSA) level, or a classifier (signature) computed from measures of numerous other variables, such as OncoType DX recurrence score, 1 which is calculated from the measurements of the expression levels of 21 genes. There is considerable confusion about the distinction between a predictive biomarker and a prognostic biomarker. Confusion even exists among biostat-isticians because they have been taught predictive modeling as part of their training. A predictive model is a mathematical relationship between explanatory (independent) variables and an outcome (dependent) variable with the goal of predicting a future outcome based on the values of the explanatory variables in the model. An example of a predictive model is a nomogram that predicts the probability a man will not die of prostate cancer (outcome variable) within 10 years of undergoing a radical prostatectomy. 2 This model's explanatory variables (biomarkers) are age, PSA level, tumor Gleason score, tumor clinical stage, and number ofpositive biopsy cores and number of negative biopsy cores at time of diagnosis. The explanatory variables in a predictive model are often prognostic, but statisticians may refer to them as predictive variables, which may generate confusion.},
author = {Ballman, Karla V.},
doi = {10.1200/JCO.2015.63.3651},
issn = {15277755},
journal = {Journal of Clinical Oncology},
number = {33},
pages = {3968--3971},
pmid = {26392104},
title = {{Biomarker: Predictive or prognostic?}},
volume = {33},
year = {2015}
}
@article{mayberry2019assessing,
author = {Mayberry, Lindsay S and Berg, Cynthia A and {Greevy Jr}, Robert A and Wallston, Kenneth A},
journal = {Patient education and counseling},
number = {7},
pages = {1380--1388},
publisher = {Elsevier},
title = {{Assessing helpful and harmful family and friend involvement in adults' type 2 diabetes self-management}},
volume = {102},
year = {2019}
}
@article{Min2019a,
abstract = {PURPOSE: To evaluate the accuracy of a composite definition for the identification of hypoglycemia events that used both administrative claims and laboratory data in a cohort of patients. METHODS: We reviewed medical records in a sample of presumed hypoglycemia events among patients who received care at the Veterans Health Administration Tennessee Valley Healthcare System in 2001 to 2012. A hypoglycemia event was defined as a hospitalization or emergency department visit judged by the treating clinician to be due to hypoglycemia, or an outpatient laboratory or point-of-care blood glucose measurement {\textless}60 mg/dL. Based on medical record review, each event was classified as true positive (severe, documented symptomatic, documented asymptomatic) or false positive (probable symptomatic, not hypoglycemia). The positive predictive values (PPV) of the individual event types (hospitalization, emergency department, and outpatient) were estimated. RESULTS: Of 2250 events identified through the composite definition, 321 events (15 hospitalizations, 103 emergency department visits, and 203 outpatient events) were reviewed. The PPVs were 80{\%} for hospitalization events, 48{\%} for emergency department events, and 96{\%} for outpatient events. The emergency department definition included a nonspecific diagnosis code for diabetic complications which captured many false positive events. Excluding this code from the definition improved the PPV for emergency department events to 70{\%} and missed one true event. CONCLUSIONS: Our composite definition for hypoglycemia performed moderately well in a cohort of Veterans. Further evaluation of the emergency department events may be needed.},
author = {Min, Jea Young and Presley, Caroline A and Wharton, Jennifer and Griffin, Marie R and Greevy, Robert A Jr and Hung, Adriana M and Chipman, Jonathan and Grijalva, Carlos G and Hackstadt, Amber J and Roumie, Christianne L},
doi = {10.1002/pds.4712},
issn = {1099-1557 (Electronic)},
journal = {Pharmacoepidemiology and drug safety},
language = {eng},
month = {may},
number = {5},
pages = {625--631},
pmid = {30843332},
title = {{Accuracy of a composite event definition for hypoglycemia.}},
volume = {28},
year = {2019}
}
@article{Little:2013hj,
author = {Little, Roderick J},
journal = {Journal of the American Statistical Association},
month = {jun},
number = {502},
pages = {359--369},
title = {{In Praise of Simplicity not Mathematistry! Ten Simple Powerful Ideas for the Statistical Scientist}},
volume = {108},
year = {2013}
}
@article{Blume:SGPV,
author = {Blume, Jeffrey D and {DAgostino McGowan}, Lucy and Dupont, William D and {Greevy Jr.}, Robert A},
journal = {PloS one},
month = {mar},
number = {3},
pages = {e0188299 EP ----},
title = {{Second-generation p-values: Improved rigor, reproducibility, $\backslash${\&} transparency in statistical analyses}},
volume = {13},
year = {2018}
}
@article{Hanley:2003bh,
author = {Hanley, J A},
journal = {BMJ},
month = {dec},
number = {7429},
pages = {1457--1458},
title = {{How long did their hearts go on? A Titanic study}},
volume = {327},
year = {2003}
}
@article{Sørlie2001,
abstract = {The purpose of this study was to classify breast carcinomas based on variations in gene expression patterns derived from cDNA microarrays and to correlate tumor characteristics to clinical outcome. A total of 85 cDNA microarray experiments representing 78 cancers, three fibroadenomas, and four normal breast tissues were analyzed by hierarchical clustering. As reported previously, the cancers could be classified into a basal epithelial-like group, an ERBB2-overexpressing group and a normal breast-like group based on variations in gene expression. A novel finding was that the previously characterized luminal epithelial/estrogen receptor-positive group could be divided into at least two subgroups, each with a distinctive expression profile. These subtypes proved to be reasonably robust by clustering using two different gene sets: first, a set of 456 cDNA clones previously selected to reflect intrinsic properties of the tumors and, second, a gene set that highly correlated with patient outcome. Survival analyses on a subcohort of patients with locally advanced breast cancer uniformly treated in a prospective study showed significantly different outcomes for the patients belonging to the various groups, including a poor prognosis for the basal-like subtype and a significant difference in outcome for the two estrogen receptor-positive groups.},
author = {S{\o}rlie, Therese and Perou, Charles M. and Tibshirani, Robert and Aas, Turid and Geisler, Stephanie and Johnsen, Hilde and Hastie, Trevor and Eisen, Michael B. and {Van De Rijn}, Matt and Jeffrey, Stefanie S. and Thorsen, Thor and Quist, Hanne and Matese, John C. and Brown, Patrick O. and Botstein, David and L{\o}nning, Per Eystein and B{\o}rresen-Dale, Anne Lise},
doi = {10.1073/pnas.191367098},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {19},
pages = {10869--10874},
pmid = {11553815},
title = {{Gene expression patterns of breast carcinomas distinguish tumor subclasses with clinical implications}},
volume = {98},
year = {2001}
}
@article{Kohli2012,
abstract = {Recent therapeutic advances for managing advanced prostate cancer include the successful targeting of the androgen-AR axis with several new drugs in castrate resistant prostate cancer including abiraterone acetate and enzalutamide (MDV3100). This translational progress from bench to bed-side has resulted in an enlarging repertoire of novel and traditional drug choices now available for use in advanced prostate cancer therapeutics, which has had a positive clinical impact in prolonging longevity and quality of life of advanced prostate cancer patients. In order to further the clinical utility of these drugs, development of predictive biomarkers guiding individual therapeutic choices remains an ongoing challenge. This paper will summarize the potential in developing predictive biomarkers based on the pathophysiology of the androgen-AR axis in tumor tissue from patients with advanced prostate cancer as well as inherited variation in the patient's genome. Specific examples of rational clinical trial designs incorporating potential predictive biomarkers from these pathways will illustrate several aspects of pharmacogenetic and pharmacogenomic predictive biomarker development in advanced prostate cancer therapeutics. {\textcopyright} 2012 Manish Kohli et al.},
author = {Kohli, Manish and Qin, Rui and Jimenez, Rafael and Dehm, Scott M.},
doi = {10.1155/2012/781459},
issn = {16876369},
journal = {Advances in Urology},
title = {{Biomarker-based targeting of the androgen-androgen receptor axis in advanced prostate cancer}},
volume = {2012},
year = {2012}
}
@article{Samoilenko:uo,
author = {Samoilenko, M and Blais, L and Cossette, B and Forget, A},
journal = {obsstudies.org},
title = {{Assessing the dose-response relationship between maternal use of inhaled corticosteroids therapy and birth weight: a generalized propensity score approach}}
}
@article{whitehead1990double,
author = {Whitehead, John and Brunier, Hazel},
file = {::},
journal = {Sequential Analysis},
number = {2},
pages = {117--136},
publisher = {Taylor {\&} Francis},
title = {{The double triangular test: a sequential test for the two-sided alternative with early stopping under the null hypothesis}},
volume = {9},
year = {1990}
}
@article{halperin1982aid,
author = {Halperin, Max and Lan, K K Gordon and Ware, James H and Johnson, Norman J and DeMets, David L},
journal = {Controlled Clinical Trials},
number = {4},
pages = {311--323},
publisher = {Elsevier},
title = {{An aid to data monitoring in long-term clinical trials}},
volume = {3},
year = {1982}
}
@article{Quigley:2013cz,
author = {Quigley, Charmian A and Zagar, Anthony J and Liu, Charlie Chunhua and Brown, David M and Huseman, Carol and Levitsky, Lynne and Repaske, David R and Tsalikian, Eva and Chipman, John J},
journal = {International Journal of Pediatric Endocrinology},
number = {1},
pages = {6},
title = {{United States multicenter study of factors predicting the persistence of GH deficiency during the transition period between childhood and adulthood}},
volume = {2013},
year = {2013}
}
@article{Kroncke:2015eh,
author = {Kroncke, Brett M and Vanoye, Carlos G and Meiler, Jens and {George Jr.}, Alfred L and Sanders, Charles R},
journal = {Biochemistry},
month = {apr},
number = {16},
pages = {2551--2559},
title = {{Personalized Biochemistry and Biophysics}},
volume = {54},
year = {2015}
}
@article{Einstein2019,
abstract = {OBJECTIVES: To test the validity of an Internet-based version of Expanded Prostate Cancer Index Composite (EPIC-26) versus the phone-based version. Most men will survive for years after treatment for localized prostate cancer (PCa) and may experience lasting treatment-related toxicities affecting health-related quality of life. The EPIC-26 is a validated instrument that measures health-related quality of life across 5 PCa-specific domains. Previously, EPIC-26 was administered via phone in a large multicenter clinical trial. METHODS: We developed an Internet-based version of EPIC-26. We recruited subjects from two prospective longitudinal study cohorts of PCa patients undergoing local therapy: PROST-QA, and PROSTQA-RP2. Subjects were randomized to either an "Internet-first" or "phone-first" group. Subjects were offered the alternate questionnaire modality 2 weeks after completing the initial modality. RESULTS: 181 subjects were offered enrollment; 133 agreed to participate. 65 subjects were randomized to the "Internet- first" group and 68 subjects to the "phone-first" group. Of these, 37 and 26 subjects respectively completed both questionnaire versions (response rate: 44.4{\%}). Test-retest analysis showed significant intraclass correlations in all 5 domains of EPIC-26: urinary incontinence (r=0.96), urinary irritation (r=0.85), bowel function (r=0.61), sexual function (r=0.94), and hormonal function (r=0.89). There was no effect of order of questionnaire administration. CONCLUSION: This study demonstrates excellent correlation of responses between Internet-based and phone-based EPIC-26 administration. All domains demonstrated test-retest reliability between modalities, without ordering effect. This validates the use of internet-based EPIC-26 in international registries as part of the International Consortium for Health Outcomes Measurement effort, and may facilitate its use in clinical practice and quality improvement.},
author = {Einstein, David J and Patil, Dattatraya and Chipman, Jonathan and Regan, Meredith M and Davis, Kyle and Crociani, Catrina M and Wagner, Andrew A and Sanda, Martin G and Chang, Peter},
doi = {10.1016/j.urology.2019.02.004},
issn = {1527-9995 (Electronic)},
journal = {Urology},
keywords = {Age Factors,Aged,Cohort Studies,Humans,Internet,Longitudinal Studies,Male,Middle Aged,Neoplasm Invasiveness,Neoplasm Staging,Prospective Studies,Prostatic Neoplasms,Quality of Life,Risk Assessment,Sickness Impact Profile,Survival Analysis,Telephone,mortality,pathology,psychology,statistics {\&} numerical data,therapy},
language = {eng},
month = {may},
pages = {53--60},
pmid = {30790648},
title = {{Expanded Prostate Cancer Index Composite-26 (EPIC-26) Online: Validation of an Internet-Based Instrument for Assessment of Health-Related Quality of Life After Treatment for Localized Prostate Cancer.}},
volume = {127},
year = {2019}
}
@article{Saville:2014cg,
author = {Saville, Benjamin R and Connor, Jason T and Ayers, Gregory D and Alvarez, JoAnn},
journal = {Clinical Trials},
month = {aug},
number = {4},
pages = {485--493},
title = {{The utility of Bayesian predictive probabilities for interim monitoring of clinical trials}},
volume = {11},
year = {2014}
}
@misc{makena2022review,
author = {{U.S. Food and Drug Administration}},
booktitle = {https://www.fda.gov/media/164774/download},
howpublished = {https://www.fda.gov/media/164774/download},
title = {{Presiding Officer's Written Report Summarizing Public Hearing and Providing Recommendations on CDER's Proposal to Withdraw Approval of MAKENA}},
url = {https://www.fda.gov/media/164774/download},
urldate = {2023-01-28},
year = {2023}
}
@article{Cook:2008ge,
author = {Cook, Nancy R},
journal = {Statistics in medicine},
number = {2},
pages = {191--195},
title = {{Comments on {\{}$\backslash$textquoteleft{\}}Evaluating the added predictive ability of a new marker: From area under the ROC curve to reclassification and beyond{\{}$\backslash$textquoteright{\}} by M. J. Pencinaet al.,Statistics in Medicine (DOI: 10.1002/sim.2929)}},
volume = {27},
year = {2007}
}
@article{pdufavi,
abstract = {PDUFA REAUTHORIZATION PERFORMANCE GOALS AND PROCEDURES FISCAL YEARS 2018 THROUGH 2022},
author = {{U.S. Food and Drug Administration}},
pages = {1--34},
title = {{PDUFA VI Commitment Letter}},
url = {https://www.fda.gov/downloads/ForIndustry/UserFees/PrescriptionDrugUserFee/UCM511438.pdf},
year = {2016}
}
@article{Reboussin:2000uf,
author = {Reboussin, D M and DeMets, D L and Kim, K M and Lan, K K},
journal = {Controlled Clinical Trials},
month = {jun},
number = {3},
pages = {190--207},
title = {{Computations for group sequential boundaries using the Lan-DeMets spending function method.}},
volume = {21},
year = {2000}
}
@book{Pituch2009,
abstract = {Due to the clustered nature of field data, multi-level modeling has become commonly used to analyze data arising from educational field experiments. While recent methodological literature has focused on multi-level mediation analysis, relatively little attention has been devoted to mediation analysis when three levels (e.g., student, class, school) are present in a study setting. This article presents analysis models that can be used to test indirect effects in experimental designs having three levels where random assignment is at the third (school) or second (class) level and where the indirect effect may be random. In the presentation, simulated datasets are used to illustrate model specification and results interpretation for hypothetical three-level educational experiments involving mediation and moderation of treatment effects. Copyright {\textcopyright} Heldref Publications.},
annote = {i = student
j = class
k = school},
author = {Pituch, Keenan A. and Murphy, Daniel L. and Tate, Richard L.},
booktitle = {Journal of Experimental Education},
doi = {10.1080/00220970903224685},
file = {::},
isbn = {0022097090},
issn = {00220973},
keywords = {Experimental design,Indirect effect,Mediation,Moderation,Multi-level model},
number = {1},
pages = {60--95},
title = {{Three-level models for indirect effects in school- and class-randomized experiments in education}},
volume = {78},
year = {2009}
}
@article{Aapro:2009jk,
author = {Aapro, Matti and Spivak, Jerry L},
journal = {The Oncologist},
number = {Supplement 1},
pages = {6--15},
title = {{Update on erythropoiesis-stimulating agents and clinical trials in oncology.}},
volume = {14 Suppl 1},
year = {2009}
}
@article{Anonymous:r_zRvR67,
month = {apr},
pages = {1--10},
title = {{CommentN:eyman(1923)and Causal InferencienExperimentasnd ObservationaSltudies}},
year = {2015}
}
@article{kim2011battle,
author = {Kim, Edward S and Herbst, Roy S and Wistuba, Ignacio I and Lee, J Jack and Blumenschein, George R and Tsao, Anne and Stewart, David J and Hicks, Marshall E and Erasmus, Jeremy and Gupta, Sanjay and Others},
journal = {Cancer discovery},
number = {1},
pages = {44--53},
publisher = {AACR},
title = {{The BATTLE Trial: Personalizing Therapy for Lung CancerThe BATTLE Trial: Personalizing Therapy for Lung Cancer}},
volume = {1},
year = {2011}
}
@article{berger2016comparing,
author = {Berger, Vance W and Bejleri, Klejda and Agnor, Rebecca},
journal = {Statistics in medicine},
number = {5},
pages = {685--694},
publisher = {Wiley Online Library},
title = {{Comparing MTI randomization procedures to blocked randomization}},
volume = {35},
year = {2016}
}
@book{Anonymous:1988vo,
address = {Berlin, Heidelberg},
publisher = {Springer Berlin Heidelberg},
title = {{Clinical Epidemiology and Biostatistics}},
year = {1988}
}
@article{Tomlins:2005cu,
author = {Tomlins, S A},
journal = {Science},
month = {oct},
number = {5748},
pages = {644--648},
title = {{Recurrent Fusion of TMPRSS2 and ETS Transcription Factor Genes in Prostate Cancer}},
volume = {310},
year = {2005}
}
@article{VanCalster:2013ec,
author = {{Van Calster}, B and Vickers, A J and Pencina, M J and Baker, S G and Timmerman, D and Steyerberg, E W},
journal = {Medical Decision Making},
month = {apr},
number = {4},
pages = {490--501},
title = {{Evaluation of Markers and Risk Prediction Models: Overview of Relationships between NRI and Decision-Analytic Measures}},
volume = {33},
year = {2013}
}
@article{Sparano2020,
abstract = {Importance: A high 21-gene recurrence score (RS) by breast cancer assay is prognostic for distant recurrence of early breast cancer after local therapy and endocrine therapy alone, and for chemotherapy benefit. Objective: To describe clinical outcomes for women with a high RS who received adjuvant chemotherapy plus endocrine therapy in the TAILORx trial, a population expected to have a high distant recurrence rate with endocrine therapy alone. Design, Setting, and Participants: In this secondary analysis of data from a multicenter randomized clinical trial, 1389 women with hormone receptor-positive, ERBB2-negative, axillary node-negative breast cancer, and a high RS of 26 to 100 were prospectively assigned to receive adjuvant chemotherapy in addition to endocrine therapy. The analysis was conducted on May 12, 2019. Interventions: The adjuvant chemotherapy regimen was selected by the treating physician. Main Outcomes and Measures: Freedom from recurrence of breast cancer at a distant site, and freedom from recurrence, second primary cancer, and death (also known as invasive disease-free survival [IDFS]). Results: Among the 9719 eligible women, with a mean age of 56 years (range 23-75 years), 1389 (14{\%}) had a recurrence score of 26 to 100, of whom 598 (42{\%}) had an RS of 26 to 30 and 791 (58{\%}) had an RS of 31 to 100. The most common chemotherapy regimens included docetaxel/cyclophosphamide in 589 (42{\%}), an anthracycline without a taxane in 334 (24{\%}), an anthracycline and taxane in 244 (18{\%}), cyclophosphamide/methotrexate/5-fluorouracil in 52 (4{\%}), other regimens in 81 (6{\%}), and no chemotherapy in 89 (6{\%}). At 5 years, the estimated rate of freedom from recurrence of breast cancer at a distant site was 93.0{\%} (standard error [SE], 0.8{\%}), freedom of recurrence of breast cancer at a distant and/or local regional site 91.0{\%} (SE, 0.8{\%}), IDFS 87.6{\%} (SE, 1.0{\%}), and overall survival 95.9{\%} (SE, 0.6{\%}). Conclusions and Relevance: The estimated rate of freedom from recurrence of breast cancer at a distant site in women with an RS of 26 to 100 treated largely with taxane and/or anthracycline-containing adjuvant chemotherapy regimens plus endocrine therapy in the prospective TAILORx trial was 93{\%} at 5 years, an outcome better than expected with endocrine therapy alone in this population.},
author = {Sparano, Joseph A. and Gray, Robert J. and Makower, Della F. and Albain, Kathy S. and Saphner, Thomas J. and Badve, Sunil S. and Wagner, Lynne I. and Kaklamani, Virginia G. and Keane, Maccon M. and Gomez, Henry L. and Reddy, Pavan S. and Goggins, Timothy F. and Mayer, Ingrid A. and Toppmeyer, Deborah L. and Brufsky, Adam M. and Goetz, Matthew P. and Berenberg, Jeffrey L. and Mahalcioiu, Catalin and Desbiens, Christine and Hayes, Daniel F. and Dees, Elizabeth C. and Geyer, Charles E. and Olson, John A. and Wood, William C. and Lively, Tracy and Paik, Soonmyung and Ellis, Matthew J. and Abrams, Jeffrey and Sledge, George W.},
doi = {10.1001/jamaoncol.2019.4794},
file = {::},
issn = {23742445},
journal = {JAMA Oncology},
number = {3},
pages = {367--374},
pmid = {31566680},
title = {{Clinical Outcomes in Early Breast Cancer with a High 21-Gene Recurrence Score of 26 to 100 Assigned to Adjuvant Chemotherapy Plus Endocrine Therapy: A Secondary Analysis of the TAILORx Randomized Clinical Trial}},
volume = {6},
year = {2020}
}
@article{Vickers:2014bx,
author = {Vickers, Andrew J and Edwards, Kelly and Cooperberg, Matthew R and Mushlin, Alvin I},
journal = {Annals of Internal Medicine},
month = {sep},
number = {6},
pages = {441},
title = {{A Simple Schema for Informed Decision Making About Prostate Cancer Screening}},
volume = {161},
year = {2014}
}
@article{Austin:2009fr,
author = {Austin, Peter C},
journal = {Communications in Statistics - Simulation and Computation},
month = {apr},
number = {6},
pages = {1228--1234},
title = {{Using the Standardized Difference to Compare the Prevalence of a Binary Variable Between Two Groups in Observational Research}},
volume = {38},
year = {2009}
}
@article{soares1983some,
author = {Soares, Jose F and {Jeff Wu}, C F},
journal = {Communications in Statistics-Theory and Methods},
number = {17},
pages = {2017--2034},
publisher = {Taylor {\&} Francis},
title = {{Some restricted randomization rules in sequential designs}},
volume = {12},
year = {1983}
}
@article{Steyerberg:2011fx,
author = {Steyerberg, Ewout W and Calster, Ben Van and Pencina, Michael J},
journal = {Revista Espa{\~{n}}ola de Cardiolog{\{}$\backslash$'$\backslash$i{\}}a (English Edition)},
month = {sep},
number = {9},
pages = {788--794},
title = {{Performance Measures for Prediction Models and Markers: Evaluation of Predictions and Classifications}},
volume = {64},
year = {2011}
}
@article{blume2019introduction,
author = {Blume, Jeffrey D and Greevy, Robert A and Welty, Valerie F and Smith, Jeffrey R and Dupont, William D},
journal = {The American Statistician},
number = {sup1},
pages = {157--167},
publisher = {Taylor {\&} Francis},
title = {{An Introduction to Second-Generation p-Values}},
volume = {73},
year = {2019}
}
@techreport{Anonymous:UCe9Nb8z,
month = {sep},
title = {{Microsoft Word - A Better P (Revision2).docx}},
year = {2017}
}
@article{Taylor:2008kq,
author = {Taylor, J M G and Ankerst, D P and Andridge, R R},
journal = {Clinical Cancer Research},
month = {oct},
number = {19},
pages = {5977--5983},
title = {{Validation of Biomarker-Based Risk Prediction Models}},
volume = {14},
year = {2008}
}
@article{Proschan2016,
author = {Proschan, Michael},
doi = {10.1080/09332480.2016.1234883},
file = {::},
issn = {0933-2480},
journal = {Chance},
number = {3},
pages = {31--40},
title = {{FDA Advisory Committees: The Role of Statisticians}},
volume = {29},
year = {2016}
}
@article{Qin2016,
abstract = {In comparative studies, such as in causal inference and clinical trials, balancing important covariates is often one of the most important concerns for both efficient and credible comparison. However, chance imbalance still exists in many randomized experiments. This phenomenon of covariate imbalance becomes much more serious as the number of covariates {\$}p{\$} increases. To address this issue, we introduce a new randomization procedure, called pairwise sequential randomization (PSR). The proposed method allocates the units sequentially and adaptively, using information on the current level of imbalance and the incoming unit's covariate. With a large number of covariates or a large number of units, the proposed method shows substantial advantages over the traditional methods in terms of the covariate balance, estimation accuracy, and computational time, making it an ideal technique in the era of big data. The proposed method attains the optimal covariate balance, in the sense that the estimated treatment effect under the proposed method attains its minimum variance asymptotically. Also the proposed method is widely applicable in both causal inference and clinical trials. Numerical studies and real data analysis provide further evidence of the advantages of the proposed method.},
annote = {I found this article unclear.

My understanding is that total MD is used as a minimization strategy with a biased coin as patients enter in pairs.

Assign the first of a pair with a biased coin and the second is made deterministically to maintain allocation balance.

Although they cited work, it appears they directly used text from Morgan and Rubin. I did not like this.},
archivePrefix = {arXiv},
arxivId = {1611.02802},
author = {Qin, Yichen and Li, Yang and Ma, Wei and Hu, Feifang},
doi = {10.48550/ARXIV.1611.02802},
eprint = {1611.02802},
journal = {arXiv:1611.02802},
title = {{Pairwise Sequential Randomization and Its Properties}},
url = {http://arxiv.org/abs/1611.02802},
year = {2016}
}
@article{Liu:2010vz,
author = {Liu, M and Kapadia, A S and Etzel, C J},
journal = {Journal of Statistical Theory and Practice},
month = {dec},
number = {4},
pages = {845--855},
title = {{Evaluating a New Risk Marker's Predictive Contribution in Survival Models}},
volume = {4},
year = {2010}
}
@article{Hugtenburg2013,
abstract = {BACKGROUND Nonadherence with medication is a complex and multidimensional health care problem. The causes may be related to the patient, treatment, and/or health care provider. As a consequence, substantial numbers of patients do not benefit optimally from pharmacotherapy, resulting in increased morbidity and mortality as well as increased societal costs. Several interventions may contribute to improved adherence. However, most interventions have only a modest effect. Thus, despite the many efforts made, there has been little progress made as yet in tackling the problem of nonadherence. METHODS This paper summarizes the definitions and taxonomy of adherence with medication, as well as types and causes of nonadherence. In addition, interventions aimed at improvement of adherence are discussed. CONCLUSION There is not just one solution for the nonadherence problem that fits all patients. Most interventions to improve adherence are aimed at all patients regardless of whether they are adherent or not. Recently, a number of tailored interventions have been described in the literature. Modern techniques are useful. Electronic pill boxes combined with Short Message Service reminders are specifically designed to improve unintentional adherence and have resulted in an increase in refill adherence in diabetic patients with suboptimal adherence. Tailored Internet interventions are a possibility for influencing patient drug-taking behavior and show promising results. Tailored counseling interventions targeted at the underlying causes of nonadherence seem an attractive method for supporting patients with their use of drugs. However, despite the plausible theoretical framework, data on long-term health effects of the various interventions are not available. To improve adherence effectively, there is a need for a tailored approach based on the type and cause of nonadherence and the specific needs of the patient.},
author = {Hugtenburg, Jacqueline G. and Timmers, Lonneke and Elders, Petra J.M. and Vervloet, Marcia and van Dijk, Liset},
doi = {10.2147/PPA.S29549},
issn = {1177889X},
journal = {Patient Preference and Adherence},
keywords = {Adherence,Compliance,Concordance,Tailored intervention},
pages = {675--682},
title = {{Definitions, variants, and causes of nonadherence with medication: A challenge for tailored interventions}},
volume = {7},
year = {2013}
}
@article{Bailey:1987ko,
author = {Bailey, R A},
journal = {Journal of the American Statistical Association},
month = {sep},
number = {399},
pages = {712--719},
title = {{Restricted Randomization: A Practical Example}},
volume = {82},
year = {1987}
}
@article{VanHoorde:2014ci,
author = {{Van Hoorde}, Kirsten and Vergouwe, Yvonne and Timmerman, Dirk and {Van Huffel}, Sabine and Steyerberg, Ewout W and {Van Calster}, Ben},
journal = {Statistics in medicine},
month = {jul},
number = {15},
pages = {2585--2596},
title = {{Assessing calibration of multinomial risk prediction models.}},
volume = {33},
year = {2014}
}
@article{Steyerberg:2003fq,
author = {Steyerberg, Ewout W and Bleeker, Sacha E and Moll, Henri{\"{e}}tte A and Grobbee, Diederick E and Moons, Karel G M},
journal = {Journal of Clinical Epidemiology},
month = {may},
number = {5},
pages = {441--447},
title = {{Internal and external validation of predictive models: A simulation study of bias and precision in small samples}},
volume = {56},
year = {2003}
}
@article{Greenland:2016kw,
author = {Greenland, Sander and Senn, Stephen J and Rothman, Kenneth J and Carlin, John B and Poole, Charles and Goodman, Steven N and Altman, Douglas G},
journal = {European Journal of Epidemiology},
month = {may},
number = {4},
pages = {337--350},
title = {{Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations}},
volume = {31},
year = {2016}
}
@book{Little1988,
abstract = {Imputations are means or draws from a predictive distribution of the missing values, and require a method of creating a predictive distribution for the imputation based on the observed data. There are two generic approaches to generating this distribution: Explicit modeling: the predictive distribution is based on a formal statistical model, and hence the assumptions are explicit; Implicit modeling: the focus is on an algorithm, which implies an underlying model; assumptions are implicit, but they still need to be carefully assessed to ensure that they are reasonable. This chapter introduces these approaches. It considers methods that impute the mean of a predictive distribution, and methods that impute a draw from a predictive distribution. An important limitation of the single imputation methods is that standard variance formulas applied to the filled-in data systematically underestimate the variance of estimates, even if the model used to generate the imputations is correct.},
author = {Little, R. J. A. and Rubin, D. B.},
booktitle = {Journal of the Royal Statistical Society. Series A (Statistics in Society)},
doi = {10.2307/2982783},
isbn = {9781118596012},
issn = {09641998},
number = {2},
pages = {375},
title = {{Statistical Analysis with Missing Data.}},
volume = {151},
year = {1988}
}
@article{Rosenkranz:2011jj,
author = {Rosenkranz, Gerd K},
journal = {Statistics in medicine},
month = {dec},
number = {30},
pages = {3475--3487},
title = {{The impact of randomization on the analysis of clinical trials}},
volume = {30},
year = {2011}
}
@article{mayberry2019text,
author = {Mayberry, Lindsay S and Bergner, Erin M and Harper, Kryseana J and Laing, Simone and Berg, Cynthia A},
journal = {Journal of the American Medical Informatics Association},
number = {10},
pages = {1099--1108},
publisher = {Oxford University Press},
title = {{Text messaging to engage friends/family in diabetes self-management support: acceptability and potential to address disparities}},
volume = {26},
year = {2019}
}
@article{Guisan:2009ei,
author = {Guisan, Antoine and Harrell, Frank E},
journal = {Journal of Vegetation Science},
month = {apr},
number = {5},
pages = {617--626},
title = {{Ordinal response regression models in ecology}},
volume = {11},
year = {2009}
}
@article{Wetter2007,
author = {Wetter, D W and Mazas, C and Daza, P and Nguyen, L and Fouladi, R T and Li, Y and Cofta-Woerpel, L},
doi = {10.1002/cncr.22360},
issn = {0008-543X (Print) 0008-543x},
journal = {Cancer},
number = {2 Suppl},
pages = {406--413},
title = {{Reaching and treating Spanish-speaking smokers through the National Cancer Institute's Cancer Information Service. A randomized controlled trial}},
volume = {109},
year = {2007}
}
@article{DAgostino:2007cp,
author = {D'Agostino, R B},
journal = {Circulation},
month = {may},
number = {17},
pages = {2340--2343},
title = {{Propensity Scores in Cardiovascular Research}},
volume = {115},
year = {2007}
}
@article{villar2018,
abstract = {Response-adaptive randomisation (RAR) can considerably improve the chances of a successful treatment outcome for patients in a clinical trial by skewing the allocation probability towards better performing treatments as data accumulates. There is considerable interest in using RAR designs in drug development for rare diseases, where traditional designs are not either feasible or ethically questionable. In this paper, we discuss and address a major criticism levelled at RAR: namely, type I error inflation due to an unknown time trend over the course of the trial. The most common cause of this phenomenon is changes in the characteristics of recruited patients—referred to as patient drift. This is a realistic concern for clinical trials in rare diseases due to their lengthly accrual rate. We compute the type I error inflation as a function of the time trend magnitude to determine in which contexts the problem is most exacerbated. We then assess the ability of different correction methods to preserve type I error in these contexts and their performance in terms of other operating characteristics, including patient benefit and power. We make recommendations as to which correction methods are most suitable in the rare disease context for several RAR rules, differentiating between the 2-armed and the multi-armed case. We further propose a RAR design for multi-armed clinical trials, which is computationally efficient and robust to several time trends considered.},
author = {Villar, Sof{\'{i}}a S. and Bowden, Jack and Wason, James},
doi = {10.1002/pst.1845},
file = {::},
issn = {15391612},
journal = {Pharmaceutical Statistics},
keywords = {clinical trials,power,randomisation test,response-adaptive randomisation,type I error},
number = {2},
pages = {182--197},
pmid = {29266692},
title = {{Response-adaptive designs for binary responses: How to offer patient benefit while being robust to time trends?}},
volume = {17},
year = {2018}
}
@article{ball1973reading,
author = {Ball, Samuel and Others},
publisher = {ERIC},
title = {{Reading with Television: An Evaluation of The Electric Company. A Report to the Children's Television Workshop. Volumes 1 and 2.}},
year = {1973}
}
@article{Jennison:1984cq,
author = {Jennison, Christopher and Turnbull, Bruce W},
file = {::},
journal = {Controlled Clinical Trials},
month = {mar},
number = {1},
pages = {33--45},
title = {{Repeated confidence intervals for group sequential clinical trials}},
volume = {5},
year = {1984}
}
@article{Yang:2011it,
author = {Yang, S and Prentice, R L},
journal = {Biostatistics (Oxford, England)},
month = {mar},
number = {2},
pages = {354--368},
title = {{Estimation of the 2-sample hazard ratio function using a semiparametric model}},
volume = {12},
year = {2011}
}
@misc{beck2016package,
author = {Beck, Cole and Lu, Bo and Greevy, Robert and Beck, Maintainer Cole},
publisher = {CRAN},
title = {{Package ‘nbpMatching'}},
year = {2016}
}
@article{Gail:2017go,
author = {Gail, Mitchell H and Haneuse, Sebastien},
journal = {Statistical Methods in Medical Research},
month = {jan},
pages = {962280217737157},
title = {{Power and sample size for multivariate logistic modeling of unmatched case-control studies.}},
year = {2017}
}
@article{Ding2018a,
abstract = {Fisher randomization tests for Neyman's null hypothesis of no average treatment effect are considered in a finite-population setting associated with completely randomized experiments involving more than two treatments. The consequences of using the F statistic to conduct such a test are examined, and we argue that under treatment effect heterogeneity, use of the F statistic in the Fisher randomization test can severely inflate the Type I error under Neyman's null hypothesis. We propose to use an alternative test statistic, derive its asymptotic distributions under Fisher's and Neyman's null hypotheses, and demonstrate its advantages through simulations.},
archivePrefix = {arXiv},
arxivId = {1608.01787},
author = {Ding, Peng and Dasgupta, Tirthankar},
doi = {10.1093/biomet/asx059},
eprint = {1608.01787},
issn = {14643510},
journal = {Biometrika},
keywords = {Additivity,Fisher randomization test,Null hypothesis,One-way layout},
number = {1},
pages = {45--56},
title = {{A randomization-based perspective on analysis of variance: A test statistic robust to treatment effect heterogeneity}},
volume = {105},
year = {2018}
}
@article{Normand:2001hw,
author = {Normand, Sharon-Lise T and Landrum, Mary Beth and Guadagnoli, Edward and Ayanian, John Z and Ryan, Thomas J and Cleary, Paul D and McNeil, Barbara J},
journal = {Journal of Clinical Epidemiology},
month = {apr},
number = {4},
pages = {387--398},
title = {{Validating recommendations for coronary angiography following acute myocardial infarction in the elderly: A matched analysis using propensity scores}},
volume = {54},
year = {2001}
}
@article{Parhat2014,
abstract = {We discuss the computation of randomization tests for clinical trials of two treatments when the primary outcome is based on a regression model. We begin by revisiting the seminal paper of Gail, Tan, and Piantadosi (1988), and then describe a method based on Monte Carlo generation of randomization sequences. The tests based on this Monte Carlo procedure are design based, in that they incorporate the particular randomization procedure used. We discuss permuted block designs, complete randomization, and biased coin designs. We also use a new technique by Plamadeala and Rosenberger (2012) for simple computation of conditional randomization tests. Like Gail, Tan, and Piantadosi, we focus on residuals from generalized linear models and martingale residuals from survival models. Such techniques do not apply to longitudinal data analysis, and we introduce a method for computation of randomization tests based on the predicted rate of change from a generalized linear mixed model when outcomes are longitudinal. We show, by simulation, that these randomization tests preserve the size and power well under model misspecification. {\textcopyright} 2014 John Wiley {\&} Sons, Ltd.},
author = {Parhat, Parwen and Rosenberger, William F. and Diao, Guoqing},
doi = {10.1002/sim.6149},
file = {::},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Generalized linear mixed models,Generalized linear models,Linear rank test,Longitudinal data,Martingale residuals,Time-to-event data},
number = {18},
pages = {3078--3088},
pmid = {24648378},
title = {{Conditional Monte Carlo randomization tests for regression models}},
volume = {33},
year = {2014}
}
@article{Anonymous:u00BRJU6,
month = {oct},
pages = {1--398},
title = {{"Front Matter". In: Bayesian Approaches to Clinical Trials and Health-Care Evaluation}},
year = {2008}
}
@article{Benedetto:2014jh,
author = {Benedetto, Umberto and Raja, Shahzad G},
journal = {The Journal of Thoracic and Cardiovascular Surgery},
month = {nov},
number = {5},
pages = {2390----2396.e1},
title = {{Scoring system to guide decision making for the use of gentamicin-impregnated collagen sponge to prevent deep sternal wound infection}},
volume = {148},
year = {2014}
}
@article{Whitehead1986,
author = {Whitehead, John},
file = {::},
number = {3},
pages = {573--581},
title = {{On the Bias of Maximum Likelihood Estimation Following a Sequential Test Author ( s ): John Whitehead Published by : Oxford University Press on behalf of Biometrika Trust Stable URL : https://www.jstor.org/stable/2336521 REFERENCES Linked references are a}},
volume = {73},
year = {1986}
}
@article{Houlston2004,
abstract = {Much of the familial aggregation of common cancer results from inherited susceptibility, but highly penetrant mutations in known genes cannot account for most of the excess. Some of the unexplained familial risk is presumably due to high-penetrance mutations in as yet unidentified genes, but polygenic mechanisms are likely to account for a greater proportion, particularly in breast cancer. This inference, coupled with technological developments, has led to a renaissance in association studies. Most such studies have evaluated small numbers of single-nucleotide polymorphisms (SNPs) in a few candidate genes, but reliable high-density oligonucleoticle arrays and other novel techniques will allow genome-wide allelic association studies to be conducted. High-density genome-wide SNP analysis will include targets identified by structural considerations, as well as the growing list of candidate genes. In the longer term, high-throughput resequencing will be required to identify the rare pathogenic variants that may constitute the majority of low-penetrance alleles. The detection of low-penetrance cancer susceptibility genes will then be restricted mainly by the availability of large numbers of well-characterized cases and controls. Cancer patients with affected relatives are considerably more informative than unselected cases for such studies.},
author = {Houlston, Richard S. and Peto, Julian},
doi = {10.1038/sj.onc.1207951},
issn = {09509232},
journal = {Oncogene},
number = {38},
pages = {6471--6476},
pmid = {15322517},
title = {{The search for low-penetrance cancer susceptibility alleles}},
volume = {23},
year = {2004}
}
@article{Dahabreh:2018fc,
author = {Dahabreh, Issa J and Robertson, Sarah E and Tchetgen, Eric J Tchetgen and Stuart, Elizabeth A and Hern{\'{a}}n, Miguel A},
journal = {Biometrics},
month = {nov},
title = {{Generalizing causal inferences from individuals in randomized trials to all trial-eligible individuals.}},
year = {2018}
}
@article{Merl:2009ki,
author = {Merl, Daniel and Johnson, Leah R and Gramacy, Robert B and Mangel, Marc},
journal = {PloS one},
month = {jun},
number = {6},
pages = {e5807},
title = {{A Statistical Framework for the Adaptive Management of Epidemiological Interventions}},
volume = {4},
year = {2009}
}
@article{Cook:2010eh,
author = {Cook, Nancy R},
journal = {Current Cardiovascular Risk Reports},
month = {feb},
number = {2},
pages = {112--119},
title = {{Assessing the Incremental Role of Novel and Emerging Risk Factors}},
volume = {4},
year = {2010}
}
@article{Joffe:1999fe,
author = {Joffe, Marshall M and Rosenbaum, Paul R},
journal = {American Journal of Epidemiology},
month = {aug},
number = {4},
pages = {327--333},
title = {{Invited Commentary: Propensity Scores}},
volume = {150},
year = {1999}
}
@article{Nelson2021,
abstract = {OBJECTIVE: Text messaging interventions have high potential for scalability and for reductions in health disparities. However, more rigorous, long-term trials are needed. We examined the long-term efficacy and mechanisms of a tailored text messaging intervention. RESEARCH DESIGN AND METHODS: Adults with type 2 diabetes participated in a parallel-groups, 15-month randomized controlled trial and were assigned to receive Rapid Education/Encouragement and Communications for Health (REACH) for 12 months or control. REACH included interactive texts and tailored texts addressing medication adherence and nontailored texts supporting other self-care behaviors. Outcomes included hemoglobin A1c (HbA1c), diabetes medication adherence, self-care, and self-efficacy. RESULTS: Participants (N = 506) were approximately half racial/ethnic minorities, and half were underinsured, had annual household incomes {\textless}{\$}35,000, and had a high school education or less; 11{\%} were homeless. Average baseline HbA1c was 8.6{\%} ± 1.8{\%}; 70.0 ± 19.7 mmol/mol) with n = 219 having HbA1c ≥8.5{\%} (69 mmol/mol). Half were prescribed insulin. Retention was over 90{\%}. Median response rate to interactive texts was 91{\%} (interquartile range 75{\%}, 97{\%}). The treatment effect on HbA1c at 6 months (-0.31{\%}; 95{\%} CI -0.61{\%}, -0.02{\%}) was greater among those with baseline HbA1c ≥8.5{\%} (-0.74{\%}; 95{\%} CI -1.26{\%}, -0.23{\%}), and there was no evidence of effect modification by race/ethnicity or socioeconomic disadvantage. REACH improved medication adherence and diet through 12 months and self-efficacy through 6 months. Treatment effects were not significant for any outcome at 15 months. REACH reduced barriers to adherence, but barrier reduction did not mediate outcome improvements. CONCLUSIONS: REACH engaged at-risk patients in diabetes self-management and improved short-term HbA1c. More than texts alone may be needed to sustain the effects.},
author = {Nelson, Lyndsay A. and Greevy, Robert A. and Spieker, Andrew and Wallston, Kenneth A. and Elasy, Tom A. and Kripalani, Sunil and Gentry, Chad and Bergner, Erin M. and LeStourgeon, Lauren M. and Williamson, Sarah E. and Mayberry, Lindsay S.},
doi = {10.2337/dc20-0961},
file = {::},
issn = {19355548},
journal = {Diabetes care},
number = {1},
pages = {26--34},
pmid = {33154039},
title = {{Effects of a Tailored Text Messaging Intervention Among Diverse Adults With Type 2 Diabetes: Evidence From the 15-Month REACH Randomized Controlled Trial}},
volume = {44},
year = {2021}
}
@article{Roychoudhury:2018gg,
author = {Roychoudhury, Satrajit and Scheuer, Nicolas and Neuenschwander, Beat},
journal = {Clinical Trials},
month = {aug},
number = {5},
pages = {452--461},
title = {{Beyond p-values: A phase II dual-criterion design with statistical significance and clinical relevance}},
volume = {15},
year = {2018}
}
@article{Royall:2000ih,
author = {Royall, Richard},
journal = {Journal of the American Statistical Association},
month = {sep},
number = {451},
pages = {760--768},
title = {{On the Probability of Observing Misleading Statistical Evidence}},
volume = {95},
year = {2000}
}
@book{Charles2018,
address = {Amherst, New York},
author = {Charles, Patrick J.},
isbn = {9781633883130},
keywords = {National Rifle Association of America},
language = {eng},
publisher = {Prometheus Books},
title = {{Armed in America : a history of gun rights from colonial militias to concealed carry}},
year = {2018}
}
@article{jennison2015adaptive,
author = {Jennison, Christopher and Turnbull, Bruce W},
journal = {Statistics in medicine},
number = {29},
pages = {3793--3810},
publisher = {Wiley Online Library},
title = {{Adaptive sample size modification in clinical trials: start small then ask for more?}},
volume = {34},
year = {2015}
}
@article{Min2019b,
abstract = {AIM: To evaluate whether weight change or hypoglycaemia mediates the association  between insulin use and death. MATERIALS AND METHODS: In a retrospective cohort of veterans who filled a new prescription for metformin and added insulin or sulphonylurea (2001-2012), we assessed change in body mass index (BMI) and hypoglycaemia during the first 12 months of treatment intensification. Cox proportional hazards models compared the risk of death between treatment groups. Using the difference method, we estimated the indirect effect and proportion mediated through each mediator. A sensitivity analysis assessed mediators in the first 6 months of intensified therapy. RESULTS: Among 28 892 patients surviving 12 months, deaths per 1000 person-years were 15.4 for insulin users and 12.9 for sulphonylurea users (HR 1.20, 95{\%} CI 0.87, 1.64). Change in BMI and hypoglycaemia mediated 13{\%} (-98, 98) and -1{\%} (-37, 71) of this association, respectively. Among 30 214 patients surviving 6 months, deaths per 1000 person-years were 34.8 for insulin users and 21.3 for sulphonylurea users (HR 1.66, 95{\%} CI 1.28, 2.15). Change in BMI and hypoglycaemia mediated 9{\%} (1, 23) and 0{\%} (-9, 4) of this association, respectively. CONCLUSIONS: We observed an increased risk of death among metformin users intensifying treatment with insulin versus sulphonylurea and surviving 6 months of intensified therapy, but not among those surviving 12 months. This association was mediated in part by weight change.},
author = {Min, Jea Young and Hackstadt, Amber J and Griffin, Marie R and Greevy, Robert A Jr and Chipman, Jonathan and Grijalva, Carlos G and Hung, Adriana M and Roumie, Christianne L},
doi = {10.1111/dom.13846},
issn = {1463-1326 (Electronic)},
journal = {Diabetes, obesity {\&} metabolism},
language = {eng},
month = {aug},
pmid = {31373104},
title = {{Evaluation of weight change and hypoglycaemia as mediators in the association between insulin use and death.}},
year = {2019}
}
@article{proschan2020resist,
author = {Proschan, Michael and Evans, Scott},
file = {::},
journal = {Clinical Infectious Diseases},
number = {11},
pages = {3002--3004},
publisher = {Oxford University Press US},
title = {{Resist the temptation of response-adaptive randomization}},
volume = {71},
year = {2020}
}
@article{Ross:2011bo,
author = {Ross, Judith L and Quigley, Charmian A and Cao, Dachuang and Feuillan, Penelope and Kowal, Karen and Chipman, John J and {Cutler Jr.}, Gordon B},
journal = {New England Journal of Medicine},
month = {mar},
number = {13},
pages = {1230--1242},
title = {{Growth Hormone plus Childhood Low-Dose Estrogen in Turner's Syndrome}},
volume = {364},
year = {2011}
}
@article{VanCalster:2010ki,
author = {{Van Calster}, Ben and {Van Huffel}, Sabine},
journal = {Statistics in medicine},
month = {jan},
number = {2},
pages = {318--319},
title = {{Integrated discrimination improvement and probability-sensitive AUC variants}},
volume = {29},
year = {2010}
}
@article{Anonymous:1994wl,
journal = {Circulation},
month = {oct},
number = {4},
pages = {1765--1773},
title = {{A randomized trial of beta-blockade in heart failure. The Cardiac Insufficiency Bisoprolol Study (CIBIS). CIBIS Investigators and Committees.}},
volume = {90},
year = {1994}
}
@article{sverdlov2023randomization,
author = {Sverdlov, Oleksandr and Carter, Kerstine and Hilgers, Ralf-Dieter and Everett, Colin C and Berger, Vance W and Luo, Yuqun Abigail and Chipman, Jonathan J and Ryeznik, Yevgen and Ross, Jennifer and Knight, Ruth and Yamada, Kazumi},
doi = {10.1080/19466315.2023.2225451},
journal = {Statistics in Biopharmaceutical Research},
number = {ja},
pages = {1--21},
publisher = {Taylor {\&} Francis},
title = {{Which Randomization Methods Are Used Most Frequently in Clinical Trials? Results of a Survey by the Randomization Working Group}},
url = {https://doi.org/10.1080/19466315.2023.2225451},
volume = {0},
year = {2023}
}
@article{Morgan:2012iq,
author = {Morgan, K L and Rubin, D B},
journal = {The Annals of Statistics},
title = {{Rerandomization to improve covariate balance in experiments}},
year = {2012}
}
@book{molenberghs2014handbook,
author = {Molenberghs, Geert and Fitzmaurice, Garrett and Kenward, Michael G and Tsiatis, Anastasios and Verbeke, Geert},
file = {::},
publisher = {CRC Press},
title = {{Handbook of missing data methodology}},
year = {2014}
}
@book{royall1997statistical,
author = {Royall, Richard},
publisher = {CRC press},
title = {{Statistical evidence: a likelihood paradigm}},
volume = {71},
year = {1997}
}
@article{Rubin:1978bv,
author = {Rubin, Donald B},
file = {::},
journal = {The Annals of Statistics},
number = {1},
pages = {34--58},
title = {{Bayesian Inference for Causal Effects: The Role of Randomization}},
volume = {6},
year = {1978}
}
@article{Drazen:2015bk,
author = {Drazen, Jeffrey M and Morrissey, Stephen and Campion, Edward W and Jarcho, John A},
journal = {New England Journal of Medicine},
month = {nov},
number = {22},
pages = {2174--2175},
title = {{A SPRINT to the Finish}},
volume = {373},
year = {2015}
}
@article{campbell2018tenecteplase,
author = {Campbell, Bruce C V and Mitchell, Peter J and Churilov, Leonid and Yassi, Nawaf and Kleinig, Timothy J and Dowling, Richard J and Yan, Bernard and Bush, Steven J and Dewey, Helen M and Thijs, Vincent and Others},
journal = {New England Journal of Medicine},
number = {17},
pages = {1573--1582},
publisher = {Mass Medical Soc},
title = {{Tenecteplase versus alteplase before thrombectomy for ischemic stroke}},
volume = {378},
year = {2018}
}
@article{Buse:1982ds,
author = {Buse, A},
journal = {The American statistician},
month = {aug},
number = {3a},
pages = {153--157},
title = {{The Likelihood Ratio, Wald, and Lagrange Multiplier Tests: An Expository Note}},
volume = {36},
year = {1982}
}
@article{Statistics2012,
author = {Statistics, Mathematical},
file = {::},
number = {1},
pages = {165--197},
title = {{A Modification of the Sequential Probability Ratio Test to Reduce the Sample Size Author ( s ): T . W . Anderson Reviewed work ( s ): Source : The Annals of Mathematical Statistics , Vol . 31 , No . 1 ( Mar ., 1960 ), pp . 165-197 Published by : Institute}},
volume = {31},
year = {2012}
}
@article{AMBERSON:1931wk,
author = {AMBERSON, J B Jr},
journal = {American Review of Tuberculosis},
pages = {401--435},
title = {{A clinical trial of sanocrysin in pulmonary tuberculosis}},
volume = {24},
year = {1931}
}
@article{mayberry2019text,
author = {Mayberry, Lindsay S and Bergner, Erin M and Harper, Kryseana J and Laing, Simone and Berg, Cynthia A},
journal = {Journal of the American Medical Informatics Association},
number = {10},
pages = {1099--1108},
publisher = {Oxford University Press},
title = {{Text messaging to engage friends/family in diabetes self-management support: acceptability and potential to address disparities}},
volume = {26},
year = {2019}
}
@article{Li:2013cd,
author = {Li, J and Jiang, B and Fine, J P},
journal = {Biostatistics (Oxford, England)},
month = {mar},
number = {2},
pages = {382--394},
title = {{Multicategory reclassification statistics for assessing improvements in diagnostic accuracy}},
volume = {14},
year = {2013}
}
@book{jennison1999group,
author = {Jennison, Christopher and Turnbull, Bruce W},
publisher = {CRC Press},
title = {{Group sequential methods with applications to clinical trials}},
year = {1999}
}
@article{Austin2017,
abstract = {In survival analysis, a competing risk is an event whose occurrence precludes the occurrence of the primary event of interest. Outcomes in medical research are frequently subject to competing risks. In survival analysis, there are 2 key questions that can be addressed using competing risk regression models: first, which covariates affect the rate at which events occur, and second, which covariates affect the probability of an event occurring over time. The cause-specific hazard model estimates the effect of covariates on the rate at which events occur in subjects who are currently event-free. Subdistribution hazard ratios obtained from the Fine-Gray model describe the relative effect of covariates on the subdistribution hazard function. Hence, the covariates in this model can also be interpreted as having an effect on the cumulative incidence function or on the probability of events occurring over time. We conducted a review of the use and interpretation of the Fine-Gray subdistribution hazard model in articles published in the medical literature in 2015. We found that many authors provided an unclear or incorrect interpretation of the regression coefficients associated with this model. An incorrect and inconsistent interpretation of regression coefficients may lead to confusion when comparing results across different studies. Furthermore, an incorrect interpretation of estimated regression coefficients can result in an incorrect understanding about the magnitude of the association between exposure and the incidence of the outcome. The objective of this article is to clarify how these regression coefficients should be reported and to propose suggestions for interpreting these coefficients.},
annote = {In many instances, particularly in epidemiological research, the most appropriate model will be the cause‐specific hazard model. However, in settings in which it is important to make inferences about the effect of covariates on the incidence of the outcome, then the Fine‐Gray model will be the most appropriate model.},
author = {Austin, Peter C. and Fine, Jason P.},
doi = {10.1002/sim.7501},
file = {::},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {competing risks,cumulative incidence function,subdistribution hazard model,survival analysis},
number = {27},
pages = {4391--4400},
pmid = {28913837},
title = {{Practical recommendations for reporting Fine-Gray model analyses for competing risk data}},
volume = {36},
year = {2017}
}
@article{antoniou2010common,
abstract = {The known breast cancer susceptibility polymorphisms in FGFR2, TNRC9/TOX3, MAP3K1, LSP1, and 2q35 confer increased risks of breast cancer for BRCA1 or BRCA2 mutation carriers. We evaluated the associations of 3 additional single nucleotide polymorphisms (SNPs), rs4973768 in SLC4A7/NEK10, rs6504950 in STXBP4/COX11, and rs10941679 at 5p12, and reanalyzed the previous associations using additional carriers in a sample of 12,525 BRCA1 and 7,409 BRCA2 carriers. Additionally, we investigated potential interactions between SNPs and assessed the implications for risk prediction. The minor alleles of rs4973768 and rs10941679 were associated with increased breast cancer risk for BRCA2 carriers (per-allele HR = 1.10, 95{\%} CI: 1.03-1.18, P = 0.006 and HR = 1.09, 95{\%} CI: 1.01-1.19, P = 0.03, respectively). Neither SNP was associated with breast cancer risk for BRCA1 carriers, and rs6504950 was not associated with breast cancer for either BRCA1 or BRCA2 carriers. Of the 9 polymorphisms investigated, 7 were associated with breast cancer for BRCA2 carriers (FGFR2, TOX3, MAP3K1, LSP1, 2q35, SLC4A7, 5p12, P = 7 × 10-11 - 0.03), but only TOX3 and 2q35 were associated with the risk for BRCA1 carriers (P = 0.0049, 0.03, respectively). All risk-associated polymorphisms appear to interact multiplicatively on breast cancer risk for mutation carriers. Based on the joint genotype distribution of the 7 risk-associated SNPs in BRCA2 mutation carriers, the 5{\%} of BRCA2 carriers at highest risk (i.e., between 95th and 100th percentiles) were predicted to have a probability between 80{\%} and 96{\%} of developing breast cancer by age 80, compared with 42{\%} to 50{\%} for the 5{\%} of carriers at lowest risk. Our findings indicated that these risk differences might be sufficient to influence the clinical management of mutation carriers. {\textcopyright}2010 AACR.},
author = {Antoniou, Antonis C. and Beesley, Jonathan and McGuffog, Lesley and Sinilnikova, Olga M. and Healey, Sue and Neuhausen, Susan L. and Ding, Yuan Chun and Rebbeck, Timothy R. and Weitzel, Jeffrey N. and Lynch, Henry T. and Isaacs, Claudine and Ganz, Patricia A. and Tomlinson, Gail and Olopade, Olufunmilayo I. and Couch, Fergus J. and Wang, Xianshu and Lindor, Noralane M. and Pankratz, Vernon S. and Radice, Paolo and Manoukian, Siranoush and Peissel, Bernard and Zaffaroni, Daniela and Barile, Monica and Viel, Alessandra and Allavena, Anna and Dall'Olio, Valentina and Peterlongo, Paolo and Szabo, Csilla I. and Zikan, Michal and Claes, Kathleen and Poppe, Bruce and Foretova, Lenka and Mai, Phuong L. and Greene, Mark H. and Rennert, Gad and Lejbkowicz, Flavio and Glendon, Gord and Ozcelik, Hilmi and Andrulis, Irene L. and Thomassen, Mads and Gerdes, Anne Marie and Sunde, Lone and Cruger, Dorthe and Jensen, Uffe Birk and Caligo, Maria and Friedman, Eitan and Kaufman, Bella and Laitman, Yael and Milgrom, Roni and Dubrovsky, Maya and Cohen, Shimrit and Borg, Ake and Jernstr{\"{o}}m, Helena and Lindblom, Annika and Rantala, Johanna and Stenmark-Askmalm, Marie and Melin, Beatrice and Nathanson, Kate and Domchek, Susan and Jakubowska, Ania and Lubinski, Jan and Huzarski, Tomasz and Osorio, Ana and Lasa, Adriana and Dur{\'{a}}n, Mercedes and Tejada, Maria Isabel and Godino, Javier and Benitez, Javier and Hamann, Ute and Kriege, Mieke and Hoogerbrugge, Nicoline and {Van Der Luijt}, Rob B. and {Van Asperen}, Christi J. and Devilee, Peter and Meijers-Heijboer, E. J. and Blok, Marinus J. and Aalfs, Cora M. and Hogervorst, Frans and Rookus, Matti and Cook, Margaret and Oliver, Clare and Frost, Debra and Conroy, Don and Evans, D. Gareth and Lalloo, Fiona and Pichert, Gabriella and Davidson, Rosemarie and Cole, Trevor and Cook, Jackie and Paterson, Joan and Hodgson, Shirley and Morrison, Patrick J. and Porteous, Mary E. and Walker, Lisa and Kennedy, M. John and Dorkins, Huw and Peock, Susan and Godwin, Andrew K. and Stoppa-Lyonnet, Dominique and {De Pauw}, Antoine and Mazoyer, Sylvie and Bonadona, Val{\'{e}}rie and Lasset, Christine and Dreyfus, H{\'{e}}l{\`{e}}ne and Leroux, Dominique and Hardouin, Agn{\`{e}}s and Berthet, Pascaline and Faivre, Laurence and Loustalot, Catherine and Noguchi, Tetsuro and Sobol, Hagay and Rouleau, Etienne and Nogues, Catherine and Fr{\'{e}}nay, Marc and V{\'{e}}nat-Bouvet, Laurence and Hopper, John L. and Daly, Mary B. and Terry, Mary B. and John, Esther M. and Buys, Saundra S. and Yassin, Yosuf and Miron, Alexander and Goldgar, David and Singer, Christian F. and Dressler, Anne Catharina and Gschwantler-Kaulich, Daphne and Pfeiler, Georg and Hansen, Thomas V.O. and Jnson, Lars and Agnarsson, Bjarni A. and Kirchhoff, Tomas and Offit, Kenneth and Devlin, Vincent and Dutra-Clarke, Ana and Piedmonte, Marion and Rodriguez, Gustavo C. and Wakeley, Katie and Boggess, John F. and Basil, Jack and Schwartz, Peter E. and Blank, Stephanie V. and Toland, Amanda Ewart and Montagna, Marco and Casella, Cinzia and Imyanitov, Evgeny and Tihomirova, Laima and Blanco, Ignacio and Lazaro, Conxi and Ramus, Susan J. and Sucheston, Lara and Karlan, Beth Y. and Gross, Jenny and Schmutzler, Rita and Wappenschmidt, Barbara and Engel, Christoph and Meindl, Alfons and Lochmann, Magdalena and Arnold, Norbert and Heidemann, Simone and Varon-Mateeva, Raymonda and Niederacher, Dieter and Sutter, Christian and Deissler, Helmut and Gadzicki, Dorothea and Preisler-Adams, Sabine and Kast, Karin and Sch{\"{o}}nbuchner, Ines and Caldes, Trinidad and {De La Hoya}, Miguel and Aittom{\"{a}}ki, Kristiina and Nevanlinna, Heli and Simard, Jacques and Spurdle, Amanda B. and Holland, Helene and Chen, Xiaoqing and Platte, Radka and Chenevix-Trench, Georgia and Easton, Douglas F.},
doi = {10.1158/0008-5472.CAN-10-1907},
file = {::},
issn = {15387445},
journal = {Cancer Research},
number = {23},
pages = {9742--9754},
title = {{Common breast cancer susceptibility alleles and the risk of breast cancer for BRCA1 and BRCA2 mutation carriers: Implications for risk prediction}},
volume = {70},
year = {2010}
}
@article{Steyerberg:2014iv,
author = {Steyerberg, Ewout W and Vedder, Moniek M and Leening, Maarten J G and Postmus, Douwe and {D'Agostino Sr.}, Ralph B and {Van Calster}, Ben and Pencina, Michael J},
journal = {Biometrical Journal},
month = {jul},
number = {4},
pages = {556--570},
title = {{Graphical assessment of incremental value of novel markers in prediction models: From statistical to decision analytical perspectives}},
volume = {57},
year = {2014}
}
@incollection{Steyerberg:2008hu,
address = {New York, NY},
author = {Steyerberg, E W},
booktitle = {Clinical Prediction Models},
month = {sep},
pages = {335--360},
publisher = {Springer New York},
title = {{Patterns of external validity}},
year = {2008}
}
@article{Yuan2011a,
abstract = {We propose a Bayesian response-adaptive covariate-balanced (RC) randomization design for multiple-arm comparative clinical trials. The goal of the design is to skew the allocation probability to more efficacious treatment arms, while also balancing the distribution of the covariates across the arms. In particular, we first propose a new covariate-adaptive randomization (CA) method based on a prognostic score that naturally accommodates continuous and categorical prognostic factors and automatically assigns imbalance weights to covariates according to their importance in response prediction. We then incorporate this CA design into a group sequential response-adaptive randomization (RA) scheme. The resulting RC randomization design combines the advantages of both CA and RA randomizations and meets the design goal. We illustrate the proposed design through its application to a phase II leukemia clinical trial, and evaluate its operating characteristics through simulation studies. {\textcopyright} 2011 John Wiley {\&} Sons, Ltd.},
author = {Yuan, Ying and Huang, Xuelin and Liu, Suyu},
doi = {10.1002/sim.4218},
file = {::},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Adaptive randomization,Balance covariates,Prognostic factor,Response-adaptive},
number = {11},
pages = {1218--1229},
pmid = {21432894},
title = {{A Bayesian response-adaptive covariate-balanced randomization design with application to a leukemia clinical trial}},
volume = {30},
year = {2011}
}
@article{Hilgers:2017dp,
author = {Hilgers, Ralf-Dieter and Uschner, Diane and Rosenberger, William F and Heussen, Nicole},
journal = {BMC Medical Research Methodology},
month = {dec},
number = {1},
pages = {159},
title = {{ERDO - a framework to select an appropriate randomization procedure for clinical trials.}},
volume = {17},
year = {2017}
}
@book{Piantadosi:2005uc,
address = {Hoboken, NJ, USA},
author = {Piantadosi, Steven},
month = {jul},
publisher = {John Wiley {\&} Sons, Inc.},
series = {A Methodologic Perspective},
title = {{Clinical Trials}},
year = {2005}
}
@article{mavaddat2013cancer,
abstract = {Background Reliable estimates of cancer risk are critical for guiding management of BRCA1 and BRCA2 mutation carriers. The aims of this study were to derive penetrance estimates for breast cancer, ovarian cancer, and contralateral breast cancer in a prospective series of mutation carriers and to assess how these risks are modified by common breast cancer susceptibility alleles. Methods Prospective cancer risks were estimated using a cohort of 978 BRCA1 and 909 BRCA2 carriers from the United Kingdom. Nine hundred eighty-eight women had no breast or ovarian cancer diagnosis at baseline, 1509 women were unaffected by ovarian cancer, and 651 had been diagnosed with unilateral breast cancer. Cumulative risks were obtained using Kaplan-Meier estimates. Associations between cancer risk and covariables of interest were evaluated using Cox regression. All statistical tests were two-sided. Results The average cumulative risks by age 70 years for BRCA1 carriers were estimated to be 60{\%} (95{\%} confidence interval [CI] = 44{\%} to 75{\%}) for breast cancer, 59{\%} (95{\%} CI = 43{\%} to 76{\%}) for ovarian cancer, and 83{\%} (95{\%} CI = 69{\%} to 94{\%}) for contralateral breast cancer. For BRCA2 carriers, the corresponding risks were 55{\%} (95{\%} CI = 41{\%} to 70{\%}) for breast cancer, 16.5{\%} (95{\%} CI = 7.5{\%} to 34{\%}) for ovarian cancer, and 62{\%} (95{\%} CI = 44{\%} to 79.5{\%}) for contralateral breast cancer. BRCA2 carriers in the highest tertile of risk, defined by the joint genotype distribution of seven single nucleotide polymorphisms associated with breast cancer risk, were at statistically significantly higher risk of developing breast cancer than those in the lowest tertile (hazard ratio = 4.1, 95{\%} CI = 1.2 to 14.5; P =. 02). Conclusions Prospective risk estimates confirm that BRCA1 and BRCA2 carriers are at high risk of developing breast, ovarian, and contralateral breast cancer. Our results confirm findings from retrospective studies that common breast cancer susceptibility alleles in combination are predictive of breast cancer risk for BRCA2 carriers. {\textcopyright} 2013 The Author.},
author = {Mavaddat, Nasim and Peock, Susan and Frost, Debra and Ellis, Steve and Platte, Radka and Fineberg, Elena and Evans, D. Gareth and Izatt, Louise and Eeles, Rosalind A. and Adlard, Julian and Davidson, Rosemarie and Eccles, Diana and Cole, Trevor and Cook, Jackie and Brewer, Carole and Tischkowitz, Marc and Douglas, Fiona and Hodgson, Shirley and Walker, Lisa and Porteous, Mary E. and Morrison, Patrick J. and Side, Lucy E. and Kennedy, M. John and Houghton, Catherine and Donaldson, Alan and Rogers, Mark T. and Dorkins, Huw and Miedzybrodzka, Zosia and Gregory, Helen and Eason, Jacqueline and Barwell, Julian and McCann, Emma and Murray, Alex and Antoniou, Antonis C. and Easton, Douglas F.},
doi = {10.1093/jnci/djt095},
file = {::},
issn = {00278874},
journal = {Journal of the National Cancer Institute},
number = {11},
pages = {812--822},
pmid = {23628597},
title = {{Cancer risks for BRCA1 and BRCA2 mutation carriers: Results from prospective analysis of EMBRACE}},
volume = {105},
year = {2013}
}
@article{Kapelner2021,
abstract = {We propose a dynamic allocation procedure that increases power and efficiency when measuring an average treatment effect in sequential randomized trials exploiting some subjects' previous assessed responses. Subjects arrive sequentially and are either randomized or paired to a previously randomized subject and administered the alternate treatment. The pairing is made via a dynamic matching criterion that iteratively learns which specific covariates are important to the response. We develop estimators for the average treatment effect as well as an exact test. We illustrate our method's increase in efficiency and power over other allocation procedures in both simulated scenarios and a clinical trial dataset. An R package “SeqExpMatch” for use by practitioners is available on CRAN.},
author = {Kapelner, Adam and Krieger, Abba},
doi = {10.1111/biom.13561},
file = {::},
issn = {15410420},
journal = {Biometrics},
keywords = {clinical trials,covariate and response adaptive randomization,crowdsourcing experimentation,matching,sequential experiments},
title = {{A matching procedure for sequential experiments that iteratively learns which covariates improve power}},
year = {2021}
}
@article{Pocock:2016ey,
author = {Pocock, Stuart J and Stone, Gregg W},
journal = {New England Journal of Medicine},
month = {sep},
number = {9},
pages = {861--870},
title = {{The Primary Outcome Fails - What Next?}},
volume = {375},
year = {2016}
}
@article{Park2016,
abstract = {{\textcopyright} Copyright 2016 Massachusetts Medical Society. BACKGROUND The heterogeneity of breast cancer makes identifying effective therapies challenging. The I-SPY 2 trial, a multicenter, adaptive phase 2 trial of neoadjuvant therapy for highrisk clinical stage II or III breast cancer, evaluated multiple new agents added to standard chemotherapy to assess the effects on rates of pathological complete response (i.e., absence of residual cancer in the breast or lymph nodes at the time of surgery). METHODS We used adaptive randomization to compare standard neoadjuvant chemotherapy plus the tyrosine kinase inhibitor neratinib with control. Eligible women were categorized according to eight biomarker subtypes on the basis of human epidermal growth factor receptor 2 (HER2) status, hormone-receptor status, and risk according to a 70-gene profile. Neratinib was evaluated against control with regard to 10 biomarker signatures (prospectively defined combinations of subtypes). The primary end point was pathological complete response. Volume changes on serial magnetic resonance imaging were used to assess the likelihood of such a response in each patient. Adaptive assignment to experimental groups within each disease subtype was based on Bayesian probabilities of the superiority of the treatment over control. Enrollment in the experimental group was stopped when the 85{\%} Bayesian predictive probability of success in a confirmatory phase 3 trial of neoadjuvant therapy reached a prespecified threshold for any biomarker signature ("graduation"). Enrollment was stopped for futility if the probability fell to below 10{\%} for every biomarker signature. RESULTS Neratinib reached the prespecified efficacy threshold with regard to the HER2-positive, hormone-receptor-negative signature. Among patients with HER2-positive, hormone-receptor-negative cancer, the mean estimated rate of pathological complete response was 56{\%} (95{\%} Bayesian probability interval [PI], 37 to 73{\%}) among 115 patients in the neratinib group, as compared with 33{\%} among 78 controls (95{\%} PI, 11 to 54{\%}). The final predictive probability of success in phase 3 testing was 79{\%}. CONCLUSIONS Neratinib added to standard therapy was highly likely to result in higher rates of pathological complete response than standard chemotherapy with trastuzumab among patients with HER2-positive, hormone-receptor-negative breast cancer. (Funded by QuantumLeap Healthcare Collaborative and others; I-SPY 2 TRIAL ClinicalTrials.gov number, NCT01042379.).},
author = {Park, John W. and Liu, Minetta C. and Yee, Douglas and Yau, Christina and {van 't Veer}, Laura J. and Symmans, W. Fraser and Paoloni, Melissa and Perlmutter, Jane and Hylton, Nola M. and Hogarth, Michael and DeMichele, Angela and Buxton, Meredith B. and Chien, A. Jo and Wallace, Anne M. and Boughey, Judy C. and Haddad, Tufia C. and Chui, Stephen Y. and Kemmer, Kathleen A. and Kaplan, Henry G. and Isaacs, Claudine and Nanda, Rita and Tripathy, Debasish and Albain, Kathy S. and Edmiston, Kirsten K. and Elias, Anthony D. and Northfelt, Donald W. and Pusztai, Lajos and Moulder, Stacy L. and Lang, Julie E. and Viscusi, Rebecca K. and Euhus, David M. and Haley, Barbara B. and Khan, Qamar J. and Wood, William C. and Melisko, Michelle and Schwab, Richard and Helsten, Teresa and Lyandres, Julia and Davis, Sarah E. and Hirst, Gillian L. and Sanil, Ashish and Esserman, Laura J. and Berry, Donald A.},
doi = {10.1056/nejmoa1513750},
file = {::},
issn = {0028-4793},
journal = {New England Journal of Medicine},
number = {1},
pages = {11--22},
pmid = {27406346},
title = {{Adaptive Randomization of Neratinib in Early Breast Cancer}},
volume = {375},
year = {2016}
}
@inproceedings{Shalit2017,
author = {Shalit, Uri and Johansson, Fredrik D and Sontag, David},
booktitle = {International conference on machine learning},
pages = {3076--3085},
title = {{Estimating individual treatment effect: generalization bounds and algorithms}},
year = {2017}
}
@article{Shao:2013jz,
author = {Shao, Jun and Yu, Xinxin},
file = {::},
journal = {Biometrics},
month = {jul},
number = {4},
pages = {960--969},
title = {{Validity of Tests under Covariate-Adaptive Biased Coin Randomization and Generalized Linear Models}},
volume = {69},
year = {2013}
}
@misc{ForDiseaseControl2023,
author = {{for Disease Control}, Centers and Prevention},
number = {August 22},
title = {{COVID Data Tracker}},
volume = {2023},
year = {2023}
}
@misc{U.S.FoodandDrugAdministration2014,
author = {{U.S. Food and Drug Administration}},
booktitle = {https://fda.report/media/88337/103976-Omalizumab-Statistical-PREA.pdf},
file = {::},
keywords = {phase 3},
title = {{Statistical Review and Evaluation of NDA/BLA {\#}: STN 103976 s5211}},
url = {https://fda.report/media/88337/103976-Omalizumab-Statistical-PREA.pdf},
urldate = {2023-02-03},
year = {2014}
}
@article{Anonymous:rCKExJBO,
author = {Platt, J R},
journal = {Science},
month = {oct},
number = {3642},
pages = {347--353},
title = {{Strong Inference: Certain systematic methods of scientific thinking may produce much more rapid progress than others}},
volume = {146},
year = {1964}
}
@article{NAGELKERKE:1991hp,
author = {NAGELKERKE, N J D},
journal = {Biometrika},
number = {3},
pages = {691--692},
title = {{A note on a general definition of the coefficient of determination}},
volume = {78},
year = {1991}
}
@article{Anonymous:UBfPPuiI,
month = {nov},
pages = {1--10},
title = {{Sec 3 RS-POLICY}},
year = {2018}
}
@book{mallinckrodt2019estimands,
author = {Mallinckrodt, Craig and Molenberghs, Geert and Lipkovich, Ilya and Ratitch, Bohdana},
publisher = {CRC Press},
title = {{Estimands, estimators and sensitivity analysis in clinical trials}},
year = {2019}
}
@article{Jiang:2007bj,
author = {Jiang, Wenyu and Simon, Richard},
journal = {Statistics in medicine},
number = {29},
pages = {5320--5334},
title = {{A comparison of bootstrap methods and an adjusted bootstrap approach for estimating the prediction error in microarray classification}},
volume = {26},
year = {2007}
}
@article{Ye2020,
abstract = {Covariate-adaptive randomization is popular in clinical trials with sequentially arrived patients for balancing treatment assignments across prognostic factors that may have influence on the response. However, existing theory on tests for the treatment effect under covariate-adaptive randomization is limited to tests under linear or generalized linear models, although the covariate-adaptive randomization method has been used in survival analysis for a long time. Often, practitioners will simply adopt a conventional test to compare two treatments, which is controversial since tests derived under simple randomization may not be valid in terms of type I error under other randomization schemes. We derive the asymptotic distribution of the partial likelihood score function under covariate-adaptive randomization and a working model that is subject to possible model misspecification. Using this general result, we prove that the partial likelihood score test that is robust against model misspecification under simple randomization is no longer robust but conservative under covariate-adaptive randomization. We also show that the unstratified log-rank test is conservative and the stratified log-rank test remains valid under covariate-adaptive randomization. We propose a modification to variance estimation in the partial likelihood score test, which leads to a score test that is valid and robust against arbitrary model misspecification under a large family of covariate-adaptive randomization schemes including simple randomization. Furthermore, we show that the modified partial likelihood score test derived under a correctly specified model is more powerful than log-rank-type tests in terms of Pitman's asymptotic relative efficiency. Simulation studies about the type I error and power of various tests are presented under several popular randomization schemes.},
archivePrefix = {arXiv},
arxivId = {1811.07232},
author = {Ye, Ting and Shao, Jun},
doi = {10.1111/rssb.12392},
eprint = {1811.07232},
file = {::},
issn = {14679868},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Cox model,Log-rank test,Pitman's asymptotic relative efficiency,Robustness against model misspecification,Stratified permuted block,Type I error},
number = {5},
pages = {1301--1323},
title = {{Robust tests for treatment effect in survival analysis under covariate-adaptive randomization}},
volume = {82},
year = {2020}
}
@article{Hartman:2002iu,
author = {Hartman, Mark L and Crowe, Brenda J and Biller, Beverly M K and Ho, Ken K Y and Clemmons, David R and Chipman, John J},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {feb},
number = {2},
pages = {477--485},
title = {{Which Patients Do Not Require a GH Stimulation Test for the Diagnosis of Adult GH Deficiency?}},
volume = {87},
year = {2002}
}
@article{zampieri2020effects,
author = {Zampieri, Fernando G and Damiani, Lucas P and Bakker, Jan and Ospina-Tasc{\'{o}}n, Gustavo A and Castro, Ricardo and Cavalcanti, Alexandre B and Hernandez, Glenn},
journal = {American Journal of Respiratory and Critical Care Medicine},
number = {4},
pages = {423--429},
publisher = {American Thoracic Society},
title = {{Effects of a resuscitation strategy targeting peripheral perfusion status versus serum lactate levels among patients with septic shock. A Bayesian reanalysis of the ANDROMEDA-SHOCK Trial}},
volume = {201},
year = {2020}
}
@article{Beland2023,
author = {Beland, L P and Brodeur, A and Wright, T},
doi = {10.1371/journal.pone.0270341},
issn = {1932-6203 (Electronic) 1932-6203 (Linking)},
journal = {PLoS One},
number = {3},
pages = {e0270341},
title = {{The short-term economic consequences of COVID-19: Exposure to disease, remote work and government response}},
volume = {18},
year = {2023}
}
@article{Biswas2013,
abstract = {Health care providers need simple tools to identify patients at genetic risk of breast and ovarian cancers. Genetic risk prediction models such as BRCAPRO could fill this gap if incorporated into Electronic Medical Records or other Health Information Technology solutions. However, BRCAPRO requires potentially extensive information on the counselee and her family history. Thus, it may be useful to provide simplified version(s) of BRCAPRO for use in settings that do not require exhaustive genetic counseling. We explore four simplified versions of BRCAPRO, each using less complete information than the original model. BRCAPROLYTE uses information on affected relatives only up to second degree. It is in clinical use but has not been evaluated. BRCAPROLYTE-Plus extends BRCAPROLYTE by imputing the ages of unaffected relatives. BRCAPROLYTE-Simple reduces the data collection burden associated with BRCAPROLYTE and BRCAPROLYTE-Plus by not collecting the family structure. BRCAPRO-1Degree only uses first-degree affected relatives. We use data on 2,713 individuals from seven sites of the Cancer Genetics Network and MD Anderson Cancer Center to compare these simplified tools with the Family History Assessment Tool (FHAT) and BRCAPRO, with the latter serving as the benchmark. BRCAPROLYTE retains high discrimination; however, because it ignores information on unaffected relatives, it overestimates carrier probabilities. BRCAPROLYTE-Plus and BRCAPROLYTE-Simple provide better calibration than BRCAPROLYTE, so they have higher specificity for similar values of sensitivity. BRCAPROLYTE-Plus performs slightly better than BRCAPROLYTE-Simple. The Areas Under the ROC curve are 0.783 (BRCAPRO), 0.763 (BRCAPROLYTE), 0.772 (BRCAPROLYTE-Plus), 0.773 (BRCAPROLYTE-Simple), 0.728 (BRCAPRO-1Degree), and 0.745 (FHAT). The simpler versions, especially BRCAPROLYTE-Plus and BRCAPROLYTE-Simple, lead to only modest loss in overall discrimination compared to BRCAPRO in this dataset. Thus, we conclude that simplified implementations of BRCAPRO can be used for genetic risk prediction in settings where collection of complete pedigree information is impractical.},
author = {Biswas, Swati and Atienza, Philamer and Chipman, Jonathan and Hughes, Kevin and Barrera, Angelica M Gutierrez and Amos, Christopher I and Arun, Banu and Parmigiani, Giovanni},
doi = {10.1007/s10549-013-2564-4},
issn = {1573-7217 (Electronic)},
journal = {Breast cancer research and treatment},
keywords = {Breast Neoplasms,Female,Genes, BRCA1,Genes, BRCA2,Genetic Counseling,Genetic Predisposition to Disease,Heterozygote,Humans,Internet,Male,Medical Informatics,Mutation,Ovarian Neoplasms,Risk,Software,diagnosis,genetics,methods},
language = {eng},
month = {jun},
number = {2},
pages = {571--579},
pmid = {23690142},
title = {{Simplifying clinical use of the genetic risk prediction model BRCAPRO.}},
volume = {139},
year = {2013}
}
@article{Anonymous:A0cR_dee,
month = {feb},
pages = {1--11},
title = {{Pepe Anderson 1994}},
year = {2014}
}
@article{tendeiro2022,
abstract = {In classical statistics, there is a close link between null hypothesis significance testing (NHST) and parameter estimation via confidence intervals. However, for the Bayesian counterpart, a link between null hypothesis Bayesian testing (NHBT) and Bayesian estimation via a posterior distribution is less straightforward, but does exist, and has recently been reiterated by Rouder, Haaf, and Vandekerckhove (2018). It hinges on a combination of a point mass probability and a probability density function as prior (denoted as the spike-and-slab prior). In the present paper, it is first carefully explained how the spike-and-slab prior is defined, and how results can be derived for which proofs were not given in Rouder, Haaf, and Vandekerckhove (2018). Next, it is shown that this spike-and-slab prior can be approximated by a pure probability density function with a rectangular peak around the center towering highly above the remainder of the density function. Finally, we will indicate how this ‘hill-and-chimney' prior may in turn be approximated by fully continuous priors. In this way, it is shown that NHBT results can be approximated well by results from estimation using a strongly peaked prior, and it is noted that the estimation itself offers more than merely the posterior odds on which NHBT is based. Thus, it complies with the strong APA requirement of not just mentioning testing results but also offering effect size information. It also offers a transparent perspective on the NHBT approach employing a prior with a strong peak around the chosen point null hypothesis value.},
author = {Tendeiro, Jorge N. and Kiers, Henk A.L.},
doi = {10.3758/s13423-022-02164-3},
file = {::},
isbn = {1342302202164},
issn = {15315320},
journal = {Psychonomic Bulletin and Review},
keywords = {Bayes factor,Bayesian estimation,Null hypothesis Bayesian testing,Unification},
pages = {534--552},
publisher = {Springer US},
title = {{With Bayesian estimation one can get all that Bayes factors offer, and more}},
url = {https://doi.org/10.3758/s13423-022-02164-3},
year = {2022}
}
@article{Pickering:2012di,
author = {Pickering, J W and Endre, Z H},
journal = {Clinical Journal of the American Society of Nephrology},
month = {aug},
number = {8},
pages = {1355--1364},
title = {{New Metrics for Assessing Diagnostic Potential of Candidate Biomarkers}},
volume = {7},
year = {2012}
}
@article{Anonymous:XyZkCQCO,
month = {nov},
pages = {1--3},
title = {{Sec 4 - RS-POLICY}},
year = {2018}
}
@article{Smith:1992wx,
author = {Hanagal, D D},
journal = {Statistical Methods in Medical Research},
month = {dec},
number = {6},
pages = {936},
title = {{Modeling survival data using frailty models}},
volume = {24},
year = {2015}
}
@article{He:2007hm,
author = {He, Yanling and Huang, Wenzheng and Liang, Hua},
journal = {Communications in Statistics - Theory and Methods},
month = {nov},
number = {15},
pages = {2695--2706},
title = {{Axiomatic Development of Profile Likelihoods as the Strength of Evidence for Composite Hypotheses}},
volume = {36},
year = {2007}
}
@article{Kohli2017,
abstract = {Purpose: Androgen receptor (AR) variant AR-V7 is a ligand-independent transcription factor that promotes prostate cancer resistance to AR-targeted therapies. Accordingly, efforts are under way to develop strategies for monitoring and inhibiting AR-V7 in castration-resistant prostate cancer (CRPC). The purpose of this study was to understand whether other AR variants may be coexpressed with AR-V7 and promote resistance to AR-targeted therapies. Experimental Design: We utilized complementary short- and long-read sequencing of intact AR mRNA isoforms to characterize AR expression in CRPC models. Coexpression of AR-V7 and AR-V9 mRNA in CRPC metastases and circulating tumor cells was assessed by RNA-seq and RT-PCR, respectively. Expression of AR-V9 protein in CRPC models was evaluated with polyclonal antisera. Multivariate analysis was performed to test whether AR variant mRNA expression in metastatic tissues was associated with a 12-week progression-free survival endpoint in a prospective clinical trial of 78 CRPC-stage patients initiating therapy with the androgen synthesis inhibitor, abiraterone acetate. Results: AR-V9 was frequently coexpressed with AR-V7. Both AR variant species were found to share a common 30 terminal cryptic exon, which rendered AR-V9 susceptible to experimental manipulations that were previously thought to target AR-V7 uniquely. AR-V9 promoted ligand-independent growth of prostate cancer cells. High AR-V9 mRNA expression in CRPC metastases was predictive of primary resistance to abiraterone acetate (HR ¼ 4.0; 95{\%} confidence interval, 1.31–12.2; P ¼ 0.02). Conclusions: AR-V9 may be an important component of therapeutic resistance in CRPC.},
author = {Kohli, Manish and Ho, Yeung and Hillman, David W. and {Van Etten}, Jamie L. and Henzler, Christine and Yang, Rendong and Sperger, Jamie M. and Li, Yingming and Tseng, Elizabeth and Hon, Ting and Clark, Tyson and Tan, Winston and Carlson, Rachel E. and Wang, Liguo and Sicotte, Hugues and Thai, Ho and Jimenez, Rafael and Huang, Haojie and Vedell, Peter T. and Eckloff, Bruce W. and Quevedo, Jorge F. and Pitot, Henry C. and Costello, Brian A. and Jen, Jin and Wieben, Eric D. and Silverstein, Kevin A.T. and Lang, Joshua M. and Wang, Liewei and Dehm, Scott M.},
doi = {10.1158/1078-0432.CCR-17-0017},
isbn = {6126251504},
issn = {15573265},
journal = {Clinical Cancer Research},
number = {16},
pages = {4704--4715},
pmid = {28473535},
title = {{Androgen receptor variant AR-V9 is coexpressed with AR-V7 in prostate cancer metastases and predicts abiraterone resistance}},
volume = {23},
year = {2017}
}
@book{Berger:2010ue,
author = {Berger, V W},
publisher = {Contemporary clinical trials},
title = {{Minimization, by its nature, precludes allocation concealment, and invites selection bias}},
year = {2010}
}
@article{Papadimitrakopoulou2016,
abstract = {Purpose: By applying the principles of real-time biopsy, biomarker-based, adaptively randomized studies in non-small-cell lung cancer (NSCLC) established by the Biomarker-Integrated Approaches of Targeted Therapy for Lung Cancer Elimination (BATTLE) trial, we conducted BATTLE-2 (BATTLE-2 Program: A Biomarker-Integrated Targeted Therapy Study in Previously Treated Patients With Advanced Non-Small Cell Lung Cancer), an umbrella study to evaluate the effects of targeted therapies focusing on KRAS-mutated cancers. Patients and Methods: Patients with advanced NSCLC (excluding sensitizing EGFR mutations and ALK gene fusions) refractory to more than one prior therapy were randomly assigned, stratified by KRAS status, to four arms: (1) erlotinib, (2) erlotinib plus MK-2206, (3) MK-2206 plus AZD6244, or (4) sorafenib. Tumor gene expression profiling-targeted next-generation sequencing was performed to evaluate predictive and prognostic biomarkers. Results: Two hundred patients, 27{\%} with KRAS-mutated (KRAS mut+) tumors, were adaptively randomly assigned to erlotinib (n = 22), erlotinib plus MK-2206 (n = 42), MK-2206 plus AZD6244 (n = 75), or sorafenib(n =61). Inall, 186 patients were evaluable, and the primary end point of an 8-week disease control rate (DCR) was 48{\%} (arm1,32{\%}; arm 2,50{\%}; arm3,53{\%}; and arm4,46{\%}). For KRAS mut+ patients, DCR was 20{\%}, 25{\%}, 62{\%}, and 44{\%} whereas for KRAS wild-type patients, DCR was 36{\%}, 57{\%}, 49{\%}, and 47{\%} for arms 1, 2, 3, and 4, respectively. Median progression-free survival was 2.0 months, not different by KRAS status, 1.8 months for arm 1, and 2.5 months for arms 2 versus arms 3 and 4 in KRAS mut+ patients (P =.04). Median overall survival was 6.5 months, 9.0 and 5.1 months for arms 1 and 2 versus arms 3 and 4 in KRAS wild-type patients (P =.03). Median overall survival was 7.5 months in mesenchymal versus 5 months in epithelial tumors (P =.02). Conclusion: Despite improved progression-free survival on therapy that did not contain erlotinib for KRAS mut+ patients and improved prognosis for mesenchymal tumors, better biomarker-driven treatment strategies are still needed.},
author = {Papadimitrakopoulou, Vassiliki and {Jack Lee}, J. and Wistuba, Ignacio I. and Tsao, Anne S. and Fossella, Frank V. and Kalhor, Neda and Gupta, Sanjay and Byers, Lauren Averett and Izzo, Julie G. and Gettinger, Scott N. and Goldberg, Sarah B. and Tang, Ximing and Miller, Vincent A. and Skoulidis, Ferdinandos and Gibbons, Don L. and Shen, Li and Wei, Caimiao and Diao, Lixia and {Andrew Peng}, S. and Wang, Jing and Tam, Alda L. and Coombes, Kevin R. and Koo, Ja Seok and Mauro, David J. and Rubin, Eric H. and Heymach, John V. and Hong, Waun Ki and Herbst, Roy S.},
doi = {10.1200/JCO.2015.66.0084},
file = {::},
issn = {15277755},
journal = {Journal of Clinical Oncology},
number = {30},
pages = {3638--3647},
pmid = {27480147},
title = {{The BATTLE-2 study: A biomarker-integrated targeted therapy study in previously treated patients with advanced non-small-cell lung cancer}},
volume = {34},
year = {2016}
}
@article{Falk1970,
abstract = {This book shows engineers how to use optimization theory to solve complex problems. Unifies the large field of optimization with a few geometric principles.},
author = {Falk, James E.},
doi = {10.1137/1012072},
issn = {0036-1445},
journal = {SIAM Review},
number = {2},
pages = {315--316},
title = {{Optimization by Vector Space Methods (David G. Luenberger)}},
volume = {12},
year = {1970}
}
@article{Lambert:2012br,
author = {Lambert, C G and Black, L J},
journal = {Biostatistics (Oxford, England)},
month = {mar},
number = {2},
pages = {195--203},
title = {{Learning from our GWAS mistakes: from experimental design to scientific method}},
volume = {13},
year = {2012}
}
@article{Biswas2016,
abstract = {Genetic risk prediction models such as BRCAPRO are used routinely in genetic counseling for identification of potential BRCA1 and BRCA2 mutation carriers. They require extensive information on the counselee and her family history, and thus are not practical for primary care. To address this gap, we develop and test a two-stage approach to genetic risk assessment by balancing the tradeoff between the amount of information used and accuracy achieved. The first stage is intended for primary care wherein limited information is collected and analyzed using a simplified version of BRCAPRO. If the assessed risk is sufficiently high, more extensive information is collected and the full BRCAPRO is used (stage two: intended for genetic counseling). We consider three first-stage tools: BRCAPROLYTE, BRCAPROLYTE-Plus, and BRCAPROLYTE-Simple. We evaluate the two-stage approach on independent clinical data on probands with family history of breast and ovarian cancers, and BRCA genetic test results. These include population-based data on 1344 probands from Newton-Wellesley Hospital and mostly high-risk family data on 2713 probands from Cancer Genetics Network and MD Anderson Cancer Center. We use discrimination and calibration measures, appropriately modified to evaluate the overall performance of a two-stage approach. We find that the proposed two-stage approach has very limited loss of discrimination and comparable calibration as BRCAPRO. It identifies a similar number of carriers without requiring a full family history evaluation on all probands. We conclude that the two-stage approach allows for practical large-scale genetic risk assessment in primary care.},
author = {Biswas, Swati and Atienza, Philamer and Chipman, Jonathan and Blackford, Amanda L and Arun, Banu and Hughes, Kevin and Parmigiani, Giovanni},
doi = {10.1007/s10549-016-3686-2},
issn = {1573-7217 (Electronic)},
journal = {Breast cancer research and treatment},
keywords = {BRCA1 Protein,BRCA2 Protein,Breast Neoplasms,Female,Genetic Counseling,Genetic Predisposition to Disease,Humans,Male,Middle Aged,Mutation,Ovarian Neoplasms,Pedigree,Primary Health Care,Retrospective Studies,Risk Assessment,Risk Factors,genetics,methods},
language = {eng},
month = {jan},
number = {2},
pages = {375--383},
pmid = {26786860},
title = {{A two-stage approach to genetic risk assessment in primary care.}},
volume = {155},
year = {2016}
}
@article{Baker:2014io,
author = {Baker, Stuart G and Schuit, Ewoud and Steyerberg, Ewout W and Pencina, Michael J and Vickers, Andew and Moons, Karel G M and Mol, Ben W J and Lindeman, Karen S},
journal = {Statistics in Medicine},
month = {may},
number = {22},
pages = {3946--3959},
title = {{How to interpret a small increase in AUC with an additional risk prediction marker: decision analysis comes through}},
volume = {33},
year = {2014}
}
@article{Omura2006,
author = {Omura, George A.},
doi = {10.1158/1078-0432.CCR-05-1762},
file = {::},
issn = {10780432},
journal = {Clinical Cancer Research},
number = {1},
pages = {321},
pmid = {16397058},
title = {{Phase 1 dose-finding trials and fibonacci}},
volume = {12},
year = {2006}
}
@article{Wennemann:2011ea,
author = {Wennemann, R and Bouanane, M and Liebeton, J and S{\"{u}}rmeci, G and Trappe, H},
journal = {Ultrasound in Medicine {\&} Biology},
month = {aug},
number = {8},
pages = {S160},
title = {{Incidence of Patients with Deep Vein Thrombosis and Pulmonary Embolism in Elevated D-Dimer Levels}},
volume = {37},
year = {2011}
}
@article{Kahan:2011iz,
author = {Kahan, Brennan C and Morris, Tim P},
journal = {Statistics in medicine},
month = {dec},
number = {4},
pages = {328--340},
title = {{Improper analysis of trials randomised using stratified blocks or minimisation}},
volume = {31},
year = {2011}
}
@article{Abadie2020,
abstract = {Consider a researcher estimating the parameters of a regression function based on data for all 50 states in the United States or on data for all visits to a website. What is the interpretation of the estimated parameters and the standard errors? In practice, researchers typically assume that the sample is randomly drawn from a large population of interest and report standard errors that are designed to capture sampling variation. This is common even in applications where it is difficult to articulate what that population of interest is, and how it differs from the sample. In this article, we explore an alternative approach to inference, which is partly design‐based. In a design‐based setting, the values of some of the regressors can be manipulated, perhaps through a policy intervention. Design‐based uncertainty emanates from lack of knowledge about the values that the regression outcome would have taken under alternative interventions. We derive standard errors that account for design‐based uncertainty instead of, or in addition to, sampling‐based uncertainty. We show that our standard errors in general are smaller than the usual infinite‐population sampling‐based standard errors and provide conditions under which they coincide.},
author = {Abadie, Alberto and Athey, Susan and Imbens, Guido W. and Wooldridge, Jeffrey M.},
doi = {10.3982/ecta12675},
file = {::},
issn = {0012-9682},
journal = {Econometrica},
number = {1},
pages = {265--296},
title = {{Sampling‐Based versus Design‐Based Uncertainty in Regression Analysis}},
volume = {88},
year = {2020}
}
@article{Lopiano:2014ff,
author = {Lopiano, Kenneth K and Obenchain, Robert L and Young, S Stanley},
journal = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
month = {aug},
number = {5},
pages = {376--384},
title = {{Fair treatment comparisons in observational research}},
volume = {7},
year = {2014}
}
@article{Anonymous:6jLA-dfo,
annote = {In code: SCRSSN: Scrambled social security number (at a national level) Hypoglycemia},
title = {{No Title}}
}
@article{Zhao2021,
abstract = {Fisher's randomization test (FRT) delivers exact p-values under the strong null hypothesis of no treatment effect on any units whatsoever and allows for flexible covariate adjustment to improve the power. Of interest is whether the resulting covariate-adjusted procedure could also be valid for testing the weak null hypothesis of zero average treatment effect. To this end, we evaluate two general strategies for conducting covariate adjustment in FRTs: the pseudo-outcome strategy that uses the residuals from an outcome model with only the covariates as the pseudo, covariate-adjusted outcomes to form the test statistic, and the model-output strategy that directly uses the output from an outcome model with both the treatment and covariates as the covariate-adjusted test statistic. Based on theory and simulation, we recommend using the ordinary least squares (OLS) fit of the observed outcome on the treatment, centered covariates, and their interactions for covariate adjustment, and conducting FRT with the robust t-value of the treatment as the test statistic. The resulting FRT is finite-sample exact for testing the strong null hypothesis, asymptotically valid for testing the weak null hypothesis, and more powerful than the unadjusted counterpart under alternatives, all irrespective of whether the linear model is correctly specified or not. We start with complete randomization, and then extend the theory to cluster randomization, stratified randomization, and rerandomization, respectively, giving a recommendation for the test procedure and test statistic under each design. Our theory is design-based, also known as randomization-based, in which we condition on the potential outcomes but average over the random treatment assignment.},
archivePrefix = {arXiv},
arxivId = {2010.14555},
author = {Zhao, Anqi and Ding, Peng},
doi = {10.1016/j.jeconom.2021.04.007},
eprint = {2010.14555},
file = {::},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Finite-population inference,Permutation test,Randomization distribution,Robust standard error,Studentization,Super-population inference},
number = {2},
pages = {278--294},
publisher = {Elsevier B.V.},
title = {{Covariate-adjusted Fisher randomization tests for the average treatment effect}},
url = {https://doi.org/10.1016/j.jeconom.2021.04.007},
volume = {225},
year = {2021}
}
@article{Kang2018,
abstract = {The method of instrumental variables provides a framework to study causal effects in both randomized experiments with non-compliance and in observational studies where natural circumstances produce as if random nudges to accept treatment. Traditionally, inference for instrumental variables relied on asymptotic approximations of the distribution of the Wald estimator or two-stage least squares, often with structural modelling assumptions and/or moment conditions. We utilize the randomization inference approach to instrumental variables inference. First, we outline the exact method, which uses the randomized assignment of treatment in experiments as a basis for inference but lacks a closed form solution and may be computationally infeasible in many applications. We then provide an alternative to the exact method, the almost exact method, which is computationally feasible but retains the advantages of the exact method. We also review asymptotic methods of inference, including those associated with two-stage least squares, and analytically compare them with randomization inference methods. We also perform additional comparisons by using a set of simulations. We conclude with three different applications from the social sciences.},
archivePrefix = {arXiv},
arxivId = {1606.04146},
author = {Kang, Hyunseung and Peck, Laura and Keele, Luke},
doi = {10.1111/rssa.12353},
eprint = {1606.04146},
issn = {1467985X},
journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
keywords = {Effect ratio,Exclusion restriction,Instrumental variables,Randomization inference,Weak instrument},
number = {4},
pages = {1231--1254},
title = {{Inference for instrumental variables: a randomization inference approach}},
volume = {181},
year = {2018}
}
@article{Moons:2012gp,
author = {Moons, K G M and de Groot, J A H and Linnet, K and Reitsma, J B and Bossuyt, P M M},
journal = {Clinical chemistry},
month = {sep},
number = {10},
pages = {1408--1417},
title = {{Quantifying the Added Value of a Diagnostic Test or Marker}},
volume = {58},
year = {2012}
}
@incollection{Chang:2016vy,
address = {Hoboken, NJ, USA},
author = {Chang, Mark},
booktitle = {Classical and Adaptive Clinical Trial Designs using Expdesign Studio{\{}$\backslash$texttrademark{\}}},
month = {jul},
pages = {187--213},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Classical Design Method Reference}},
year = {2008}
}
@article{Balaguer:2008je,
author = {Balaguer, Francesc and Balma{\~{n}}a, Judith and Castellv$\backslash$'$\backslash$i-Bel, Sergi and Steyerberg, Ewout W and Andreu, Montserrat and Llor, Xavier and Jover, Rodrigo and Syngal, Sapna and Castells, Antoni},
journal = {Gastroenterology},
month = {jan},
number = {1},
pages = {39--46},
title = {{Validation and Extension of the PREMM1,2 Model in a Population-Based Cohort of Colorectal Cancer Patients}},
volume = {134},
year = {2008}
}
@article{Mandel:2013fh,
author = {Mandel, Micha and Mercier, Francois and Eckert, Benjamin and Chin, Peter and Betensky, Rebecca A},
journal = {Biometrics},
month = {feb},
number = {1},
pages = {225--234},
title = {{Estimating Time to Disease Progression Comparing Transition Models and Survival Methods-An Analysis of Multiple Sclerosis Data}},
volume = {69},
year = {2013}
}
@article{chang2023covariate,
author = {Chang, Chia-Rui and Song, Yue and Li, Fan and Wang, Rui},
journal = {Statistics in Medicine},
number = {22},
pages = {3919--3935},
publisher = {Wiley Online Library},
title = {{Covariate adjustment in randomized clinical trials with missing covariate and outcome data}},
volume = {42},
year = {2023}
}
@article{nelson2016development,
author = {Nelson, Lyndsay A and Mayberry, Lindsay S and Wallston, Kenneth and Kripalani, Sunil and Bergner, Erin M and Osborn, Chandra Y},
journal = {JMIR human factors},
number = {2},
pages = {e23},
publisher = {JMIR Publications Inc., Toronto, Canada},
title = {{Development and usability of REACH: a tailored theory-based text messaging intervention for disadvantaged adults with type 2 diabetes}},
volume = {3},
year = {2016}
}
@article{Demler:2013iw,
author = {Demler, Olga V and Pencina, Michael J and {D'Agostino Sr.}, Ralph B},
journal = {Statistics in medicine},
month = {may},
number = {24},
pages = {4196--4210},
title = {{Impact of correlation on predictive ability of biomarkers}},
volume = {32},
year = {2013}
}
@article{Anonymous:v6nVvp3G,
month = {may},
pages = {1--8},
title = {{Rosenbaum Rubin 1983 Biometrika}},
year = {2010}
}
@article{Blume2002,
abstract = {Focused on interpreting data as statistical evidence, the evidential paradigm uses likelihood ratios to measure the strength of statistical evidence. Under this paradigm, re-examination of accumulating evidence is encouraged because (i) the likelihood ratio, unlike a p-value, is unaffected by the number of examinations and (ii) the probability of observing strong misleading evidence is naturally low, even for study designs that re-examine the data with each new observation. Further, the controllable probabilities of observing misleading and weak evidence provide assurance that the study design is reliable without affecting the strength of statistical evidence in the data. This paper illustrates the ideas and methods associated with using likelihood ratios to measure statistical evidence. It contains a comprehensive introduction to the evidential paradigm, including an overview of how to quantify the probability of observing misleading evidence for various study designs. The University Group Diabetes Program (UGDP), a classic and still controversial multi-centred clinical trial, is used as an illustrative example. Some of the original UGDP results, and subsequent re-analyses, are presented for comparison purposes. Copyright {\textcopyright} 2002 John Wiley $\backslash${\&} Sons, Ltd.},
author = {Blume, Jeffrey D.},
doi = {10.1002/sim.1216},
file = {::},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Bump function,Law of likelihood,Misleading evidence,Statistical evidence,Tepee function,University Group Diabetes Program (UGDP)},
number = {17},
pages = {2563--2599},
pmid = {12205699},
title = {{Likelihood methods for measuring statistical evidence}},
volume = {21},
year = {2002}
}
@article{koyama2008,
abstract = {Simon's two-stage designs are very popular for phase II clinical trials. A literature review revealed that the inference procedures used with Simon's designs almost always ignore the actual sampling plan used. Reported P-values, point estimates and confidence intervals for the response rate are not usually adjusted for the design's adaptiveness. In addition, we found that the actual sample size for the second stage is often different from that planned. We present here a method for inferences using both the planned and the actual sample sizes. The conventional and the preferred inference procedures usually yield similar P-values and confidence intervals for the response rate. The conventional inference, however, may contradict the result of the corresponding hypothesis testing.},
author = {Koyama, Tatsuki and Chen, Heidi},
doi = {10.1002/sim},
file = {::},
journal = {Statistics in medicine},
pages = {3145--3154},
title = {{Proper inference from Simon's two-stage designs}},
volume = {27},
year = {2008}
}
@article{Uno:2012jc,
author = {Uno, Hajime and Tian, Lu and Cai, Tianxi and Kohane, Isaac S and Wei, L J},
journal = {Statistics in medicine},
month = {oct},
number = {14},
pages = {2430--2442},
title = {{A unified inference procedure for a class of measures to assess improvement in risk prediction systems with survival data}},
volume = {32},
year = {2012}
}
@article{Anonymous:4IawlKwW,
month = {nov},
pages = {1--8},
title = {{CONFLICT-INTEREST}},
year = {2018}
}
@article{Roumie:2014bc,
author = {Roumie, Christianne L and Greevy, Robert A and Grijalva, Carlos G and Hung, Adriana M and Liu, Xulei and Murff, Harvey J and Elasy, Tom A and Griffin, Marie R},
journal = {JAMA},
month = {jun},
number = {22},
pages = {2288},
title = {{Association Between Intensification of Metformin Treatment With Insulin vs Sulfonylureas and Cardiovascular Events and All-Cause Mortality Among Patients With Diabetes}},
volume = {311},
year = {2014}
}
@article{Quigley:2002ew,
author = {Quigley, Charmian A and Crowe, Brenda J and Anglin, D Greg and Chipman, John J},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {may},
number = {5},
pages = {2033--2041},
title = {{Growth Hormone and Low Dose Estrogen in Turner Syndrome: Results of a United States Multi-Center Trial to Near-Final Height}},
volume = {87},
year = {2002}
}
@article{schulz2002allocation,
author = {Schulz, Kenneth F and Grimes, David A},
journal = {The Lancet},
number = {9306},
pages = {614--618},
publisher = {Elsevier},
title = {{Allocation concealment in randomised trials: defending against deciphering}},
volume = {359},
year = {2002}
}
@article{Akacha2017,
abstract = {Defining the scientific questions of interest in a clinical trial is crucial to align its planning, design, conduct, analysis, and interpretation. However, practical experience shows that oftentimes specific choices in the statistical analysis blur the scientific question either in part or even completely, resulting in misalignment between trial objectives, conduct, analysis, and confusion in interpretation. The need for more clarity was highlighted by the Steering Committee of the International Council for Harmonization (ICH) in 2014, which endorsed a Concept Paper with the goal of developing a new regulatory guidance, suggested to be an addendum to ICH guideline E9. Triggered by these developments, we elaborate in this paper what the relevant questions in drug development are and how they fit with the current practice of intention-to-treat analyses. To this end, we consider the perspectives of patients, physicians, regulators, and payers. We argue that despite the different backgrounds and motivations of the various stakeholders, they all have similar interests in what the clinical trial estimands should be. Broadly, these can be classified into estimands addressing (a) lack of adherence to treatment due to different reasons and (b) efficacy and safety profiles when patients, in fact, are able to adhere to the treatment for its intended duration. We conclude that disentangling adherence to treatment and the efficacy and safety of treatment in patients that adhere leads to a transparent and clinical meaningful assessment of treatment risks and benefits. We touch upon statistical considerations and offer a discussion of additional implications. Copyright {\textcopyright} 2016 John Wiley $\backslash${\&} Sons, Ltd.},
author = {Akacha, Mouna and Bretz, Frank and Ruberg, Stephen},
doi = {10.1002/sim.7033},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {adherence,causal inference,effectiveness,efficacy,estimand,intention-to-treat,treatment-policy},
number = {1},
pages = {5--19},
pmid = {27435045},
title = {{Estimands in clinical trials – broadening the perspective}},
volume = {36},
year = {2017}
}
@article{yates1982external,
author = {Yates, J Frank},
journal = {Organizational Behavior and Human Performance},
number = {1},
pages = {132--156},
publisher = {Elsevier},
title = {{External correspondence: Decompositions of the mean probability score}},
volume = {30},
year = {1982}
}
@article{Senn:1994vy,
author = {Senn, S},
journal = {Statistics in medicine},
month = {feb},
number = {3},
pages = {217--230},
title = {{Fisher's game with the devil.}},
volume = {13},
year = {1994}
}
@article{Dhanasekaran:2001iw,
author = {Dhanasekaran, Saravana M and Barrette, Terrence R and Ghosh, Debashis and Shah, Rajal and Varambally, Sooryanarayana and Kurachi, Kotoku and Pienta, Kenneth J and Rubin, Mark A and Chinnaiyan, Arul M},
journal = {Nature},
month = {aug},
number = {6849},
pages = {822--826},
title = {{Delineation of prognostic biomarkers in prostate cancer}},
volume = {412},
year = {2001}
}
@article{saville2022bayesian,
author = {Saville, Benjamin R and Berry, Donald A and Berry, Nicholas S and Viele, Kert and Berry, Scott M},
file = {::},
journal = {Clinical Trials},
number = {5},
pages = {490--501},
publisher = {SAGE Publications Sage UK: London, England},
title = {{The bayesian time machine: Accounting for temporal drift in multi-arm platform trials}},
volume = {19},
year = {2022}
}
@article{Zuo2021,
abstract = {Many statistical methods have been proposed for variable selection in the past century, but few balance inference and prediction tasks well. Here, we report on a novel variable selection approach called penalized regression with second-generation p-values (ProSGPV). It captures the true model at the best rate achieved by current standards, is easy to implement in practice, and often yields the smallest parameter estimation error. The idea is to use an (Formula presented.) penalization scheme with second-generation p-values (SGPV), instead of traditional ones, to determine which variables remain in a model. The approach yields tangible advantages for balancing support recovery, parameter estimation, and prediction tasks. The ProSGPV algorithm can maintain its good performance even when there is strong collinearity among features or when a high-dimensional feature space with p {\textgreater} n is considered. We present extensive simulations and a real-world application comparing the ProSGPV approach with smoothly clipped absolute deviation (SCAD), adaptive lasso (AL), and minimax concave penalty with penalized linear unbiased selection (MC+). While the last three algorithms are among the current standards for variable selection, ProSGPV has superior inference performance and comparable prediction performance in certain scenarios.},
author = {Zuo, Yi and Stewart, Thomas G. and Blume, Jeffrey D.},
doi = {10.1080/00031305.2021.1946150},
issn = {15372731},
journal = {American Statistician},
keywords = {Lasso,Penalized regression,Second-generation p-values,Variable selection},
title = {{Variable Selection With Second-Generation P-Values}},
year = {2021}
}
@article{meinert2012clinicaltrials,
author = {Chaplin, Caroline},
journal = {Statistics in medicine},
month = {apr},
number = {4},
pages = {545},
title = {{Clinical trials: Design, conduct and analysis, Curtis L. Meinert, Oxford University Press, 1986. No. of pages xxvi + 469. price: {\pounds}50.00}},
volume = {7},
year = {1988}
}
@article{kruschke2018newcomers,
abstract = {This article explains the foundational concepts of Bayesian data analysis using virtually no mathematical notation. Bayesian ideas already match your intuitions from everyday reasoning and from traditional data analysis. Simple examples of Bayesian data analysis are presented that illustrate how the information delivered by a Bayesian analysis can be directly interpreted. Bayesian approaches to null-value assessment are discussed. The article clarifies misconceptions about Bayesian methods that newcomers might have acquired elsewhere. We discuss prior distributions and explain how they are not a liability but an important asset. We discuss the relation of Bayesian data analysis to Bayesian models of mind, and we briefly discuss what methodological problems Bayesian data analysis is not meant to solve. After you have read this article, you should have a clear sense of how Bayesian data analysis works and the sort of information it delivers, and why that information is so intuitive and useful for drawing conclusions from data.},
author = {Kruschke, John K. and Liddell, Torrin M.},
doi = {10.3758/s13423-017-1272-1},
issn = {15315320},
journal = {Psychonomic Bulletin and Review},
keywords = {Bayes factor,Bayesian analysis,Bayesian model,Confidence interval,Highest density interval,Null hypothesis significance test,Region of practical equivalence,Replication crisis,p value},
number = {1},
pages = {155--177},
pmid = {28405907},
publisher = {Psychonomic Bulletin {\&} Review},
title = {{Bayesian data analysis for newcomers}},
volume = {25},
year = {2018}
}
@article{chipman2022sequential,
author = {Chipman, Jonathan J and {Greevy Jr}, Robert A and Mayberry, Lindsay and Blume, Jeffrey D},
journal = {arXiv preprint arXiv:2204.10678},
title = {{Sequential monitoring using the Second Generation P-Value with Type I error controlled by monitoring frequency}},
year = {2022}
}
@article{Begg:1980bp,
author = {Begg, Colin B and Iglewicz, Boris},
journal = {Biometrics},
month = {mar},
number = {1},
pages = {81},
title = {{A Treatment Allocation Procedure for Sequential Clinical Trials}},
volume = {36},
year = {1980}
}
@article{Journal2023,
author = {Journal, Source and Statistical, Royal and Series, Society and Statistics, C Applied},
file = {::},
number = {4},
pages = {585--601},
title = {{Two-stage marker-stratified clinical trial design in the presence of biomarker misclassification Author ( s ): Yong Zang , J . Jack Lee and Ying Yuan Published by : Wiley for the Royal Statistical Society Stable URL : https://www.jstor.org/stable/24773041}},
volume = {65},
year = {2023}
}
@article{Proschan:2011jv,
author = {Proschan, Michael and Brittain, Erica and Kammerman, Lisa},
journal = {Biometrics},
month = {sep},
number = {3},
pages = {1135--1141},
title = {{Minimize the Use of Minimization with Unequal Allocation}},
volume = {67},
year = {2011}
}
@article{christ2017advanced,
author = {Christ, Oliver and Hewstone, Miles and Schmid, Katharina and Green, Eva G T and Sarrasin, Oriane and Gollwitzer, Mario and Wagner, Ulrich},
file = {::},
journal = {Group Dynamics: Theory, Research, and Practice},
number = {3},
pages = {121},
publisher = {Educational Publishing Foundation},
title = {{Advanced multilevel modeling for a science of groups: A short primer on multilevel structural equation modeling.}},
volume = {21},
year = {2017}
}
@techreport{Anonymous:uMAM8s4J,
month = {dec},
title = {{Microsoft Word - 9.doc}},
year = {2009}
}
@book{rosenberger2015randomization,
author = {Rosenberger, William F and Lachin, John M},
publisher = {John Wiley {\&} Sons},
title = {{Randomization in clinical trials: theory and practice}},
year = {2015}
}
@article{Pocock:2016ca,
author = {Pocock, Stuart J and Stone, Gregg W},
journal = {New England Journal of Medicine},
month = {sep},
number = {10},
pages = {971--979},
title = {{The Primary Outcome Is Positive - Is That Good Enough?}},
volume = {375},
year = {2016}
}
@article{Scott:2007vq,
author = {Scott, W F},
journal = {Mathematical Scientist},
title = {{A SIMPLE OPTIMISATION METHOD FOR CLINICAL TRIALS.}},
year = {2007}
}
@article{Leschek:2004wb,
author = {Leschek, Ellen Werber and Rose, Susan R and Yanovski, Jack A and Troendle, James F and Quigley, Charmian A and Chipman, John J and Crowe, Brenda J and Ross, Judith L and Cassorla, Fernando G and Blum, Werner F and {Cutler Jr.}, Gordon B and Baron, Jeffrey},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {jul},
number = {7},
pages = {3140--3148},
title = {{Effect of Growth Hormone Treatment on Adult Height in Peripubertal Children with Idiopathic Short Stature: A Randomized, Double-Blind, Placebo-Controlled Trial}},
volume = {89},
year = {2004}
}
@article{Pocock:2003ts,
author = {Pocock, Stuart J},
journal = {Fundamental and Clinical Pharmacology},
month = {aug},
number = {4},
pages = {483--490},
title = {{The pros and cons of noninferiority trials}},
volume = {17},
year = {2003}
}
@article{Ma:2015id,
author = {Ma, Wei and Hu, Feifang and Zhang, Lixin},
journal = {Journal of the American Statistical Association},
month = {jul},
number = {510},
pages = {669--680},
title = {{Testing Hypotheses of Covariate-Adaptive Randomized Clinical Trials}},
volume = {110},
year = {2015}
}
@article{Kallus:2018um,
author = {B, N Kallus Journal of the Royal Statistical Society Series and 2018},
file = {::},
journal = {Journal of the Royal Statistical Society Series B},
pages = {85--112},
title = {{Optimal a priori balance in the design of controlled experiments}},
volume = {80},
year = {2018}
}
@article{VanCalster:2017dn,
author = {{Van Calster}, Ben and {Van Hoorde}, Kirsten and Vergouwe, Yvonne and Bobdiwala, Shabnam and Condous, George and Kirk, Emma and Bourne, Tom and Steyerberg, Ewout W},
journal = {Diagnostic and Prognostic Research},
month = {feb},
number = {1},
pages = {453},
title = {{Validation and updating of risk models based on multinomial logistic regression}},
volume = {1},
year = {2017}
}
@article{Calverley:2007gx,
author = {Calverley, Peter M A and Anderson, Julie A and Celli, Bartolome and Ferguson, Gary T and Jenkins, Christine and Jones, Paul W and Yates, Julie C and Vestbo, J{\o}rgen and TORCH investigators},
journal = {New England Journal of Medicine},
month = {feb},
number = {8},
pages = {775--789},
title = {{Salmeterol and fluticasone propionate and survival in chronic obstructive pulmonary disease}},
volume = {356},
year = {2007}
}
@article{Hoppe2014,
abstract = {BACKGROUND: Data continue to emerge on the relative merits of different treatment modalities for prostate cancer. The objective of this study was to compare patient-reported quality-of-life (QOL) outcomes after proton therapy (PT) and intensity-modulated radiation therapy (IMRT) for prostate cancer. METHODS: A comparison was performed of prospectively collected QOL data using the Expanded Prostate Cancer Index Composite (EPIC) questionnaire. QOL data were collected during the first 2 years after treatment for men who received PT and IMRT. PT was delivered to 1243 men at a single center at doses from 76 grays (Gy) to 82 Gy. IMRT was delivered to 204 men who were included in the Prostate Cancer Outcomes and Satisfaction with Treatment Quality Assessment (PROSTQA) study in doses from 75.6 Gy to 79.4 Gy. The Wilcoxon rank-sum test was used to compare EPIC outcomes by modality using baseline-adjusted scores at different time points. Individual questions were assessed by converting to binary outcomes and testing with generalized estimating equations. RESULTS: No differences were observed in summary score changes for bowel, urinary incontinence, urinary irritative/obstructive, and sexual domains between the 2 cohorts. However, more men who received IMRT reported moderate/big problems with rectal urgency (P = 0.02) and frequent bowel movements (P = 0.05) than men who received PT. CONCLUSIONS: There were no differences in QOL summary scores between the IMRT and PT cohorts during early follow-up (up to 2-years). Response to individual questions suggests possible differences in specific bowel symptoms between the 2 cohorts. These outcomes highlight the need for further comparative studies of PT and IMRT.},
author = {Hoppe, Bradford S and Michalski, Jeff M and Mendenhall, Nancy P and Morris, Christopher G and Henderson, Randal H and Nichols, Romaine C and Mendenhall, William M and Williams, Christopher R and Regan, Meredith M and Chipman, Jonathan J and Crociani, Catrina M and Sandler, Howard M and Sanda, Martin G and Hamstra, Daniel A},
doi = {10.1002/cncr.28536},
issn = {1097-0142 (Electronic)},
journal = {Cancer},
keywords = {Aged,Aged, 80 and over,Cohort Studies,Comparative Effectiveness Research,Humans,Male,Middle Aged,Patient Outcome Assessment,Patient Satisfaction,Prostatic Neoplasms,Proton Therapy,Quality of Life,Radiotherapy, Intensity-Modulated,Surveys and Questionnaires,Treatment Outcome,radiotherapy},
language = {eng},
month = {apr},
number = {7},
pages = {1076--1082},
pmid = {24382757},
title = {{Comparative effectiveness study of patient-reported outcomes after proton therapy or intensity-modulated radiotherapy for prostate cancer.}},
volume = {120},
year = {2014}
}
@article{Hu2023,
author = {Hu, Feifang and Ye, Xiaoqing and Zhang, Li-xin},
file = {::},
keywords = {balancing covariate,clinical trial,hu,hu and,marginal balance,markov chain,multiple treatment,pocock and simon,s general procedure,s procedure,stratified permuted block design},
number = {1},
pages = {163--190},
title = {{Multi-arm covariate-adaptive randomization}},
volume = {66},
year = {2023}
}
@article{W.J.Dixon1948,
author = {{W.J. Dixon}, A.M. Mood},
file = {::},
journal = {Journal of the American Statistical Association},
number = {241},
pages = {109--126},
title = {{A Method for Obtaining and Analyzing Sensitivity Data Author ( s ): W . J . Dixon and A . M . Mood Source : Journal of the American Statistical Association , Vol . 43 , No . 241 ( Mar ., 1948 ), pp . Published by : Taylor {\&} Francis , Ltd . on behalf of th}},
volume = {43},
year = {1948}
}
@article{Kass1995,
abstract = {In a 1935 paper and in his book Theory of Probability, Jeffreys developed a methodology for quantifying the evidence in favor of a scientific theory. The centerpiece was a number, now called the Bayes factor, which is the posterior odds of the null hypothesis when the prior probability on the null is one-half. Although there has been much discussion of Bayesian hypothesis testing in the context of criticism of P-values, less attention has been given to the Bayes factor as a practical tool of applied statistics. In this article we review and discuss the uses of Bayes factors in the context of five scientific applications in genetics, sports, ecology, sociology, and psychology. We emphasize the following points: • From Jeffreys' Bayesian viewpoint, the purpose of hypothesis testing is to evaluate the evidence in favor of a scientific theory. • Bayes factors offer a way of evaluating evidence in favor of a null hypothesis. • Bayes factors provide a way of incorporating external information into the evaluation of evidence about a hypothesis. • Bayes factors are very general and do not require alternative models to be nested. • Several techniques are available for computing Bayes factors, including asymptotic approximations that are easy to compute using the output from standard packages that maximize likelihoods. • In “nonstandard” statistical models that do not satisfy common regularity conditions, it can be technically simpler to calculate Bayes factors than to derive non-Bayesian significance tests. • The Schwarz criterion (or BIC) gives a rough approximation to the logarithm of the Bayes factor, which is easy to use and does not require evaluation of prior distributions. • When one is interested in estimation or prediction, Bayes factors may be converted to weights to be attached to various models so that a composite estimate or prediction may be obtained that takes account of structural or model uncertainty. • Algorithms have been proposed that allow model uncertainty to be taken into account when the class of models initially considered is very large. • Bayes factors are useful for guiding an evolutionary model-building process. • It is important, and feasible, to assess the sensitivity of conclusions to the prior distributions used. {\textcopyright} 1995 Taylor {\&} Francis Group, LLC.},
author = {Kass, Robert E. and Raftery, Adrian E.},
doi = {10.1080/01621459.1995.10476572},
file = {::},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {BIC,Bayesian hypothesis tests,Importance sampling,Laplace method,Markov chain Monte Carlo,Model selection,Monte Carlo integration,Posterior model probabilities,Posterior odds,Quadrature,Schwarz criterion,Sensitivity analysis,Strength of evidence},
number = {430},
pages = {773--795},
title = {{Bayes factors}},
volume = {90},
year = {1995}
}
@article{Snyder:2007jg,
author = {Snyder, Peter J and Biller, Beverly M K and Zagar, Anthony and Jackson, Ivor and Arafah, Baha M and Nippoldt, Todd B and Cook, David M and Mooradian, Arshag D and Kwan, Anita and Scism-Bacon, Jamie and Chipman, John J and Hartman, Mark L},
journal = {Journal of Bone and Mineral Research},
month = {feb},
number = {5},
pages = {762--770},
title = {{Effect of Growth Hormone Replacement on BMD in Adult-Onset Growth Hormone Deficiency}},
volume = {22},
year = {2007}
}
@article{harris2019redcap,
author = {Harris, Paul A and Taylor, Robert and Minor, Brenda L and Elliott, Veida and Fernandez, Michelle and O'Neal, Lindsay and McLeod, Laura and Delacqua, Giovanni and Delacqua, Francesco and Kirby, Jacqueline and Others},
journal = {Journal of biomedical informatics},
pages = {103208},
publisher = {Elsevier},
title = {{The REDCap consortium: Building an international community of software platform partners}},
volume = {95},
year = {2019}
}
@article{Chipman2017,
abstract = {The integrated discrimination improvement (IDI) is commonly used to compare two risk prediction models; it summarizes the extent a new model increases risk in events and decreases risk in non-events. The IDI averages risks across events and non-events and is therefore susceptible to Simpson's paradox. In some settings, adding a predictive covariate to a well calibrated model results in an overall negative (positive) IDI. However, if stratified by that same covariate, the strata-specific IDIs are positive (negative). Meanwhile, the calibration (observed to expected ratio and Hosmer–Lemeshow Goodness of Fit Test), area under the receiver operating characteristic curve, and Brier score improve overall and by stratum. We ran extensive simulations to investigate the impact of an imbalanced covariate upon metrics (IDI, area under the receiver operating characteristic curve, Brier score, and R2), provide an analytic explanation for the paradox in the IDI, and use an investigative metric, a Weighted IDI, to better understand the paradox. In simulations, all instances of the paradox occurred under stratum-specific mis-calibration, yet there were mis-calibrated settings in which the paradox did not occur. The paradox is illustrated on Cancer Genomics Network data by calculating predictions based on two versions of BRCAPRO, a Mendelian risk prediction model for breast and ovarian cancer. In both simulations and the Cancer Genomics Network data, overall model calibration did not guarantee stratum-level calibration. We conclude that the IDI should only assess model performance among a clinically relevant subset when stratum-level calibration is strictly met and recommend calculating additional metrics to confirm the direction and conclusions of the IDI. Copyright {\textcopyright} 2016 John Wiley {\&} Sons, Ltd.},
author = {Chipman, J. and Braun, D.},
doi = {10.1002/sim.6862},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {BRCAPRO,integrated discrimination improvement,reclassification,risk prediction,simpson's paradox},
number = {28},
pages = {4468--4481},
pmid = {29160558},
title = {{Simpson's paradox in the integrated discrimination improvement}},
volume = {36},
year = {2017}
}
@article{Giannoni:2014fm,
author = {Giannoni, Alberto and Baruah, Resham and Leong, Tora and Rehman, Michaela B and Pastormerlo, Luigi Emilio and Harrell, Frank E and Coats, Andrew J S and Francis, Darrel P},
journal = {PloS one},
month = {jan},
number = {1},
pages = {e81699},
title = {{Do Optimal Prognostic Thresholds in Continuous Physiological Variables Really Exist? Analysis of Origin of Apparent Thresholds, with Systematic Review for Peak Oxygen Consumption, Ejection Fraction and BNP}},
volume = {9},
year = {2014}
}
@book{Anonymous:ur,
address = {1 Oliver's Yard,{\~{}}55 City Road{\~{}}London{\~{}}EC1Y 1SP{\~{}}},
publisher = {SAGE Publications, Ltd},
title = {{Using Propensity Scores in Quasi-Experimental Designs}}
}
@article{fleiss1981statistical,
author = {Fleiss, J L and Levin, B and Paik, M C},
journal = {New York},
title = {{Statistical methods for rates and proportions. John Wiley {\&} Sons}},
volume = {870},
year = {1981}
}
@article{Wu:2014ix,
author = {Wu, Yun-Chun and Lee, Wen-Chung},
journal = {PloS one},
month = {mar},
number = {3},
pages = {e91249},
title = {{Alternative Performance Measures for Prediction Models}},
volume = {9},
year = {2014}
}
@article{Presley2018,
abstract = {Background: It is unknown whether observational studies evaluating the association between antidiabetic medications and mortality adequately account for frailty. Our objectives were to evaluate if frailty was a potential confounder in the relationship between antidiabetic medication regimen and mortality and how well administrative and clinical electronic health record (EHR) data account for frailty. Methods: We conducted a retrospective cohort study in a single Veterans Health Administration (VHA) healthcare system of 500 hospitalizations - the majority due to heart failure - of Veterans who received regular VHA care and initiated type 2 diabetes treatment from 2001-2008. We measured frailty using a modified frailty index (FI, {\textgreater}0.21 frail). We obtained antidiabetic medication regimen and time-to-death from administrative sources. We compared FI among patients on different antidiabetic regimens. Stepwise Cox proportional hazards regression estimated time-to-death by demographic, administrative, clinical EHR, and FI data. Results: Median FI was 0.22 (interquartile range 0.18, 0.27). Frailty differed across antidiabetic regimens (p{\textless}0.001). A FI increase of 0.05 was associated with an increased risk of death (hazard ratio 1.45, 95{\%} confidence interval 1.32, 1.60). Cox proportional hazards model for time-to-death including demographic, administrative, and clinical EHR data had a c-statistic of 0.70; adding FI showed marginal improvement (c-statistic 0.72). Conclusions: Frailty was associated with antidiabetic regimen and death, and may confound that relationship. Demographic, administrative, and clinical EHR data, commonly used to balance differences among exposure groups, performed moderately well in assessing risk of death, with minimal gain from adding frailty. Study design and analytic techniques can help minimize potential confounding by frailty in observational studies.},
author = {Presley, Caroline A and Chipman, Jonathan and Min, Jea Young and Grijalva, Carlos G and Greevy, Robert A and Griffin, Marie R and Roumie, Christianne L},
doi = {10.1093/gerona/gly224},
issn = {1758-535X (Electronic)},
journal = {The journals of gerontology. Series A, Biological sciences and medical sciences},
language = {eng},
month = {sep},
pmid = {30256914},
title = {{Evaluation of frailty as an unmeasured confounder in observational studies of antidiabetic medications.}},
year = {2018}
}
@article{randie2013,
abstract = {The importance of hemoglobin A1c (HbA1c) as an indicator of mean glycemia and risks for complications in patients with diabetes mellitus was established by the results of long-term clinical trials, most notably the Diabetes Control and Complications Trial (DCCT) and United Kingdom Prospective Diabetes Study (UKPDS), published in 1993 and 1998 respectively. However, clinical application of recommended HbA1c targets that were based on these studies was difficult due to lack of comparability of HbA1c results among assay methods and laboratories. Thus, the National Glycohemoglobin Standardization Program (NGSP) was initiated in 1996 with the goal of standardizing HbA1c results to those of the DCCT/UKPDS. HbA1c standardization efforts have been highly successful; however, a number of issues have emerged on the "long and winding road" to better HbA1c, including the development of a higher-order HbA1c reference method by the International Federation of Clinical Chemistry (IFCC), recommendations to use HbA1c to diagnose as well as monitor diabetes, and point-of-care (POC) HbA1c testing. Here, we review the past, present and future of HbA1c standardization and describe the current status of HbA1c testing, including limitations that healthcare providers need to be aware of when interpreting HbA1c results. {\textcopyright} 2013 Elsevier B.V.},
author = {Little, Randie R. and Rohlfing, Curt L.},
doi = {10.1016/j.cca.2012.12.026},
file = {::},
issn = {00098981},
journal = {Clinica Chimica Acta},
keywords = {Diabetes,Glycated hemoglobin,HbA1c,Standardization},
pages = {63--71},
pmid = {23318564},
title = {{The long and winding road to optimal HbA1c measurement}},
volume = {418},
year = {2013}
}
@article{Barra:2012ta,
author = {Barra, S and Providencia, R and Paiva, L and Caetano, F and Almeida, I and Gomes, P and Marques, A L},
journal = {European Heart Journal: Acute Cardiovascular Care},
month = {nov},
number = {4},
pages = {320--336},
title = {{ACHTUNG-Rule: a new and improved model for prognostic assessment in myocardial infarction}},
volume = {1},
year = {2012}
}
@article{Chen:2014tr,
author = {Shi, Dawei and Chen, Tongwen and Shi, Ling},
journal = {Automatica},
month = {jan},
number = {1},
pages = {247--254},
title = {{Event-triggered maximum likelihood state estimation}},
volume = {50},
year = {2014}
}
@article{Fan:2015fd,
author = {Fan, Liqiong and Yeatts, Sharon D and Wolf, Bethany J and McClure, Leslie A and Selim, Magdy and Palesch, Yuko Y},
journal = {Statistical Methods in Medical Research},
month = {jan},
pages = {096228021561640},
title = {{The impact of covariate misclassification using generalized linear regression under covariate{\{}$\backslash$textendash{\}}adaptive randomization}},
volume = {24},
year = {2017}
}
@article{meis2003prevention,
author = {Meis, Paul J and Klebanoff, Mark and Thom, Elizabeth and Dombrowski, Mitchell P and Sibai, Baha and Moawad, Atef H and Spong, Catherine Y and Hauth, John C and Miodovnik, Menachem and Varner, Michael W and Others},
journal = {New England Journal of Medicine},
number = {24},
pages = {2379--2385},
publisher = {Mass Medical Soc},
title = {{Prevention of recurrent preterm delivery by 17 alpha-hydroxyprogesterone caproate}},
volume = {348},
year = {2003}
}
@article{Rubin:2007gc,
author = {Rubin, Donald B},
journal = {Statistics in medicine},
month = {jan},
number = {1},
pages = {20--36},
title = {{The design versus the analysis of observational studies for causal effects: parallels with the design of randomized trials.}},
volume = {26},
year = {2007}
}
@article{Lin:2013jh,
author = {Lin, Winston},
journal = {The Annals of Applied Statistics},
month = {mar},
number = {1},
pages = {295--318},
title = {{Agnostic notes on regression adjustments to experimental data: Reexamining Freedman' s critique}},
volume = {7},
year = {2013}
}
@misc{,
title = {{Ovid{\_} Modern Epidemiology Chapter 1.pdf}}
}
@misc{hill1965environment,
author = {Hill, Austin Bradford},
publisher = {Sage Publications},
title = {{The environment and disease: association or causation?}},
year = {1965}
}
@inproceedings{shalit2017estimating,
author = {Shalit, Uri and Johansson, Fredrik D and Sontag, David},
booktitle = {International conference on machine learning},
organization = {PMLR},
pages = {3076--3085},
title = {{Estimating individual treatment effect: generalization bounds and algorithms}},
year = {2017}
}
@article{Pepe:2014iq,
author = {Pepe, M S and Janes, H and Li, C I},
journal = {JNCI Journal of the National Cancer Institute},
month = {apr},
number = {4},
pages = {dju041----dju041},
title = {{Net Risk Reclassification P Values: Valid or Misleading?}},
volume = {106},
year = {2014}
}
@article{Chang2011,
abstract = {PURPOSE: Measuring the health related quality of life of patients with prostate cancer in routine clinical practice is hindered by the lack of instruments enabling efficient, real-time, point of care scoring of multiple health related quality of life domains. Thus, we developed an instrument for this purpose. MATERIALS AND METHODS: The Expanded Prostate Cancer Index Composite for Clinical Practice is a 1-page, 16-item questionnaire that we constructed to measure urinary incontinence, urinary irritation, and the bowel, sexual and hormonal health related quality of life domains. We eliminated conceptually overlapping items from the 3-page Expanded Prostate Cancer Index Composite-26 and revised the questionnaire format to mirror the AUA symptom index, thereby enabling practitioners to calculate health related quality of life scores at the point of care. We administered the Expanded Prostate Cancer Index Composite for Clinical Practice to a new cohort of patients with prostate cancer in community based and academic oncology, radiation, and urology practices to evaluate instrument validity as well as ease of use in clinical practice. RESULTS: A total of 175 treated and 132 untreated subjects with prostate cancer completed the Expanded Prostate Cancer Index Composite for Clinical Practice. The domain scores of the Expanded Prostate Cancer Index Composite for Clinical Practice correlated highly with the respective domain scores from longer versions of the Expanded Prostate Cancer Index Composite (r{\textgreater}/=0.93 for all domains). The Expanded Prostate Cancer Index Composite for Clinical Practice showed high internal consistency (Cronbach's alpha 0.64-0.84) and sensitivity to prostate cancer treatment related effects (p{\textless}0.05 in each of 5 health related quality of life domains). Patients completed the Expanded Prostate Cancer Index Composite for Clinical Practice efficiently (96{\%} in less than 10 minutes and with 11{\%} missing items). It was deemed very convenient by clinicians in 87{\%} of routine clinical encounters and clinicians accurately scored completed questionnaires 94{\%} of the time. CONCLUSIONS: The Expanded Prostate Cancer Index Composite for Clinical Practice is a valid instrument that enables patient reported, health related quality of life to be measured efficiently and accurately at the point of care, and thereby facilitates improved emphasis and management of patient reported outcomes.},
author = {Chang, Peter and Szymanski, Konrad M and Dunn, Rodney L and Chipman, Jonathan J and Litwin, Mark S and Nguyen, Paul L and Sweeney, Christopher J and Cook, Robert and Wagner, Andrew A and DeWolf, William C and Bubley, Glenn J and Funches, Renee and Aronovitz, Joseph A and Wei, John T and Sanda, Martin G},
doi = {10.1016/j.juro.2011.04.085},
issn = {1527-3792 (Electronic)},
journal = {The Journal of urology},
keywords = {Aged,Humans,Male,Middle Aged,Prostatic Neoplasms,Quality of Life,Surveys and Questionnaires,diagnosis},
language = {eng},
month = {sep},
number = {3},
pages = {865--872},
pmid = {21788038},
title = {{Expanded prostate cancer index composite for clinical practice: development and validation of a practical health related quality of life instrument for use in the routine clinical care of patients with prostate cancer.}},
volume = {186},
year = {2011}
}
@article{Li:2010dx,
author = {Li, Caixia and Lu, Ying},
journal = {Biometrical Journal},
month = {may},
number = {3},
pages = {417--435},
title = {{Evaluating the improvement in diagnostic utility from adding new predictors}},
volume = {52},
year = {2010}
}
@article{Ashley2016,
abstract = {There is great potential for genome sequencing to enhance patient care through improved diagnostic sensitivity and more precise therapeutic targeting. To maximize this potential, genomics strategies that have been developed for genetic discovery-including DNA-sequencing technologies and analysis algorithms-need to be adapted to fit clinical needs. This will require the optimization of alignment algorithms, attention to quality-coverage metrics, tailored solutions for paralogous or low-complexity areas of the genome, and the adoption of consensus standards for variant calling and interpretation. Global sharing of this more accurate genotypic and phenotypic data will accelerate the determination of causality for novel genes or variants. Thus, a deeper understanding of disease will be realized that will allow its targeting with much greater therapeutic precision.},
author = {Ashley, Euan A.},
doi = {10.1038/nrg.2016.86},
file = {::},
issn = {14710064},
journal = {Nature Reviews Genetics},
number = {9},
pages = {507--522},
pmid = {27528417},
title = {{Towards precision medicine}},
volume = {17},
year = {2016}
}
@article{Bolland:2016dw,
author = {Bolland, Mark J and Avenell, Alison and Gamble, Greg D and Grey, Andrew},
journal = {Neurology},
month = {dec},
number = {23},
pages = {2391--2402},
title = {{Systematic review and statistical analysis of the integrity of 33 randomized controlled trials}},
volume = {87},
year = {2016}
}
@article{barker2009spy,
author = {Barker, A D and Sigman, C C and Kelloff, G J and Hylton, N M and Berry, D A and Esserman, LJs},
file = {::},
journal = {Clinical Pharmacology $\backslash${\&} Therapeutics},
number = {1},
pages = {97--100},
publisher = {Wiley Online Library},
title = {{I-SPY 2: an adaptive breast cancer trial design in the setting of neoadjuvant chemotherapy}},
volume = {86},
year = {2009}
}
@article{GUIDANCE2016,
author = {GUIDANCE, DRAFT},
file = {::},
journal = {Slides},
number = {November},
title = {{Preparation of Food Contact Notifications for Food Contact Substances in Contact with Infant Formula and/or Human Milk: Guidance for Industry}},
url = {https://www.fda.gov/downloads/Food/GuidanceRegulation/GuidanceDocumentsRegulatoryInformation/UCM528255.pdf{\%}0Ahttps://www.fda.gov/downloads/Drugs/Guidances/UCM202140.pdf},
year = {2016}
}
@article{Nelson:2018bw,
author = {Nelson, Lyndsay A and Wallston, Kenneth A and Kripalani, Sunil and {Greevy Jr.}, Robert A and Elasy, Tom A and Bergner, Erin M and Gentry, Chad K and Mayberry, Lindsay S},
journal = {JMIR Research Protocols},
month = {apr},
number = {4},
pages = {e92},
title = {{Mobile Phone Support for Diabetes Self-Care Among Diverse Adults: Protocol for a Three-Arm Randomized Controlled Trial}},
volume = {7},
year = {2018}
}
@article{Fryer:2014fc,
author = {Fryer, Roland G},
journal = {The Quarterly Journal of Economics},
month = {aug},
number = {3},
pages = {1355--1407},
title = {{ Injecting Charter School Best Practices into Traditional Public Schools: Evidence from Field Experiments}},
volume = {129},
year = {2014}
}
@article{Chen:2013gc,
author = {Chen, Weijie and Samuelson, Frank W and Gallas, Brandon D and Kang, Le and Sahiner, Berkman and Petrick, Nicholas},
journal = {BMC Medical Research Methodology},
month = {jul},
number = {1},
pages = {1},
title = {{On the assessment of the added value of new predictive biomarkers}},
volume = {13},
year = {2013}
}
@article{Ware:2008ei,
author = {Ware, J H and Cai, T},
journal = {Statistics in medicine},
number = {2},
pages = {185--187},
title = {{Comments on {\{}$\backslash$textquoteleft{\}}Evaluating the added predictive ability of a new marker: From area under the ROC curve to reclassification and beyond{\{}$\backslash$textquoteright{\}} by M. J. Pencinaet al.,Statistics in Medicine (DOI: 10.1002/sim.2929)}},
volume = {27},
year = {2007}
}
@article{Abadie2020a,
abstract = {Consider a researcher estimating the parameters of a regression function based on data for all 50 states in the United States or on data for all visits to a website. What is the interpretation of the estimated parameters and the standard errors? In practice, researchers typically assume that the sample is randomly drawn from a large population of interest and report standard errors that are designed to capture sampling variation. This is common even in applications where it is difficult to articulate what that population of interest is, and how it differs from the sample. In this article, we explore an alternative approach to inference, which is partly design‐based. In a design‐based setting, the values of some of the regressors can be manipulated, perhaps through a policy intervention. Design‐based uncertainty emanates from lack of knowledge about the values that the regression outcome would have taken under alternative interventions. We derive standard errors that account for design‐based uncertainty instead of, or in addition to, sampling‐based uncertainty. We show that our standard errors in general are smaller than the usual infinite‐population sampling‐based standard errors and provide conditions under which they coincide.},
author = {Abadie, Alberto and Athey, Susan and Imbens, Guido W. and Wooldridge, Jeffrey M.},
doi = {10.3982/ecta12675},
file = {::},
issn = {0012-9682},
journal = {Econometrica},
number = {1},
pages = {265--296},
title = {{Sampling‐Based versus Design‐Based Uncertainty in Regression Analysis}},
volume = {88},
year = {2020}
}
@article{collins2016optimization,
author = {Collins, Linda M and Kugler, Kari C and Gwadz, Marya Viorst},
journal = {AIDS and Behavior},
number = {1},
pages = {197--214},
publisher = {Springer},
title = {{Optimization of multicomponent behavioral and biobehavioral interventions for the prevention and treatment of HIV/AIDS}},
volume = {20},
year = {2016}
}
@article{Levinson:gj,
author = {Levinson, Stanley S},
journal = {Clinical Chemistry and Laboratory Medicine},
number = {7},
title = {{Letter to the Editor Reply: Statistical methods for assessment of added usefulness of new biomarkers}},
volume = {49}
}
@article{bergner2017text,
author = {Bergner, Erin M and Nelson, Lyndsay A and Rothman, Russell L and Mayberry, Lindsay},
journal = {HLRP: Health Literacy Research and Practice},
number = {4},
pages = {e192----e202},
publisher = {SLACK Incorporated},
title = {{Text messaging may engage and benefit adults with type 2 diabetes regardless of health literacy status}},
volume = {1},
year = {2017}
}
@article{byington2016matrix,
author = {Byington, Carrie L and Keenan, Heather and Phillips, John D and Childs, Rebecca and Wachs, Erin and Berzins, Mary Anne and Clark, Kim and Torres, Maria K and Abramson, Jan and Lee, Vivian and Others},
journal = {Academic Medicine},
number = {4},
pages = {497},
publisher = {Wolters Kluwer Health},
title = {{A matrix mentoring model that effectively supports clinical and translational scientists and increases inclusion in biomedical research: Lessons from the University of Utah}},
volume = {91},
year = {2016}
}
@article{Vickers:2011bq,
author = {Vickers, A J},
journal = {Journal of Clinical Oncology},
month = {jul},
number = {22},
pages = {2951--2952},
title = {{Prediction Models: Revolutionary in Principle, But Do They Do More Good Than Harm?}},
volume = {29},
year = {2011}
}
@incollection{Anonymous:MBJdFZb9,
address = {Chichester, UK},
author = {Gonzalez, Ruben and Qi, Fei and Huang, Biao},
booktitle = {Process Control System Fault Diagnosis: A Bayesian Approach},
month = {aug},
pages = {62--67},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Bayesian Diagnosis}},
year = {2016}
}
@article{Bigler2010,
abstract = {This study sought to replicate Herbert et al. (2003a), which found increased overall white matter (WM) volume in subjects with autism, even after controlling for head size differences. To avoid the possibility that greater WM volume in autism is merely an epiphenomena of macrocephaly overrepresentation associated with the disorder, the current study included control subjects with benign macrocephaly. The control group also included subjects with a reading disability to insure cognitive heterogeneity. WM volume in autism was significantly larger, even when controlling for brain volume, rate of macrocephaly, and other demographic variables. Autism and controls differed little on whole-brain WM voxel-based morphometry (VBM) analyses suggesting that the overall increase in WM volume was non-localized. Autism subjects exhibited a differential pattern of IQ relationships with brain volumetry findings from controls. Current theories of brain overgrowth and their importance in the development of autism are discussed in the context of these findings.},
author = {Bigler, Erin D and Abildskov, Tracy J and Petrie, Jo Ann and Johnson, Michael and Lange, Nicholas and Chipman, Jonathan and Lu, Jeffrey and McMahon, William and Lainhart, Janet E},
doi = {10.1080/87565641003696817},
issn = {1532-6942 (Electronic)},
journal = {Developmental neuropsychology},
keywords = {Adolescent,Autistic Disorder,Body Weights and Measures,Brain,Brain Diseases,Brain Mapping,Child,Developmental Disabilities,Diffusion Magnetic Resonance Imaging,Female,Functional Laterality,Humans,Intelligence Tests,Linear Models,Male,Multivariate Analysis,Young Adult,complications,methods,pathology,physiology},
language = {eng},
number = {3},
pages = {278--295},
pmid = {20446133},
title = {{Volumetric and voxel-based morphometry findings in autism subjects with and without macrocephaly.}},
volume = {35},
year = {2010}
}
@article{koyama2008proper,
author = {Koyama, Tatsuki and Chen, Heidi},
file = {::},
journal = {Statistics in medicine},
number = {16},
pages = {3145--3154},
publisher = {Wiley Online Library},
title = {{Proper inference from Simon's two-stage designs}},
volume = {27},
year = {2008}
}
@article{Lewis2020,
abstract = {Genome-wide association studies have shown unequivocally that common complex disorders have a polygenic genetic architecture and have enabled researchers to identify genetic variants associated with diseases. These variants can be combined into a polygenic risk score that captures part of an individual's susceptibility to diseases. Polygenic risk scores have been widely applied in research studies, confirming the association between the scores and disease status, but their clinical utility has yet to be established. Polygenic risk scores may be used to estimate an individual's lifetime genetic risk of disease, but the current discriminative ability is low in the general population. Clinical implementation of polygenic risk score (PRS) may be useful in cohorts where there is a higher prior probability of disease, for example, in early stages of diseases to assist in diagnosis or to inform treatment choices. Important considerations are the weaker evidence base in application to non-European ancestry and the challenges in translating an individual's PRS from a percentile of a normal distribution to a lifetime disease risk. In this review, we consider how PRS may be informative at different points in the disease trajectory giving examples of progress in the field and discussing obstacles that need to be addressed before clinical implementation.},
author = {Lewis, Cathryn M. and Vassos, Evangelos},
doi = {10.1186/s13073-020-00742-5},
file = {::},
issn = {1756994X},
journal = {Genome Medicine},
keywords = {Common disorders,Genetics,Pharmacogenetics,Polygenic risk scores,Prediction,Risk},
number = {1},
pages = {1--11},
pmid = {32423490},
publisher = {Genome Medicine},
title = {{Polygenic risk scores: From research tools to clinical instruments}},
volume = {12},
year = {2020}
}
@article{Viallon:2011bj,
author = {Viallon, Vivian and Latouche, Aurelien},
journal = {Biometrical Journal},
month = {feb},
number = {2},
pages = {217--236},
title = {{Discrimination measures for survival outcomes: Connection between the AUC and the predictiveness curve}},
volume = {53},
year = {2011}
}
@article{Ciolino:2011ff,
author = {Ciolino, Jody and Zhao, Wenle and Martin, Renee and Palesch, Yuko},
journal = {Contemporary Clinical Trials},
month = {mar},
number = {2},
pages = {250--259},
title = {{Quantifying the cost in power of ignoring continuous covariate imbalances in clinical trial randomization}},
volume = {32},
year = {2011}
}
@article{Dinga2016,
abstract = {Unmeasured confounding may undermine the validity of causal inference with observational studies. Sensitivity analysis provides an attractive way to partially circumvent this issue by assessing the potential influence of unmeasured confounding on causal conclusions. However, previous sensitivity analysis approaches often make strong and untestable assumptions such as having an unmeasured confounder that is binary, or having no interaction between the effects of the exposure and the confounder on the outcome, or having only one unmeasured confounder. Without imposing any assumptions on the unmeasured confounder or confounders, we derive a bounding factor and a sharp inequality such that the sensitivity analysis parameters must satisfy the inequality if an unmeasured confounder is to explain away the observed effect estimate or reduce it to a particular level. Our approach is easy to implement and involves only two sensitivity parameters. Surprisingly, our bounding factor, which makes no simplifying assumptions, is no more conservative than a number of previous sensitivity analysis techniques that do make assumptions. Our new bounding factor implies not only the traditional cornfield conditions that both the relative risk of the exposure on the confounder and that of the confounder on the outcome must satisfy but also a high threshold that the maximum of these relative risks must satisfy. Furthermore, this new bounding factor can be viewed as a measure of the strength of confounding between the exposure and the outcome induced by a confounder.},
archivePrefix = {arXiv},
arxivId = {1507.03984},
author = {Dinga, Peng and VanderWeele, Tyler J.},
doi = {10.1097/eDe.0000000000000457},
eprint = {1507.03984},
isbn = {0000000000000},
issn = {15315487},
journal = {Epidemiology},
number = {3},
pages = {368--377},
pmid = {26841057},
title = {{Sensitivity analysis without assumptions}},
volume = {27},
year = {2016}
}
@article{Quigley2017,
author = {Quigley, John O and Pepe, Margaret and Fisher, Lloyd},
file = {::},
number = {1},
pages = {33--48},
title = {{Continual Reassessment Method : A Practical Design for Phase 1 Clinical Trials in Cancer Author ( s ): John O ' Quigley , Margaret Pepe and Lloyd Fisher Published by : International Biometric Society Stable URL : http://www.jstor.org/stable/2531628 Contin}},
volume = {46},
year = {2017}
}
@article{Muhlenbruch:2012fx,
author = {Muhlenbruch, Kristin and Heraclides, Alexandros and Steyerberg, Ewout W and Joost, Hans-Georg and Boeing, Heiner and Schulze, Matthias B},
journal = {European Journal of Epidemiology},
month = {nov},
number = {1},
pages = {25--33},
title = {{Assessing improvement in disease prediction using net reclassification improvement: impact of risk cut-offs and number of risk categories}},
volume = {28},
year = {2012}
}
@article{Cornfield:1966ks,
author = {Cornfield, Jerome},
journal = {The American statistician},
month = {apr},
number = {2},
pages = {18--23},
title = {{Sequential Trials, Sequential Analysis and the Likelihood Principle}},
volume = {20},
year = {1966}
}
@article{Taves:2010il,
author = {Taves, Donald R},
journal = {Contemporary Clinical Trials},
month = {mar},
number = {2},
pages = {180--184},
title = {{The use of minimization in clinical trials}},
volume = {31},
year = {2010}
}
@article{Pencina:2016cm,
author = {Pencina, Michael J and Steyerberg, Ewout W and {D'Agostino Sr.}, Ralph B},
journal = {Statistics in medicine},
month = {jul},
title = {{Net reclassification index at event rate: properties and relationships}},
year = {2016}
}
@article{Biswas:2014gx,
author = {Biswas, Swati and Arun, Banu and Parmigiani, Giovanni},
journal = {Statistics in medicine},
month = {dec},
number = {11},
pages = {1914--1927},
title = {{Reclassification of predictions for uncovering subgroup specific improvement}},
volume = {33},
year = {2013}
}
@article{Hutson:2010ih,
author = {Hutson, Stu},
journal = {Nature medicine},
month = {jun},
number = {6},
pages = {618},
title = {{Data handling errors spur debate over clinical trial.}},
volume = {16},
year = {2010}
}
@article{Booth1994,
abstract = {We show that the familiar bootstrap plug-in rule of Efron has a natural analog in finite population settings. In our method a characteristic of the population is estimated by the average value of the characteristic over a class of empirical populations constructed from the sample. Our method extends that of Gross to situations in which the stratum sizes are not integer multiples of their respective sample sizes. Moreover, we show that our method can be used to generate second-order correct confidence intervals for smooth functions of population means, a property that has not been established for other resampling methods suggested in the literature. A second resampling method is proposed that also leads to second-order correct confidence intervals and is less computationally intensive than our bootstrap. But a simulation study reveals that the second method can be quite unstable in some situations, whereas our bootstrap performs very well. {\textcopyright} 1994 Taylor {\&} Francis Group, LLC.},
author = {Booth, James G. and Butler, Ronald W. and Hall, Peter},
doi = {10.1080/01621459.1994.10476868},
file = {::},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Confidence interval,Edgeworth expansion,Empirical population,Plug-in rule,Resample,Second-order correct,Subsample,Survey data},
number = {428},
pages = {1282--1289},
title = {{Bootstrap methods for finite populations}},
volume = {89},
year = {1994}
}
@article{Vickers:2010hs,
author = {Vickers, Andrew J and Cronin, Angel M},
journal = {Urology},
month = {dec},
number = {6},
pages = {1298--1301},
title = {{Everything You Always Wanted to Know About Evaluating Prediction Models (But Were Too Afraid to Ask)}},
volume = {76},
year = {2010}
}
@article{Bothwell:2016bc,
author = {Bothwell, Laura E and Greene, Jeremy A and Podolsky, Scott H and Jones, David S},
journal = {New England Journal of Medicine},
month = {jun},
number = {22},
pages = {2175--2181},
title = {{Assessing the Gold Standard--Lessons from the History of RCTs.}},
volume = {374},
year = {2016}
}
@article{Proschan2020,
author = {Proschan, Michael and Evans, Scott},
journal = {Clinical Infectious Diseases},
number = {11},
pages = {3002--3004},
publisher = {Oxford University Press US},
title = {{Resist the temptation of response-adaptive randomization}},
volume = {71},
year = {2020}
}
@article{committee2012guideline,
author = {{Committee for Medicinal Products for Human Use and other}},
journal = {London, European Medicines Society},
title = {{Guideline on clinical investigation of medicinal products in the treatment or prevention of diabetes mellitus}},
year = {2012}
}
@book{fisher1935design,
author = {Fisher, Ronald A},
edition = {1},
publisher = {Oliver and Boyd},
title = {{The design of experiments}},
year = {1935}
}
@article{Kang:2007dx,
author = {Kang, Joseph D Y and Schafer, Joseph L},
journal = {Statistical Science},
month = {nov},
number = {4},
pages = {523--539},
title = {{Demystifying Double Robustness: A Comparison of Alternative Strategies for Estimating a Population Mean from Incomplete Data}},
volume = {22},
year = {2007}
}
@article{Rosenbaum1983,
abstract = {The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two- dimensional plot. {\textcopyright} 1983 Biometrika Trust.},
author = {Rosenbaum, Paul R. and Rubin, Donald B.},
doi = {10.1093/biomet/70.1.41},
file = {::;::},
issn = {00063444},
journal = {Biometrika},
keywords = {Covariance adjustment,Direct adjustment,Discriminant matching,Matched sampling,Nonrandomized study,Standardization,Stratification,Subclassification},
number = {1},
pages = {41--55},
title = {{The central role of the propensity score in observational studies for causal effects}},
volume = {70},
year = {1983}
}
@article{Nattino:2014wc,
author = {Nattino, G and Finazzi, S and Bertolini, G},
journal = {Statistics in medicine},
title = {{Comments on 'Graphical assessment of internal and external calibration of logistic regression models by using loess smoothers' by Peter C. Austin and Ewout {\ldots}}},
year = {2014}
}
@article{Chin2018,
abstract = {We study conditions under which treatment effect estimators constructed under the no-interference assumption in randomized experiments are asymptotically normal in the presence of interference. We prove that the standard Horvitz-Thompson estimator is asymptotically normal under a restricted interference condition characterized by limiting the degree of the dependency graph. The amount of interference is allowed to grow with the population size. We then provide a central limit theorem for the difference-in-means estimator that can handle interference that exists between all pairs of units, provided most of the interference is captured by a restricted-degree dependency graph. The asymptotic variance admits a decomposition into two terms: (a) the variance that is expected under no-interference and (b) the additional variance contributed by interference. We propose a conservative variance estimator based on this variance decomposition. The results arise as an application of Stein's method. For practitioners, our results show that standard estimators continue to exhibit normality in large sample sizes and that inference can be made robust to mild forms of interference.},
archivePrefix = {arXiv},
arxivId = {1804.03105},
author = {Chin, Alex},
eprint = {1804.03105},
file = {::},
keywords = {causal inference,dependency graph,normal approximation,sutva},
number = {Manski 2013},
pages = {1--29},
title = {{Central limit theorems via Stein's method for randomized experiments under interference}},
url = {http://arxiv.org/abs/1804.03105},
year = {2018}
}
@article{Zviedrite2021,
author = {Zviedrite, N and Hodis, J D and Jahan, F and Gao, H and Uzicanin, A},
doi = {10.1371/journal.pone.0248925},
issn = {1932-6203 (Electronic) 1932-6203 (Linking)},
journal = {PLoS One},
number = {9},
pages = {e0248925},
title = {{COVID-19-associated school closures and related efforts to sustain education and subsidized meal programs, United States, February 18-June 30, 2020}},
volume = {16},
year = {2021}
}
@misc{beck2016nbpmatching,
author = {Beck, Cole and Lu, Bo and Greevy, Robert},
title = {{nbpMatching: Functions for optimal non-bipartite matching. R package version 1.5. 1}},
year = {2016}
}
@article{Whitehead1999,
abstract = {The theory underlying sequential clinical trials is now well developed, and the methodology is increasingly being implemented in practice, both by the pharmaceutical industry and in the public sector. The consequences of conducting interim analyses for frequentist interpretations of data are now well understood. A large number of approaches are available for the calculation of stopping boundaries and for the eventual terminal analysis. In this paper, the principles of the design and analysis of sequential clinical trials will be presented. Existing methods will be reviewed, and their relationships with the general principles will be clarified. Controversies and gaps within the methodology will be highlighted. It is intended that presentation of the subject as a single unified theory will allow the few essential underlying features to be better appreciated.},
author = {Whitehead, John},
doi = {10.1002/(sici)1097-0258(19990915/30)18:17/18<2271::aid-sim254>3.0.co;2-z},
issn = {02776715},
journal = {Statistics in Medicine},
number = {17-18},
pages = {2271--2286},
pmid = {10474138},
title = {{A unified theory for sequential clinical trials}},
volume = {18},
year = {1999}
}
@article{Cook:hm,
author = {Cook, Nancy R},
journal = {The international journal of biostatistics},
number = {1},
title = {{Comment: Measures to Summarize and Compare the Predictive Capacity of Markers}},
volume = {6}
}
@article{Vickers:2014gt,
author = {Vickers, A J},
journal = {Journal of Clinical Oncology},
month = {dec},
number = {36},
pages = {4033--4034},
title = {{Markers for the Early Detection of Prostate Cancer: Some Principles for Statistical Reporting and Interpretation}},
volume = {32},
year = {2014}
}
@article{Zubizarreta:2012iv,
author = {Zubizarreta, Jos{\'{e}} R},
journal = {Journal of the American Statistical Association},
month = {dec},
number = {500},
pages = {1360--1371},
title = {{Using Mixed Integer Programming for Matching in an Observational Study of Kidney Failure After Surgery}},
volume = {107},
year = {2012}
}
@article{Moore2020,
abstract = {Objectives Little is routinely disclosed about the costs of the pivotal clinical trials that provide the key scientific evidence of the treatment benefits of new therapeutic agents. We expand our earlier research to examine why the estimated costs may vary 100-fold. Design A cross-sectional study of the estimated costs of the pivotal clinical trials supporting the approval of 101 new therapeutic agents approved by the US Food and Drug Administration from 2015 to 2017. Methods We licensed a software tool used by the pharmaceutical industry to estimate the likely costs of clinical trials to be conducted by contract research organisations. For each trial we collected 52 study characteristics. Linear regression was used to assess the most important factors affecting costs. Primary and secondary outcome measures The mean and 95{\%} CI of 225 pivotal clinical trials using varying assumptions. We also assessed median estimated costs per patient, per clinic visit and per drug. Results Measured as pivotal trials cost per approved drug, the 101 new molecular entities had an estimated median cost of US{\$}48 million (IQR US{\$}20 million-US{\$}102 million). The 225 individual clinical trials had a median estimate of US{\$}19 million (IQR US{\$}12 million-US{\$}33 million) per trial and US{\$}41 413 (IQR, US{\$}29 894-US{\$}75 047) per patient. The largest single factor driving cost was the number of patients required to establish the treatment effects and varied from 4 patients to 8442. Next was the number of trial clinic visits, which ranged from 2 to 166. Our statistical model showed trial costs rose exponentially with these two variables (R 2 =0.696, F=257.9, p{\textless}0.01). Conclusions The estimated costs are modest for measuring the benefits of new therapeutic agents but rise exponentially as more patients and clinic visits are required to establish a drug effect.},
author = {Moore, Thomas J. and Heyward, James and Anderson, Gerard and Alexander, G. Caleb},
doi = {10.1136/bmjopen-2020-038863},
issn = {20446055},
journal = {BMJ Open},
number = {6},
pages = {1--5},
pmid = {32532786},
title = {{Variation in the estimated costs of pivotal clinical benefit trials supporting the US approval of new therapeutic agents, 2015-2017: A cross-sectional study}},
volume = {10},
year = {2020}
}
@article{GreevyJr:2012hp,
author = {{Greevy Jr.}, Robert A and Grijalva, Carlos G and Roumie, Christianne L and Beck, Cole and Hung, Adriana M and Murff, Harvey J and Liu, Xulei and Griffin, Marie R},
journal = {Pharmacoepidemiology and Drug Safety},
month = {may},
pages = {148--154},
title = {{Reweighted Mahalanobis distance matching for cluster-randomized trials with missing data}},
volume = {21},
year = {2012}
}
@incollection{King:2016uw,
address = {1 Oliver's Yard,{\~{}}55 City Road{\~{}}London{\~{}}EC1Y 1SP{\~{}}},
author = {Holmes, William M},
booktitle = {Using Propensity Scores in Quasi-Experimental Designs},
pages = {103--127},
publisher = {SAGE Publications, Ltd},
title = {{Propensity Matching}}
}
@article{marshall1948streptomycin,
author = {Marshall, Geoffrey and Blacklock, J W S and Cameron, C and Capon, N B and Cruickshank, R and Gaddum, J H and Heaf, F R G and Hill, A Bradford and Houghton, L E and Hoyle, J Clifford and Others},
journal = {Br Med J},
number = {4582},
pages = {769--782},
title = {{Streptomycin treatment of pulmonary tuberculosis: a medical research council investigation}},
url = {https://www.jameslindlibrary.org/medical-research-council-1948b/},
volume = {2},
year = {1948}
}
@article{Cornfield:1951wt,
author = {Cornfield, J},
journal = {JNCI Journal of the National Cancer Institute},
month = {jun},
number = {6},
pages = {1269--1275},
title = {{A method of estimating comparative rates from clinical data; applications to cancer of the lung, breast, and cervix.}},
volume = {11},
year = {1951}
}
@misc{Zile2018,
abstract = {Background: The Food and Drug Administration (FDA) initiated the Expedited Access Pathway (EAP) to accelerate approval of novel therapies targeting unmet needs for life-threatening conditions. EAP allows for the possibility of initial FDA approval using intermediate end points with postapproval demonstration of improved outcomes. Objective: Describe the EAP process using the BeAT-HF trial as a case study. Methods: BeAT-HF will examine the safety and effectiveness of baroreflex activation therapy (BAT) in heart failure patients with reduced ejection fraction using an Expedited and Extended Phase design. In the Expedited Phase, BAT plus guideline-directed medical therapy (GDMT) will be compared at 6 months postimplant to GDMT alone using 3 intermediate end points: 6-minute hall walk distance, Minnesota Living with Heart Failure Questionnaire, and N-terminal pro–B-type natriuretic peptide. The rate of heart failure morbidity and cardiovascular mortality will be compared between the arms to evaluate early trending using predictive probability modeling. Sample size of 264 patients randomized 1:1 to BAT + GDMT versus GDMT alone provides 81{\%} power for the Expedited Phase intermediate end points. For the Extended Phase, the heart failure morbidity and cardiovascular mortality end point is based on an expected event rate of 0.4 events/patient/year in the GDMT arm. With an adaptive sample size selection design for robustness to inaccurate assumptions, a sample size of 480-960 randomized patients followed ≥2 years allows detecting a 30{\%} reduction in the primary end point with a power of 97.5{\%}. Conclusion: Through a unique collaboration with FDA under the EAP, the BeAT-HF trial design allows for the possibility of approval of BAT, initially for symptom relief and subsequently for outcomes improvement.},
author = {Zile, Michael R. and Abraham, William T. and Lindenfeld, Jo Ann and Weaver, Fred A. and Zannad, Faiez and Graves, Todd and Rogers, Tyson and Galle, Elizabeth G.},
booktitle = {American Heart Journal},
doi = {10.1016/j.ahj.2018.07.011},
issn = {10976744},
pages = {139--150},
pmid = {30118942},
title = {{First granted example of novel FDA trial design under Expedited Access Pathway for premarket approval: BeAT-HF}},
volume = {204},
year = {2018}
}
@article{Pencina:jc,
author = {Pencina, Michael J and D'Agostino, Ralph B and Vasan, Ramachandran S},
journal = {Clinical Chemistry and Laboratory Medicine},
number = {12},
title = {{Statistical methods for assessment of added usefulness of new biomarkers}},
volume = {48}
}
@article{storer1989design,
author = {Storer, Barry E},
file = {::},
journal = {Biometrics},
pages = {925--937},
publisher = {JSTOR},
title = {{Design and analysis of phase I clinical trials}},
year = {1989}
}
@article{Lin:1998wn,
author = {Lin, D Y and Psaty, B M and Kronmal, R A},
journal = {Biometrics},
month = {sep},
number = {3},
pages = {948--963},
title = {{Assessing the sensitivity of regression results to unmeasured confounders in observational studies.}},
volume = {54},
year = {1998}
}
@article{Sing:2005jf,
author = {Sing, T and Sander, O and Beerenwinkel, N and Lengauer, T},
journal = {Bioinformatics},
month = {oct},
number = {20},
pages = {3940--3941},
title = {{ROCR: visualizing classifier performance in R}},
volume = {21},
year = {2005}
}
@article{Jung2004,
abstract = {Due to the optional sampling effect in a sequential design, the maximum likelihood estimator (MLE) following sequential tests is generally biased. In a typical two-stage design employed in a phase II clinical trial in cancer drug screening, a fixed number of patients are enrolled initially. The trial may be terminated for lack of clinical efficacy of treatment if the observed number of treatment responses after the first stage is too small. Otherwise, an additional fixed number of patients are enrolled to accumulate additional information on efficacy as well as on safety. There have been numerous suggestions for design of such two-stage studies. Here we establish that under the two-stage design the sufficient statistic, i.e. stopping stage and the number of treatment responses, for the parameter of the binomial distribution is also complete. Then, based on the Rao-Blackwell theorem, we derive the uniformly minimum variance unbiased estimator (UMVUE) as the conditional expectation of an unbiased estimator, which in this case is simply the maximum likelihood estimator based only on the first stage data, given the complete sufficient statistic. Our results generalize to a multistage design. We will illustrate features of the UMVUE based on two-stage phase II clinical trial design examples and present results of numerical studies on the properties of the UMVUE in comparison to the usual MLE. Copyright {\textcopyright} 2004 John Wiley {\&} Sons, Ltd.},
author = {Jung, Sin Ho and Kim, Kyung Mann},
doi = {10.1002/sim.1653},
file = {::},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Confidence interval,Maximum likelihood estimator,Phase II clinical trial,Stochastic ordering,Uniformly minimum variance unbiased estimator},
number = {6},
pages = {881--896},
pmid = {15027078},
title = {{On the estimation of the binomial probability in multistage clinical trials}},
volume = {23},
year = {2004}
}
@article{stewart2019second,
author = {Stewart, Thomas G and Blume, Jeffrey},
journal = {Frontiers in Ecology and Evolution},
pages = {486},
publisher = {Frontiers},
title = {{Second-generation p-values, shrinkage, and regularized models}},
volume = {7},
year = {2019}
}
@article{Pepe:2004ue,
author = {Pepe, M S},
journal = {American Journal of Epidemiology},
month = {may},
number = {9},
pages = {882--890},
title = {{Limitations of the Odds Ratio in Gauging the Performance of a Diagnostic, Prognostic, or Screening Marker}},
volume = {159},
year = {2004}
}
@article{Lindquist:2014kf,
author = {Lindquist, Martin A and Xu, Yuting and Nebel, Mary Beth and Caffo, Brain S},
journal = {NeuroImage},
month = {nov},
pages = {531--546},
title = {{Evaluating dynamic bivariate correlations in resting-state fMRI: A comparison study and a new approach}},
volume = {101},
year = {2014}
}
@article{Pencina2017,
author = {Pencina, Michael J and Chipman, Jonathan and Steyerberg, Ewout W and Braun, Danielle and Fine, Jason P and D'Agostino, Ralph B Sr},
doi = {10.1002/sim.7520},
issn = {1097-0258 (Electronic)},
journal = {Statistics in medicine},
language = {eng},
month = {dec},
number = {28},
pages = {4511--4513},
pmid = {29156502},
title = {{Authors' response to comments.}},
volume = {36},
year = {2017}
}
@article{Armitage2003,
abstract = {In summary, then, we should dismiss any thoughts of competitive claims for priority between Fisher and Hill. Fisher was clearly the progenitor of randomization as an integral part of rigorous comparative experimentation, although the idea had already been broached by others such as CS Peirce, the 19th century American philosopher. Hill, aided by colleagues such as Philip D'Arcy Hart and Marc Daniels in the streptomycin trial, had the ability and personality to persuade the medical profession that this was the way forward. Scientific medicine owes them both a great debt of gratitude.},
author = {Armitage, Peter},
doi = {10.1093/ije/dyg286},
issn = {03005771},
journal = {International Journal of Epidemiology},
number = {6},
pages = {925--928},
pmid = {14681247},
title = {{Fisher, Bradford Hill, and randomization}},
volume = {32},
year = {2003}
}
@article{Giudice:2011bh,
author = {Giudice, John H and Fieberg, John R and Lenarz, Mark S},
journal = {The Journal of Wildlife Management},
month = {sep},
number = {1},
pages = {75--87},
title = {{Spending degrees of freedom in a poor economy: A case study of building a sightability model for moose in northeastern Minnesota}},
volume = {76},
year = {2011}
}
@article{Pickle:1991th,
author = {Callanan, Terrance P and Harville, David A},
journal = {Journal of Statistical Computation and Simulation},
month = {may},
number = {1-4},
pages = {239--259},
title = {{Some new algorithms for computing restricted maximum likelihood estimates of variance components}},
volume = {38},
year = {1991}
}
@article{Cook:2012bt,
author = {Cook, N R},
journal = {American Journal of Epidemiology},
month = {sep},
number = {6},
pages = {488--491},
title = {{Clinically Relevant Measures of Fit? A Note of Caution}},
volume = {176},
year = {2012}
}
@article{bibaut2021post,
author = {Bibaut, Aur{\'{e}}lien and Dimakopoulou, Maria and Kallus, Nathan and Chambaz, Antoine and van der Laan, Mark},
file = {::},
journal = {Advances in Neural Information Processing Systems},
pages = {28548--28559},
title = {{Post-contextual-bandit inference}},
volume = {34},
year = {2021}
}
@article{Package2019,
author = {Package, Type and Studies, Title Designing Multi-arm Multi-stage},
file = {::},
title = {{Package ‘ MAMS '}},
year = {2019}
}
@article{seaman2013review,
author = {Seaman, Shaun R and White, Ian R},
journal = {Statistical methods in medical research},
number = {3},
pages = {278--295},
publisher = {Sage Publications Sage UK: London, England},
title = {{Review of inverse probability weighting for dealing with missing data}},
volume = {22},
year = {2013}
}
@article{Paynter:2013ce,
author = {Paynter, N P and Cook, N R},
journal = {Medical Decision Making},
month = {feb},
number = {2},
pages = {154--162},
title = {{A Bias-Corrected Net Reclassification Improvement for Clinical Subgroups}},
volume = {33},
year = {2013}
}
@article{Anonymous:OvaR0iyH,
month = {nov},
pages = {1--11},
title = {{MISSION-AIMS}},
year = {2018}
}
@article{Harrell:1982uv,
author = {Harrell, F E},
journal = {JAMA: The Journal of the American Medical Association},
month = {may},
number = {18},
pages = {2543--2546},
title = {{Evaluating the yield of medical tests}},
volume = {247},
year = {1982}
}
@article{Sanda2017,
abstract = {Importance: Potential survival benefits from treating aggressive (Gleason score,  {\textgreater}/=7) early-stage prostate cancer are undermined by harms from unnecessary prostate biopsy and overdiagnosis of indolent disease. Objective: To evaluate the a priori primary hypothesis that combined measurement of PCA3 and TMPRSS2:ERG (T2:ERG) RNA in the urine after digital rectal examination would improve specificity over measurement of prostate-specific antigen alone for detecting cancer with Gleason score of 7 or higher. As a secondary objective, to evaluate the potential effect of such urine RNA testing on health care costs. Design, Setting, and Participants: Prospective, multicenter diagnostic evaluation and validation in academic and community-based ambulatory urology clinics. Participants were a referred sample of men presenting for first-time prostate biopsy without preexisting prostate cancer: 516 eligible participants from among 748 prospective cohort participants in the developmental cohort and 561 eligible participants from 928 in the validation cohort. Interventions/Exposures: Urinary PCA3 and T2:ERG RNA measurement before prostate biopsy. Main Outcomes and Measures: Presence of prostate cancer having Gleason score of 7 or higher on prostate biopsy. Pathology testing was blinded to urine assay results. In the developmental cohort, a multiplex decision algorithm was constructed using urine RNA assays to optimize specificity while maintaining 95{\%} sensitivity for predicting aggressive prostate cancer at initial biopsy. Findings were validated in a separate multicenter cohort via prespecified analysis, blinded per prospective-specimen-collection, retrospective-blinded-evaluation (PRoBE) criteria. Cost effects of the urinary testing strategy were evaluated by modeling observed biopsy results and previously reported treatment outcomes. Results: Among the 516 men in the developmental cohort (mean age, 62 years; range, 33-85 years) combining testing of urinary T2:ERG and PCA3 at thresholds that preserved 95{\%} sensitivity for detecting aggressive prostate cancer improved specificity from 18{\%} to 39{\%}. Among the 561 men in the validation cohort (mean age, 62 years; range, 27-86 years), analysis confirmed improvement in specificity (from 17{\%} to 33{\%}; lower bound of 1-sided 95{\%} CI, 0.73{\%}; prespecified 1-sided P = .04), while high sensitivity (93{\%}) was preserved for aggressive prostate cancer detection. Forty-two percent of unnecessary prostate biopsies would have been averted by using the urine assay results to select men for biopsy. Cost analysis suggested that this urinary testing algorithm to restrict prostate biopsy has greater potential cost-benefit in younger men. Conclusions and Relevance: Combined urinary testing for T2:ERG and PCA3 can avert unnecessary biopsy while retaining robust sensitivity for detecting aggressive prostate cancer with consequent potential health care cost savings.},
author = {Sanda, Martin G and Feng, Ziding and Howard, David H and Tomlins, Scott A and Sokoll, Lori J and Chan, Daniel W and Regan, Meredith M and Groskopf, Jack and Chipman, Jonathan and Patil, Dattatraya H and Salami, Simpa S and Scherr, Douglas S and Kagan, Jacob and Srivastava, Sudhir and Thompson, Ian M Jr and Siddiqui, Javed and Fan, Jing and Joon, Aron Y and Bantis, Leonidas E and Rubin, Mark A and Chinnayian, Arul M and Wei, John T and Bidair, Mohamed and Kibel, Adam and Lin, Daniel W and Lotan, Yair and Partin, Alan and Taneja, Samir},
doi = {10.1001/jamaoncol.2017.0177},
institution = {and the EDRN-PCA3 Study Group},
issn = {2374-2445 (Electronic)},
journal = {JAMA oncology},
keywords = {Adult,Aged,Aged, 80 and over,Antigens, Neoplasm,Biomarkers, Tumor,Costs and Cost Analysis,Humans,Male,Middle Aged,Neoplasm Grading,Oncogene Proteins, Fusion,Prostatic Neoplasms,RNA,Urinalysis,diagnosis,economics,genetics,pathology,urine},
language = {eng},
month = {aug},
number = {8},
pages = {1085--1093},
pmid = {28520829},
title = {{Association Between Combined TMPRSS2:ERG and PCA3 RNA Urinary Testing and Detection of Aggressive Prostate Cancer.}},
volume = {3},
year = {2017}
}
@book{Administration:1998vk,
address = {Hoboken, NJ, USA},
author = {Administration, Food and Drug and {Administration, Food and Drug}},
editor = {D'Agostino, Ralph B and Sullivan, Lisa and Massaro, Joseph},
month = {mar},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Federal Register}},
year = {2007}
}
@article{Tzoulaki:2011hja,
author = {Tzoulaki, I and Liberopoulos, G and Ioannidis, J P A},
journal = {International Journal of Epidemiology},
month = {aug},
number = {4},
pages = {1094--1105},
title = {{Use of reclassification for assessment of improved prediction: an empirical evaluation}},
volume = {40},
year = {2011}
}
@article{collins2015new,
author = {Collins, Francis S and Varmus, Harold},
file = {::},
journal = {New England journal of medicine},
number = {9},
pages = {793--795},
publisher = {Mass Medical Soc},
title = {{A new initiative on precision medicine}},
volume = {372},
year = {2015}
}
@article{Gu:2009jf,
author = {Gu, Wen and Pepe, Margaret},
journal = {The international journal of biostatistics},
number = {1},
title = {{Measures to Summarize and Compare the Predictive Capacity of Markers}},
volume = {5}
}
@article{Proschan2019,
abstract = {As randomization methods use more information in more complex ways to assign patients to treatments, analysis of the resulting data becomes challenging. The treatment assignment vector and outcome vector become correlated whenever randomization probabilities depend on data correlated with outcomes. One straightforward analysis method is a re-randomization test that fixes outcome data and creates a reference distribution for the test statistic by repeatedly re-randomizing according to the same randomization method used in the trial. This article reviews re-randomization tests, especially in nonstandard settings like covariate-adaptive and response-adaptive randomization. We show that re-randomization tests provide valid inference in a wide range of settings. Nonetheless, there are simple examples demonstrating limitations.},
author = {Proschan, Michael A. and Dodd, Lori E.},
doi = {10.1002/sim.8093},
file = {::},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {conditional error rate,covariate-adaptive randomization,permutation tests,response-adaptive randomization,unconditional error rate},
number = {12},
pages = {2292--2302},
pmid = {30672002},
title = {{Re-randomization tests in clinical trials}},
volume = {38},
year = {2019}
}
@article{zhao2016better,
author = {Zhao, Wenle},
journal = {Statistics in medicine},
number = {10},
pages = {1736--1738},
publisher = {Wiley Online Library},
title = {{A better alternative to the inferior permuted block design is not necessarily complex}},
volume = {35},
year = {2016}
}
@article{Zelen:1979th,
author = {Zelen, Marvin},
journal = {New England Journal of Medicine},
month = {may},
number = {22},
pages = {1242--1245},
title = {{A New Design for Randomized Clinical Trials}},
volume = {300},
year = {1979}
}
@article{Anonymous:LQCphsyt,
month = {oct},
pages = {1--152},
title = {{On the Probability of Observing Misleading Evidence in Sequential Trials}},
year = {1999}
}
@article{Deliu2021,
abstract = {Using bandit algorithms to conduct adaptive randomised experiments can minimise regret, but it poses major challenges for statistical inference (e.g., biased estimators, inflated type-I error and reduced power). Recent attempts to address these challenges typically impose restrictions on the exploitative nature of the bandit algorithm{\$}-{\$}trading off regret{\$}-{\$}and require large sample sizes to ensure asymptotic guarantees. However, large experiments generally follow a successful pilot study, which is tightly constrained in its size or duration. Increasing power in such small pilot experiments, without limiting the adaptive nature of the algorithm, can allow promising interventions to reach a larger experimental phase. In this work we introduce a novel hypothesis test, uniquely based on the allocation probabilities of the bandit algorithm, and without constraining its exploitative nature or requiring a minimum experimental size. We characterise our {\$}Allocation\backslash Probability\backslash Test{\$} when applied to {\$}Thompson\backslash Sampling{\$}, presenting its asymptotic theoretical properties, and illustrating its finite-sample performances compared to state-of-the-art approaches. We demonstrate the regret and inferential advantages of our approach, particularly in small samples, in both extensive simulations and in a real-world experiment on mental health aspects.},
archivePrefix = {arXiv},
arxivId = {2111.00137},
author = {Deliu, Nina and Williams, Joseph J. and Villar, Sofia S.},
eprint = {2111.00137},
file = {::},
title = {{Efficient Inference Without Trading-off Regret in Bandits: An Allocation Probability Test for Thompson Sampling}},
url = {http://arxiv.org/abs/2111.00137},
year = {2021}
}
@article{Efron:1986cn,
author = {Efron, B},
journal = {The American statistician},
month = {feb},
number = {1},
pages = {1--5},
title = {{Why Isn't Everyone a Bayesian?}},
volume = {40},
year = {1986}
}
@article{Freedman:2008eq,
author = {Freedman, David A},
journal = {Advances in Applied Mathematics},
month = {mar},
number = {2},
pages = {176--196},
title = {{On regression adjustments in experiments with several treatments}},
volume = {40},
year = {2008}
}
@article{gail1984biased,
author = {Gail, Mitchell H and Wieand, S and Piantadosi, Steven},
journal = {Biometrika},
number = {3},
pages = {431--444},
publisher = {Oxford University Press},
title = {{Biased estimates of treatment effect in randomized experiments with nonlinear regressions and omitted covariates}},
volume = {71},
year = {1984}
}
@article{Attanasio:2002in,
author = {Attanasio, Andrea F and Howell, Simon and Bates, Peter C and Frewer, Paul and Chipman, John and Blum, Werner F and Shalet, Stephen M},
journal = {The Journal of Clinical Endocrinology {\&} Metabolism},
month = {jul},
number = {7},
pages = {3368--3372},
title = {{Body Composition, IGF-I and IGFBP-3 Concentrations as Outcome Measures in Severely GH-Deficient (GHD) Patients after Childhood GH Treatment: A Comparison with Adult Onset GHD Patients}},
volume = {87},
year = {2002}
}
@article{Chang2023,
abstract = {When analyzing data from randomized clinical trials, covariate adjustment can be used to account for chance imbalance in baseline covariates and to increase precision of the treatment effect estimate. A practical barrier to covariate adjustment is the presence of missing data. In this article, in the light of recent theoretical advancement, we first review several covariate adjustment methods with incomplete covariate data. We investigate the implications of the missing data mechanism on estimating the average treatment effect in randomized clinical trials with continuous or binary outcomes. In parallel, we consider settings where the outcome data are fully observed or are missing at random; in the latter setting, we propose a full weighting approach that combines inverse probability weighting for adjusting missing outcomes and overlap weighting for covariate adjustment. We highlight the importance of including the interaction terms between the missingness indicators and covariates as predictors in the models. We conduct comprehensive simulation studies to examine the finite-sample performance of the proposed methods and compare with a range of common alternatives. We find that conducting the proposed adjustment methods generally improves the precision of treatment effect estimates regardless of the imputation methods when the adjusted covariate is associated with the outcome. We apply the methods to the Childhood Adenotonsillectomy Trial to assess the effect of adenotonsillectomy on neurocognitive functioning scores.},
author = {Chang, Chia Rui and Song, Yue and Li, Fan and Wang, Rui},
doi = {10.1002/sim.9840},
file = {::},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {covariate balance,imputation,missingness indicator,outcome regression,overlap weighting,propensity score},
number = {22},
pages = {3919--3935},
pmid = {37394874},
title = {{Covariate adjustment in randomized clinical trials with missing covariate and outcome data}},
volume = {42},
year = {2023}
}
@article{Austin:2014ga,
author = {Nattino, G and Finazzi, S and Bertolini, G and Austin, Peter C and Steyerberg, Ewout W},
journal = {Statistics in medicine},
month = {feb},
number = {3},
pages = {517--535},
title = {{Graphical assessment of internal and external calibration of logistic regression models by using loess smoothers}},
volume = {33},
year = {2014}
}
@article{Ware:1985td,
author = {Ware, J H and Muller, J E and Braunwald, E},
journal = {The American journal of medicine},
month = {apr},
number = {4},
pages = {635--643},
title = {{The futility index. An approach to the cost-effective termination of randomized clinical trials.}},
volume = {78},
year = {1985}
}
@article{Vickers:2013de,
author = {Vickers, Andrew J},
journal = {BJU international},
month = {jul},
number = {4},
pages = {430--431},
title = {{If something looks too good to be true, it probably is}},
volume = {112},
year = {2013}
}
@book{Anonymous:2003uc,
address = {Chichester, UK},
month = {mar},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Analysis of Survey Data}},
year = {2003}
}
@article{Kim2008,
abstract = {Background: Two phase II trials in patients with previously-treated advanced non-small-cell lung cancer suggested that gefitinib was efficacious and less toxic than was chemotherapy. We compared gefitinib with docetaxel in patients with locally advanced or metastatic non-small-cell lung cancer who had been pretreated with platinum-based chemotherapy. Methods: We undertook an open-label phase III study with recruitment between March 1, 2004, and Feb 17, 2006, at 149 centres in 24 countries. 1466 patients with pretreated (≥one platinum-based regimen) advanced non-small-cell lung cancer were randomly assigned with dynamic balancing to receive gefitinib (250 mg per day orally; n=733) or docetaxel (75 mg/m2 intravenously in 1-h infusion every 3 weeks; n=733). The primary objective was to compare overall survival between the groups with co-primary analyses to assess non-inferiority in the overall per-protocol population and superiority in patients with high epidermal growth factor receptor (EGFR)-gene-copy number in the intention-to-treat population. This study is registered with ClinicalTrials.gov, number NCT00076388. Findings: 1433 patients were analysed per protocol (723 in gefitinib group and 710 in docetaxel group). Non-inferiority of gefitinib compared with docetaxel was confirmed for overall survival (593 vs 576 events; hazard ratio [HR] 1{\textperiodcentered}020, 96{\%} CI 0{\textperiodcentered}905-1{\textperiodcentered}150, meeting the predefined non-inferiority criterion; median survival 7{\textperiodcentered}6 vs 8{\textperiodcentered}0 months). Superiority of gefitinib in patients with high EGFR-gene-copy number (85 vs 89 patients) was not proven (72 vs 71 events; HR 1{\textperiodcentered}09, 95{\%} CI 0{\textperiodcentered}78-1{\textperiodcentered}51; p=0{\textperiodcentered}62; median survival 8{\textperiodcentered}4 vs 7{\textperiodcentered}5 months). In the gefitinib group, the most common adverse events were rash or acne (360 [49{\%}] vs 73 [10{\%}]) and diarrhoea (255 [35{\%}] vs 177 [25{\%}]); whereas in the docetaxel group, neutropenia (35 [5{\%}] vs 514 [74{\%}]), asthenic disorders (182 [25{\%}] vs 334 [47{\%}]), and alopecia (23 [3{\%}] vs 254 [36{\%}]) were most common. Interpretation: INTEREST established non-inferior survival of gefitinib compared with docetaxel, suggesting that gefitinib is a valid treatment for pretreated patients with advanced non-small-cell lung cancer. Funding: AstraZeneca. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Kim, Edward S. and Hirsh, Vera and Mok, Tony and Socinski, Mark A. and Gervais, Radj and Wu, Yi Long and Li, Long Yun and Watkins, Claire L. and Sellers, Mark V. and Lowe, Elizabeth S. and Sun, Yan and Liao, Mei Lin and {\O}sterlind, Kell and Reck, Martin and Armour, Alison A. and Shepherd, Frances A. and Lippman, Scott M. and Douillard, Jean Yves},
doi = {10.1016/S0140-6736(08)61758-4},
file = {::},
issn = {01406736},
journal = {The Lancet},
number = {9652},
pages = {1809--1818},
pmid = {19027483},
publisher = {Elsevier Ltd},
title = {{Gefitinib versus docetaxel in previously treated non-small-cell lung cancer (INTEREST): a randomised phase III trial}},
url = {http://dx.doi.org/10.1016/S0140-6736(08)61758-4},
volume = {372},
year = {2008}
}
@article{Anonymous:3lX1wleJ,
author = {Cook, Nancy R},
journal = {Annals of Internal Medicine},
month = {jun},
number = {11},
pages = {795},
title = {{Advances in Measuring the Effect of Individual Predictors of Cardiovascular Risk: The Role of Reclassification Measures}},
volume = {150},
year = {2009}
}
@article{Schonbrodt2018,
abstract = {A sizeable literature exists on the use of frequentist power analysis in the null-hypothesis significance testing (NHST) paradigm to facilitate the design of informative experiments. In contrast, there is almost no literature that discusses the design of experiments when Bayes factors (BFs) are used as a measure of evidence. Here we explore Bayes Factor Design Analysis (BFDA) as a useful tool to design studies for maximum efficiency and informativeness. We elaborate on three possible BF designs, (a) a fixed-n design, (b) an open-ended Sequential Bayes Factor (SBF) design, where researchers can test after each participant and can stop data collection whenever there is strong evidence for either ℋ1 or ℋ0, and (c) a modified SBF design that defines a maximal sample size where data collection is stopped regardless of the current state of evidence. We demonstrate how the properties of each design (i.e., expected strength of evidence, expected sample size, expected probability of misleading evidence, expected probability of weak evidence) can be evaluated using Monte Carlo simulations and equip researchers with the necessary information to compute their own Bayesian design analyses.},
annote = {Excellent overview of evidence based literature

Overview of Bayes Factor BF monitoring for 2 sets of hypotheses -- Sequential Bayes Factor Schonbrodte et al 2015).
- object of experimentation is not to reach a decision but to gain knoedge about the world

Overview of Bayes Factor
- Standard Bayes solution to hypothesis testing and multiple comparisons
- Evidence for H1 vs H0
- Neither H1 nor H0 need be true
- Does not force an all or none decision
- Does not require adjustment for sampling plans (and citations for p-values being sensitive to sampling plan)

Highlights Kruschke 2014 paper on monitoring ROPE

S errors within a degree of precision: Gelman, A., {\&} Tuerlinckx, F. (2000). Type S error rates for classical and Bayesian single and multiple comparison procedures.
Computational Statistics, 15(3), 373–390
-- Note 2.5{\%} error rate rather than 5{\%} error rate.

Design prior need not be the same as the analysis prior

Probability of misleading evidence (cites blume)
- pre-data concept vs post-data concept

Expected Bayesian power reflects prior on how likely each effect is to be observed.

Mentions consistency property of BF and LRT (though not consistent for effects i between two hypotheses.

Effect size prior

Great paper to review for filling in information on Clinical trial notes


Comment: Uses hypotheses:
H0: Point null
H1: Point alternative},
author = {Sch{\"{o}}nbrodt, Felix D. and Wagenmakers, Eric Jan},
doi = {10.3758/s13423-017-1230-y},
file = {::},
issn = {15315320},
journal = {Psychonomic Bulletin and Review},
keywords = {Bayes factor,Design analysis,Design planning,Power analysis,Sequential testing},
number = {1},
pages = {128--142},
pmid = {28251595},
title = {{Bayes factor design analysis: Planning for compelling evidence}},
volume = {25},
year = {2018}
}
@book{owen2001empirical,
author = {Owen, Art B},
publisher = {Chapman and Hall/CRC},
title = {{Empirical likelihood}},
year = {2001}
}
@article{VanCalster:xr2HFyWP,
author = {{Van Calster}, Ben and Steyerberg, Ewout W and {D'Agostino Sr.}, Ralph B and Pencina, Michael J},
journal = {Medical Decision Making},
month = {may},
number = {4},
pages = {513--522},
title = {{Sensitivity and Specificity Can Change in Opposite Directions When New Predictive Markers Are Added to Risk Models}},
volume = {34},
year = {2014}
}
@article{Wyss:2017kt,
author = {Wyss, Richard and Hansen, Ben B and Ellis, Alan R and Gagne, Joshua J and Desai, Rishi J and Glynn, Robert J and St{\"{u}}rmer, Til},
journal = {American Journal of Epidemiology},
month = {mar},
number = {9},
pages = {1--11},
title = {{The "Dry-Run" Analysis: A Method for Evaluating Risk Scores for Confounding Control.}},
volume = {185},
year = {2017}
}
@incollection{Davidson:2006cf,
address = {Berlin, Heidelberg},
author = {Davidson, Ian and Fan, Wei},
booktitle = {Knowledge Discovery in Databases: PKDD 2006},
pages = {478--486},
publisher = {Springer Berlin Heidelberg},
title = {{When Efficient Model Averaging Out-Performs Boosting and Bagging}},
year = {2006}
}
@article{VodopivecJamsek2012,
author = {Vodopivec‐Jamsek, Vlasta and de Jongh, Thyra and Gurol‐Urganci, Ipek and Atun, Rifat and Car, Josip},
issn = {1465-1858},
journal = {The Cochrane Library},
title = {{Mobile phone messaging for preventive health care}},
year = {2012}
}
@article{chang2020withdrawing,
author = {Chang, Christina Y and Nguyen, Christine P and Wesley, Barbara and Guo, Jia and Johnson, Laura Lee and Joffe, Hylton V},
journal = {New England Journal of Medicine},
number = {24},
pages = {e131},
publisher = {Mass Medical Soc},
title = {{Withdrawing approval of Makena—a proposal from the FDA Center for Drug Evaluation and Research}},
volume = {383},
year = {2020}
}
@article{Leening:Ga-QNAQ6,
author = {Leening, Maarten J G and Steyerberg, Ewout W and {Van Calster}, Ben and {D'Agostino Sr.}, Ralph B and Pencina, Michael J},
journal = {Statistics in medicine},
month = {jul},
number = {19},
pages = {3415--3418},
title = {{Net reclassification improvement and integrated discrimination improvement require calibrated models: relevance from a marker and model perspective}},
volume = {33},
year = {2014}
}
@article{Armitage:1982ji,
author = {Armitage, Peter},
journal = {Statistics in medicine},
number = {4},
pages = {345--352},
title = {{The role of randomization in clinical trials}},
volume = {1},
year = {1982}
}
@article{Hellevik:2009bt,
author = {Hellevik, Ottar},
journal = {Quality {\&} Quantity},
month = {feb},
number = {1},
pages = {59--74},
title = {{Linear versus logistic regression when the dependent variable is a dichotomy}},
volume = {43},
year = {2007}
}
@article{Koch1998,
abstract = {Analysis of covariance is an effective method for addressing two considerations for randomized clinical trials. One is reduction of variance for estimates of treatment effects and thereby the production of narrower confidence intervals and more powerful statistical tests. The other is the clarification of the magnitude of treatment effects through adjustment of corresponding estimates for any random imbalances between the treatment groups with respect to the covariables. The statistical basis of covariance analysis can be either non-parametric, with reliance only on the randomization in the study design, or parametric through a statistical model for a postulated sampling process. For non-parametric methods, there are no formal assumptions for how a response variable is related to the covariables, but strong correlation between response and covariables is necessary for variance reduction. Computations for these methods are straightforward through the application of weighted least squares to fit linear models to the differences between treatment groups for the means of the response variable and the covariables jointly with a specification that has null values for the differences that correspond to the covariables. Moreover, such analysis is similarly applicable to dichotomous indicators, ranks or integers for ordered categories, and continuous measurements. Since non-parametric covariance analysis can have many forms, the ones which are planned for a clinical trial need careful specification in its protocol. A limitation of non-parametric analysis is that it does not directly address the magnitude of treatment effects within subgroups based on the covariables or the homogeneity of such effects. For this purpose, a statistical model is needed. When the response criterion is dichotomous or has ordered categories, such a model may have a non-linear nature which determines how covariance adjustment modifies results for treatment effects. Insight concerning such modifications can be gained through their evaluation relative to non-parametric counterparts. Such evaluation usually indicates that alternative ways to compare treatments for a response criterion with adjustment for a set of covariables mutually support the same conclusion about the strength of treatment effects. This robustness is noteworthy since the alternative methods for covariance analysis have substantially different rationales and assumptions. Since findings can differ in important ways across alternative choices for covariables (as opposed to methods for covariance adjustment), the critical consideration for studies with covariance analyses planned as the primary method for comparing treatments is the specification of the covariables in the protocol (or in an amendment or formal plan prior to any unmasking of the study).},
author = {Koch, Gary G. and Tangen, Catherine M. and Jung, Jin Whan and Amara, Ingrid A.},
doi = {10.1002/(sici)1097-0258(19980815/30)17:15/16<1863::aid-sim989>3.0.co;2-m},
issn = {02776715},
journal = {Statistics in Medicine},
number = {15-16},
pages = {1863--1892},
pmid = {9749453},
title = {{Issues for covariance analysis of dichotomous and ordered categorical data from randomized clinical trials and non-parametric strategies for addressing them}},
volume = {17},
year = {1998}
}
@article{Baiocchi:2017cx,
author = {Baiocchi, Michael and Omondi, Benjamin and Langat, Nickson and Boothroyd, Derek B and Sinclair, Jake and Pavia, Lee and Mulinge, Munyae and Githua, Oscar and Golden, Neville H and Sarnquist, Clea},
journal = {Prevention science : the official journal of the Society for Prevention Research},
month = {oct},
number = {7},
pages = {818--827},
title = {{A Behavior-Based Intervention That Prevents Sexual Assault: the Results of a Matched-Pairs, Cluster-Randomized Study in Nairobi, Kenya.}},
volume = {18},
year = {2017}
}
@article{Iacus2012a,
abstract = {We discuss a method for improving causal inferences called "Coarsened Exact Matching" (CEM), and the new "Monotonic Imbalance Bounding" (MIB) class of matching methods from which CEM is derived. We summarize what is known about CEM and MIB, derive and illustrate several new desirable statistical properties of CEM, and then propose a variety of useful extensions. We show that CEM possesses a wide range of statistical properties not available in most other matching methods but is at the same time exceptionally easy to comprehend and use. We focus on the connection between theoretical properties and practical applications. We also make available easy-to-use open source software for R, Stata, and SPSS that implement all our suggestions. {\textcopyright} The Author 2011. Published by Oxford University Press on behalf of the Society for Political Methodology. All rights reserved.},
author = {Iacus, Stefano M. and King, Gary and Porro, Giuseppe},
doi = {10.1093/pan/mpr013},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Iacus, King, Porro - 2012 - Causal inference without balance checking Coarsened exact matching.pdf:pdf},
issn = {10471987},
journal = {Political Analysis},
number = {1},
pages = {1--24},
title = {{Causal inference without balance checking: Coarsened exact matching}},
volume = {20},
year = {2012}
}
@article{korn1994comparison,
author = {Korn, Edward L and Midthune, Douglas and Chen, T Timothy and Rubinstein, Lawrence V and Christian, Michaele C and Simon, Richard M},
journal = {Statistics in medicine},
number = {18},
pages = {1799--1806},
publisher = {Wiley Online Library},
title = {{A comparison of two phase I trial designs}},
volume = {13},
year = {1994}
}
@article{birnbaum1962foundations,
author = {Birnbaum, Allan},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Birnbaum - 1962 - On the foundations of statistical inference.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {298},
pages = {269--306},
publisher = {Taylor {\&} Francis},
title = {{On the foundations of statistical inference}},
volume = {57},
year = {1962}
}
@article{Li2017,
abstract = {Frequentists' inference often delivers point estimators associated with confidence intervals or sets for parameters of interest. Constructing the confidence intervals or sets requires understanding the sampling distributions of the point estimators, which, in many but not all cases, are related to asymptotic Normal distributions ensured by central limit theorems. Although previous literature has established various forms of central limit theorems for statistical inference in super population models, we still need general and convenient forms of central limit theorems for some randomization-based causal analyses of experimental data, where the parameters of interests are functions of a finite population and randomness comes solely from the treatment assignment. We use central limit theorems for sample surveys and rank statistics to establish general forms of the finite population central limit theorems that are particularly useful for proving asymptotic distributions of randomization tests under the sharp null hypothesis of zero individual causal effects, and for obtaining the asymptotic repeated sampling distributions of the causal effect estimators. The new central limit theorems hold for general experimental designs with multiple treatment levels, multiple treatment factors and vector outcomes, and are immediately applicable for studying the asymptotic properties of many methods in causal inference, including instrumental variable, regression adjustment, rerandomization, cluster-randomized experiments, and so on. Previously, the asymptotic properties of these problems are often based on heuristic arguments, which in fact rely on general forms of finite population central limit theorems that have not been established before. Our new theorems fill this gap by providing more solid theoretical foundation for asymptotic randomization-based causal inference. Supplementary materials for this article are available online.},
annote = {First pass impressions:

Finite population occurs in survey sampling (Cochran 1977) [randomness in sampling process] and randomized experiments with potential outcomes (Neyman 1923, Rubin 1974) [randomness through randomization] and is the "reasoned basis" for randomization (Fisher 1935).

- [impression] asymptotic normality okay for samples of finite populations [assuming complete randomization?] but not for more complicated designs such as rerandomization, factorial designs, and cluster-randomized experiments

Simple Random Sampling
- Examples:
1) Normal approximation of hypergeometric distribution
2) RBI IV estimation},
archivePrefix = {arXiv},
arxivId = {1610.04821},
author = {Li, Xinran and Ding, Peng},
doi = {10.1080/01621459.2017.1295865},
eprint = {1610.04821},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Li, Ding - 2017 - General Forms of Finite Population Central Limit Theorems with Applications to Causal Inference(2).pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Conservative confidence set,Fisher randomization test,Potential outcome,Randomization inference,Repeated sampling property,Sharp null hypothesis},
number = {520},
pages = {1759--1769},
publisher = {Taylor {\&} Francis},
title = {{General Forms of Finite Population Central Limit Theorems with Applications to Causal Inference}},
url = {https://doi.org/10.1080/01621459.2017.1295865},
volume = {112},
year = {2017}
}
@article{Imbens2021a,
abstract = {The bootstrap, introduced by The Jackknife, the Bootstrap and Other Resampling Plans ((1982), SIAM), has become a very popular method for estimating variances and constructing confidence intervals. A key insight is that one can approximate the properties of estimators by using the empirical distribution function of the sample as an approximation for the true distribution function. This approach views the uncertainty in the estimator as coming exclusively from sampling uncertainty. We argue that for causal estimands the uncertainty arises entirely, or partially, from a different source, corresponding to the stochastic nature of the treatment received. We develop a bootstrap procedure for inference regarding the average treatment effect that accounts for this uncertainty, and compare its properties to that of the classical bootstrap. We consider completely randomized and observational designs as well as designs with imperfect compliance.},
archivePrefix = {arXiv},
arxivId = {1807.02737},
author = {Imbens, Guido and Menzel, Konrad},
doi = {10.1214/20-AOS2009},
eprint = {1807.02737},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Imbens, Menzel - 2021 - A causal bootstrap(4).pdf:pdf},
issn = {21688966},
journal = {Annals of Statistics},
keywords = {Bootstrap,Causal inference,Partial identification},
number = {3},
pages = {1460--1488},
title = {{A causal bootstrap}},
volume = {49},
year = {2021}
}
@article{Villar2018,
abstract = {The Gittins index provides a well established, computationally attractive, optimal solution to a class of resource allocation problems known collectively as the multi-arm bandit problem. Its development was originally motivated by the problem of optimal patient allocation in multi-arm clinical trials. However, it has never been used in practice, possibly for the following reasons: (1) it is fully sequential, i.e., the endpoint must be observable soon after treating a patient, reducing the medical settings to which it is applicable; (2) it is completely deterministic and thus removes randomization from the trial, which would naturally protect against various sources of bias. We propose a novel implementation of the Gittins index rule that overcomes these difficulties, trading off a small deviation from optimality for a fully randomized, adaptive group allocation procedure which offers substantial improvements in terms of patient benefit, especially relevant for small populations. We report the operating characteristics of our approach compared to existing methods of adaptive randomization using a recently published trial as motivation.},
author = {Villar, Sof{\'{i}}a S. and Rosenberger, William F.},
doi = {10.1111/biom.12738},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Villar, Rosenberger - 2018 - Covariate-adjusted response-adaptive randomization for multi-arm clinical trials using a modified forward l.pdf:pdf;::},
issn = {15410420},
journal = {Biometrics},
keywords = {Adaptive designs,CARA randomization,Ethics,Multi-armed bandit,Sequential allocation},
number = {1},
pages = {49--57},
title = {{Covariate-adjusted response-adaptive randomization for multi-arm clinical trials using a modified forward looking Gittins index rule}},
volume = {74},
year = {2018}
}
@article{Kruschke:2018bz,
annote = {HDI+ROPE decision making
- Increased data can refute hypotheses with ROPE but with NHST, increased data affirm anything-but-null hypotheses


Figure 1 shows example of interval that excludes null but is within ROPE

Setting ROPE
- 0.1 ES (one half of Cohen's D small effect of 0.2); a fallback convention
- Guided by clinical relevance
- Difficulty in setting ROPE should be kept in light of difficulty establishing threshold for p-value and Bayes Factors

Equal tailed vs HDI
- HDI treats scale as meaningful though are not scale invariant
- Monitoring ROPE without using HDI could lead to counter-intuitive results where, after transformation, the HDI and equal-tail probabilities do not agree. (This looked insightful).

Comparison to Bayes Factor monitoring:
- Motivating example, spike and slab prior can result in HDI that has mx interval segments.
- The mixture prior makes the Bayes Factor meaningless (??), I didn't quite follow this.

References:
- Cox 2006: Confidence interval is range of parameter values not rejected.
- FDA guidance for bioequivalence studies provides ROPE benchmarks},
author = {Kruschke, John K},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Kruschke - 2018 - Rejecting or Accepting Parameter Values in Bayesian Estimation.pdf:pdf},
journal = {Advances in Methods and Practices in Psychological Science},
month = {may},
number = {2},
pages = {270--280},
title = {{Rejecting or Accepting Parameter Values in Bayesian Estimation:}},
volume = {1},
year = {2018}
}
@article{heyd1999adaptive,
author = {Heyd, Julie M and Carlin, Bradley P},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Heyd, Carlin - 1999 - Adaptive design improvements in the continual reassessment method for phase I studies.pdf:pdf},
journal = {Statistics in medicine},
number = {11},
pages = {1307--1321},
publisher = {Wiley Online Library},
title = {{Adaptive design improvements in the continual reassessment method for phase I studies}},
volume = {18},
year = {1999}
}
@article{goodman1995some,
author = {Goodman, Steven N and Zahurak, Marianna L and Piantadosi, Steven},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Goodman, Zahurak, Piantadosi - 1995 - Some practical improvements in the continual reassessment method for phase I studies(2).pdf:pdf},
journal = {Statistics in medicine},
number = {11},
pages = {1149--1161},
publisher = {Wiley Online Library},
title = {{Some practical improvements in the continual reassessment method for phase I studies}},
volume = {14},
year = {1995}
}
@booklet{Berry:2010fr,
author = {Berry, Scott and Carlin, Bradley and Lee, J and M{\"{u}}ller, Peter},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Berry et al. - 2010 - Bayesian Adaptive Methods for Clinical Trials.pdf:pdf},
howpublished = {CRC Press},
title = {{Bayesian Adaptive Methods for Clinical Trials}},
year = {2010}
}
@article{Kruschke:2013jy,
author = {Kruschke, John K},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Kruschke - 2013 - Bayesian estimation supersedes the t test(2).pdf:pdf},
journal = {Journal of experimental psychology. General},
number = {2},
pages = {573--603},
title = {{Bayesian estimation supersedes the t test.}},
volume = {142},
year = {2013}
}
@article{qiao2019clinical,
author = {Qiao, Wei and Ning, Jing and Huang, Xuelin},
file = {::},
journal = {Statistics in biopharmaceutical research},
number = {4},
pages = {336--347},
publisher = {Taylor {\&} Francis},
title = {{A clinical trial design with covariate-adjusted response-adaptive randomization using superiority confidence of treatments}},
volume = {11},
year = {2019}
}
@article{Preacher2011,
abstract = {Strategies for modeling mediation effects in multilevel data have proliferated over the past decade, keeping pace with the demands of applied research. Approaches for testing mediation hypotheses with 2-level clustered data were first proposed using multilevel modeling (MLM) and subsequently using multilevel structural equation modeling (MSEM) to overcome several limitations of MLM. Because 3-level clustered data are becoming increasingly common, it is necessary to develop methods to assess mediation in such data. Whereas MLM easily accommodates 3-level data, MSEM does not. However, it is possible to specify and estimate some 3-level mediation models using both single- and multilevel SEM. Three new alternative approaches are proposed for fitting 3-level mediation models using single- and multilevel SEM, and each method is demonstrated with simulated data. Discussion focuses on the advantages and disadvantages of these approaches as well as directions for future research. {\textcopyright} Taylor {\&} Francis Group, LLC.},
author = {Preacher, Kristopher J.},
doi = {10.1080/00273171.2011.589280},
file = {::},
issn = {00273171},
journal = {Multivariate Behavioral Research},
number = {4},
pages = {691--731},
title = {{Multilevel sem strategies for evaluating mediation in three-level data}},
volume = {46},
year = {2011}
}
@article{Saville2017,
abstract = {Response adaptive randomization (RAR) methods for clinical trials are susceptible to imbalance in the distribution of influential covariates across treatment arms. This can make the interpretation of trial results difficult, because observed differences between treatment groups may be a function of the covariates and not necessarily because of the treatments themselves. We propose a method for balancing the distribution of covariate strata across treatment arms within RAR. The method uses odds ratios to modify global RAR probabilities to obtain stratum-specific modified RAR probabilities. We provide illustrative examples and a simple simulation study to demonstrate the effectiveness of the strategy for maintaining covariate balance. The proposed method is straightforward to implement and applicable to any type of RAR method or outcome.},
annote = {Method addresses the problem that treatment arms may be imbalanced on key covariates.

Steps: 
1. Calculate RAR using any method
2. Adjust RAR by categorized strata so that the probability of being assigned to treatment is tempered by current covariate balance. (I read this as tempering the optimism of a treatment arm -- allowing other treatment arms to show benefit).

Limitation:
1. Requires traditional stratification
2. Paper},
author = {Saville, Benjamin R. and Berry, Scott M.},
doi = {10.1002/pst.1803},
file = {::},
issn = {15391612},
journal = {Pharmaceutical Statistics},
keywords = {Bayesian RAR, clinical trial, covariate balance, i},
number = {3},
pages = {210--217},
pmid = {28261972},
title = {{Balanced covariates with response adaptive randomization}},
volume = {16},
year = {2017}
}
@article{Yuan2011,
abstract = {We propose a Bayesian response-adaptive covariate-balanced (RC) randomization design for multiple-arm comparative clinical trials. The goal of the design is to skew the allocation probability to more efficacious treatment arms, while also balancing the distribution of the covariates across the arms. In particular, we first propose a new covariate-adaptive randomization (CA) method based on a prognostic score that naturally accommodates continuous and categorical prognostic factors and automatically assigns imbalance weights to covariates according to their importance in response prediction. We then incorporate this CA design into a group sequential response-adaptive randomization (RA) scheme. The resulting RC randomization design combines the advantages of both CA and RA randomizations and meets the design goal. We illustrate the proposed design through its application to a phase II leukemia clinical trial, and evaluate its operating characteristics through simulation studies. {\textcopyright} 2011 John Wiley {\&} Sons, Ltd.},
author = {Yuan, Ying and Huang, Xuelin and Liu, Suyu},
doi = {10.1002/sim.4218},
file = {::},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Adaptive randomization,Balance covariates,Prognostic factor,Response-adaptive},
number = {11},
pages = {1218--1229},
pmid = {21432894},
title = {{A Bayesian response-adaptive covariate-balanced randomization design with application to a leukemia clinical trial}},
volume = {30},
year = {2011}
}
@article{liu2021,
abstract = {As diseases like cancer are increasingly understood on a molecular level, clinical trials are being designed to reveal or validate subpopulations in which an experimental therapy has enhanced benefit. Such biomarker-driven designs, particularly “adaptive enrichment” designs that initially enroll an unselected population and then allow for later restriction of accrual to “marker-positive” patients based on interim results, are increasingly popular. Many biomarkers of interest are naturally continuous, however, and most existing design approaches either require upfront dichotomization or force monotonicity through algorithmic searches for a single marker threshold, thereby excluding the possibility that the continuous biomarker has a nondisjoint and truly nonlinear or nonmonotone prognostic relationship with outcome or predictive relationship with treatment effect. To address this, we propose a novel trial design that leverages both the actual shapes of any continuous marker effects (both prognostic and predictive) and their corresponding posterior uncertainty in an adaptive decision-making framework. At interim analyses, this marker knowledge is updated and overall or marker-driven decisions are reached such as continuing enrollment to the next interim analysis or terminating early for efficacy or futility. Using simulations and patient-level data from a multi-center Children's Oncology Group trial in Acute Lymphoblastic Leukemia, we derive the operating characteristics of our design and compare its performance to a traditional approach that identifies and applies a dichotomizing marker threshold.},
author = {Liu, Yusha and Kairalla, John A. and Renfro, Lindsay A.},
doi = {10.1111/biom.13550},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Liu, Kairalla, Renfro - 2021 - Bayesian adaptive trial design for a continuous biomarker with possibly nonlinear or nonmonotone progn(2).pdf:pdf},
issn = {15410420},
journal = {Biometrics},
keywords = {Bayesian adaptive design,adaptive enrichment,biomarker-driven design,continuous biomarkers,precision medicine},
number = {July},
pages = {1--13},
title = {{Bayesian adaptive trial design for a continuous biomarker with possibly nonlinear or nonmonotone prognostic or predictive effects}},
year = {2021}
}
@article{viele2020comparison,
author = {Viele, Kert and Broglio, Kristine and McGlothlin, Anna and Saville, Benjamin R},
file = {::},
journal = {Clinical Trials},
number = {1},
pages = {52--60},
publisher = {SAGE Publications Sage UK: London, England},
title = {{Comparison of methods for control allocation in multiple arm studies using response adaptive randomization}},
volume = {17},
year = {2020}
}
@article{saville2017balanced,
author = {Saville, Benjamin R and Berry, Scott M},
file = {::},
journal = {Pharmaceutical Statistics},
number = {3},
pages = {210--217},
publisher = {Wiley Online Library},
title = {{Balanced covariates with response adaptive randomization}},
volume = {16},
year = {2017}
}
@article{wang2020randomization,
author = {Wang, Yanying and Rosenberger, William F and Uschner, Diane},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Wang, Rosenberger, Uschner - 2020 - Randomization tests for multiarmed randomized clinical trials.pdf:pdf},
journal = {Statistics in Medicine},
number = {4},
pages = {494--509},
publisher = {Wiley Online Library},
title = {{Randomization tests for multiarmed randomized clinical trials}},
volume = {39},
year = {2020}
}
@article{hansen2014clustered,
author = {Hansen, Ben B and Rosenbaum, Paul R and Small, Dylan S},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Hansen, Rosenbaum, Small - 2014 - Clustered treatment assignments and sensitivity to unmeasured biases in observational studies(2).pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {505},
pages = {133--144},
publisher = {Taylor {\&} Francis},
title = {{Clustered treatment assignments and sensitivity to unmeasured biases in observational studies}},
volume = {109},
year = {2014}
}
@article{stuart2010matching,
author = {Stuart, Elizabeth A},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Stuart - 2010 - Matching methods for causal inference A review and a look forward.pdf:pdf},
journal = {Statistical science: a review journal of the Institute of Mathematical Statistics},
number = {1},
pages = {1},
publisher = {NIH Public Access},
title = {{Matching methods for causal inference: A review and a look forward}},
volume = {25},
year = {2010}
}
@article{Society2008,
abstract = {Matching estimators are widely used in empirical economics for the evaluation of programs or treatments. Researchers using matching methods often apply the bootstrap to calculate the standard errors. However, no formal justification has been provided for the use of the bootstrap in this setting. In this article, we show that the standard bootstrap is, in general, not valid for matching estimators, even in the simple case with a single continuous covariate where the estimator is root-N consistent and asymptotically normally distributed with zero asymptotic bias. Valid inferential methods in this setting are the analytic asymptotic variance estimator of Abadie and Imbens (2006a) as well as certain modifications of the standard bootstrap, like the subsampling methods in Politis and Romano (1994).},
author = {Society, The Econometric},
doi = {10.3982/ecta6474},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Society - 2008 - On the Failure of the Bootstrap for Matching Estimators.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
number = {6},
pages = {1537--1557},
title = {{On the Failure of the Bootstrap for Matching Estimators}},
volume = {76},
year = {2008}
}
@article{Freedman:1984wz,
author = {Freedman, L S and Lowe, D and Macaskill, P},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Freedman, Lowe, Macaskill - 1984 - Stopping rules for clinical trials incorporating clinical opinion(2).pdf:pdf},
journal = {Biometrics},
month = {sep},
number = {3},
pages = {575--586},
title = {{Stopping rules for clinical trials incorporating clinical opinion.}},
volume = {40},
year = {1984}
}
@article{Zeng2021,
abstract = {Chance imbalance in baseline characteristics is common in randomized clinical trials. Regression adjustment such as the analysis of covariance (ANCOVA) is often used to account for imbalance and increase precision of the treatment effect estimate. An objective alternative is through inverse probability weighting (IPW) of the propensity scores. Although IPW and ANCOVA are asymptotically equivalent, the former may demonstrate inferior performance in finite samples. In this article, we point out that IPW is a special case of the general class of balancing weights, and advocate to use overlap weighting (OW) for covariate adjustment. The OW method has a unique advantage of completely removing chance imbalance when the propensity score is estimated by logistic regression. We show that the OW estimator attains the same semiparametric variance lower bound as the most efficient ANCOVA estimator and the IPW estimator for a continuous outcome, and derive closed-form variance estimators for OW when estimating additive and ratio estimands. Through extensive simulations, we demonstrate OW consistently outperforms IPW in finite samples and improves the efficiency over ANCOVA and augmented IPW when the degree of treatment effect heterogeneity is moderate or when the outcome model is incorrectly specified. We apply the proposed OW estimator to the Best Apnea Interventions for Research (BestAIR) randomized trial to evaluate the effect of continuous positive airway pressure on patient health outcomes. All the discussed propensity score weighting methods are implemented in the R package PSweight.},
archivePrefix = {arXiv},
arxivId = {2004.10075},
author = {Zeng, Shuxi and Li, Fan and Wang, Rui and Li, Fan},
doi = {10.1002/sim.8805},
eprint = {2004.10075},
file = {::},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {analysis of covariance,covariate balance,inverse probability weighting,overlap weighting,randomized controlled trials,variance reduction},
number = {4},
pages = {842--858},
pmid = {33174296},
title = {{Propensity score weighting for covariate adjustment in randomized clinical trials}},
volume = {40},
year = {2021}
}
@article{iacus2012causal,
author = {Iacus, Stefano M and King, Gary and Porro, Giuseppe},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Iacus, King, Porro - 2012 - Causal inference without balance checking Coarsened exact matching.pdf:pdf},
journal = {Political analysis},
number = {1},
pages = {1--24},
publisher = {Cambridge University Press},
title = {{Causal inference without balance checking: Coarsened exact matching}},
volume = {20},
year = {2012}
}
@article{austin2014use,
author = {Austin, Peter C and Small, Dylan S},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Austin, Small - 2014 - The use of bootstrapping when using propensity-score matching without replacement a simulation study.pdf:pdf},
journal = {Statistics in medicine},
number = {24},
pages = {4306--4319},
publisher = {Wiley Online Library},
title = {{The use of bootstrapping when using propensity-score matching without replacement: a simulation study}},
volume = {33},
year = {2014}
}
@article{jennison1989interim,
author = {Jennison, Christopher and Turnbull, Bruce W},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Jennison, Turnbull - 1989 - Interim analyses the repeated confidence interval approach.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
number = {3},
pages = {305--334},
publisher = {Wiley Online Library},
title = {{Interim analyses: the repeated confidence interval approach}},
volume = {51},
year = {1989}
}
@article{Villar2015a,
abstract = {The Gittins index provides a well established, computationally attractive, optimal solution to a class of resource allocation problems known collectively as the multi-arm bandit problem. Its development was originally motivated by the problem of optimal patient allocation in multi-arm clinical trials. However, it has never been used in practice, possibly for the following reasons: (1) it is fully sequential, i.e., the endpoint must be observable soon after treating a patient, reducing the medical settings to which it is applicable; (2) it is completely deterministic and thus removes randomization from the trial, which would naturally protect against various sources of bias. We propose a novel implementation of the Gittins index rule that overcomes these difficulties, trading off a small deviation from optimality for a fully randomized, adaptive group allocation procedure which offers substantial improvements in terms of patient benefit, especially relevant for small populations. We report the operating characteristics of our approach compared to existing methods of adaptive randomization using a recently published trial as motivation.},
author = {Villar, Sof{\'{i}}a S. and Wason, James and Bowden, Jack},
doi = {10.1111/biom.12337},
file = {::},
issn = {15410420},
journal = {Biometrics},
keywords = {Bayesian adaptive designs,Clinical trials,Gittins index,Multi-armed bandit,Sequential allocation},
number = {4},
pages = {969--978},
pmid = {26098023},
title = {{Response-adaptive randomization for multi-arm clinical trials using the forward looking Gittins index rule}},
volume = {71},
year = {2015}
}
@article{Wheeler2019,
abstract = {The continual reassessment method (CRM) is a model-based design for phase I trials, which aims to find the maximum tolerated dose (MTD) of a new therapy. The CRM has been shown to be more accurate in targeting the MTD than traditional rule-based approaches such as the 3 + 3 design, which is used in most phase I trials. Furthermore, the CRM has been shown to assign more trial participants at or close to the MTD than the 3 + 3 design. However, the CRM's uptake in clinical research has been incredibly slow, putting trial participants, drug development and patients at risk. Barriers to increasing the use of the CRM have been identified, most notably a lack of knowledge amongst clinicians and statisticians on how to apply new designs in practice. No recent tutorial, guidelines, or recommendations for clinicians on conducting dose-finding studies using the CRM are available. Furthermore, practical resources to support clinicians considering the CRM for their trials are scarce. To help overcome these barriers, we present a structured framework for designing a dose-finding study using the CRM. We give recommendations for key design parameters and advise on conducting pre-trial simulation work to tailor the design to a specific trial. We provide practical tools to support clinicians and statisticians, including software recommendations, and template text and tables that can be edited and inserted into a trial protocol. We also give guidance on how to conduct and report dose-finding studies using the CRM. An initial set of design recommendations are provided to kick-start the design process. To complement these and the additional resources, we describe two published dose-finding trials that used the CRM. We discuss their designs, how they were conducted and analysed, and compare them to what would have happened under a 3 + 3 design. The framework and resources we provide are aimed at clinicians and statisticians new to the CRM design. Provision of key resources in this contemporary guidance paper will hopefully improve the uptake of the CRM in phase I dose-finding trials.},
author = {Wheeler, Graham M. and Mander, Adrian P. and Bedding, Alun and Brock, Kristian and Cornelius, Victoria and Grieve, Andrew P. and Jaki, Thomas and Love, Sharon B. and Odondi, Lang'O and Weir, Christopher J. and Yap, Christina and Bond, Simon J.},
file = {::},
issn = {14712288},
journal = {BMC Medical Research Methodology},
keywords = {Adaptive designs,Continual reassessment method,Dose escalation,Dose-finding,Maximum tolerated dose,Phase I trials},
number = {1},
pages = {1--15},
publisher = {BMC Medical Research Methodology},
title = {{Design a dose-finding study}},
volume = {19},
year = {2019}
}
@article{Yuan2016,
abstract = {Despite more than two decades of publications that offer more innovative model-based designs, the classical 3 +3 design remains the most dominant phase I trial design in practice. In this article, we introduce a new trial design, the Bayesian optimal interval (BOIN) design. The BOIN design is easy to implement in a way similar to the 3 + 3 design, but is more flexible for choosing the target toxicity rate and cohort size and yields a substantially better performance that is comparable with that of more complex model-based designs. The BOIN design contains the 3 + 3 design and the accelerated titration design as special cases, thus linking itto established phase I approaches. A numerical study shows that the BOIN design generally outperforms the 3 + 3 design and the modified toxicity probability interval (mTPI) design. The BOIN design is more likely than the 3 + 3 design to correctly select the MTD and allocate more patients to the MTD. Compared with the mTPI design, the BOIN design has a substantially lower risk of overdosing patients and generally a higher probability of correctly selecting the MTD. User-friendly software is freely available to facilitate the application of the BOIN design.},
author = {Yuan, Ying and Hess, Kenneth R. and Hilsenbeck, Susan G. and Gilbert, Mark R.},
doi = {10.1158/1078-0432.CCR-16-0592},
file = {::},
issn = {15573265},
journal = {Clinical Cancer Research},
number = {17},
pages = {4291--4301},
pmid = {27407096},
title = {{Bayesian optimal interval design: A simple and well-performing design for phase i oncology trials}},
volume = {22},
year = {2016}
}
@article{kruschke2011bayesian,
abstract = {Psychologists have been trained to do data analysis by asking whether null values can be rejected. Is the difference between groups nonzero? Is choice accuracy not at chance level? These questions have been traditionally addressed by null hypothesis significance testing (NHST). NHST has deep problems that are solved by Bayesian data analysis. As psychologists transition to Bayesian data analysis, it is natural to ask how Bayesian analysis assesses null values. The article explains and evaluates two different Bayesian approaches. One method involves Bayesian model comparison (and uses Bayes factors). The second method involves Bayesian parameter estimation and assesses whether the null value falls among the most credible values. Which method to use depends on the specific question that the analyst wants to answer, but typically the estimation approach (not using Bayes factors) provides richer information than the model comparison approach. {\textcopyright} The Author(s) 2011.},
author = {Kruschke, John K.},
doi = {10.1177/1745691611406925},
file = {::},
issn = {17456924},
journal = {Perspectives on Psychological Science},
keywords = {Bayes,Model comparison,Parameter estimation},
number = {3},
pages = {299--312},
publisher = {Sage Publications Sage CA: Los Angeles, CA},
title = {{Bayesian assessment of null values via parameter estimation and model comparison}},
volume = {6},
year = {2011}
}
@article{chipman2023,
abstract = {Covariate-adjusted randomization (CAR) can reduce the risk of covariate imbalance and, when accounted for in analysis, increase the power of a trial. Despite CAR advances, stratified randomization remains the most common CAR method. Matched randomization (MR) randomizes treatment assignment within optimally identified matched pairs based on covariates and a distance matrix. When participants enroll sequentially, sequentially matched randomization (SMR) randomizes within matches found "on-the-fly" to meet a pre-specified matching threshold. However, pre-specifying the ideal threshold can be challenging and SMR yields less-optimal matches than MR. We extend SMR to allow multiple participants to be randomized simultaneously, to use a dynamic threshold, and to allow matches to break and rematch if a better match later enrolls (sequential rematched randomization; SRR). In simplified settings and a real-world application, we assess whether these extensions improve covariate balance, estimator/study efficiency, and optimality of matches. We investigate whether adjusting for more covariates can be detrimental upon covariate balance and efficiency as is the case of traditional stratified randomization. As secondary objectives, we use the case study to assess how SMR schemes compare side-by-side with common and related CAR schemes and whether adjusting for covariates in the design can be as powerful as adjusting for covariates in a parametric model. We find each SMR extension, individually and collectively, to improve covariate balance, estimator efficiency, study power, and quality of matches. We provide a case-study where CAR schemes with randomization-based inference can be as and more powerful than non-CAR schemes with parametric adjustment for covariates.},
author = {Chipman, Jonathan J and Mayberry, Lindsay and Greevy, Robert A Jr},
doi = {10.1002/sim.9843},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Chipman, Mayberry, Greevy - 2023 - Rematching on-the-fly Sequential matched randomization and a case for covariate-adjusted randomizatio.pdf:pdf},
issn = {1097-0258 (Electronic)},
journal = {Statistics in medicine},
keywords = {Computer Simulation,Random Allocation,Research Design},
language = {eng},
month = {sep},
number = {22},
pages = {3981--3995},
pmid = {37439157},
title = {{Rematching on-the-fly: Sequential matched randomization and a case for covariate-adjusted randomization.}},
volume = {42},
year = {2023}
}
@article{fda2023adjusting,
abstract = {This guidance describes FDA's current recommendations regarding adjusting for covariates in the statistical analysis of randomized clinical trials in drug development programs. This guidance provides recommendations for the use of covariates in the analysis of randomized, parallel group clinical trials that are applicable to both superiority trials and noninferiority trials. The main focus of the guidance is on the use of prognostic baseline covariates to improve statistical efficiency for estimating and testing treatment effects. This guidance does not address use of covariates to control for confounding variables in non-randomized trials, the use of covariates in models to account for missing outcome data (National Research Council 2010), the use of covariate adjustment for analyzing longitudinal repeated measures data, the use of Bayesian methods for covariate adjustment, or the use of machine learning methods for covariate adjustment.},
author = {{U.S. Department of Health and Human Services Food and Drug Administration}},
file = {::},
journal = {Guidance Document},
keywords = {Adjusting for Covariates,Biostatistics,Statistical Efficiency},
number = {May},
title = {{Adjusting for Covariates in Randomized Clinical Trials for Drugs and Biological Products}},
url = {https://www.fda.gov/regulatory-information/search-fda-guidance-documents/adjusting-covariates-randomized-clinical-trials-drugs-and-biological-products},
year = {2023}
}
@article{paik2008development,
abstract = {Several multigene markers that predict relapse more accurately than classical clinicopathologic features have been developed. The 21-gene assay was developed specifically for patients with estrogen receptor (ER)-positive breast cancer, and has been shown to predict distant recurrence more accurately that classical clinicopathologic features in patients with ER-positive breast cancer and negative axillary nodes treated with adjuvant tamoxifen; validation studies in this population led to its approval as a diagnostic test. In a similar population, it also may be used to assess the benefit of adding chemotherapy to hormonal therapy. Other validation studies indicate that it also predicts the risk of distant and local recurrence in other populations with ER-positive disease, including node-negative patients receiving no adjuvant therapy and patients with positive axillary nodes treated with doxorubicin-containing chemotherapy. The Trial Assigning Individualized Options for Treatment (TAILORx) is multicenter trial that integrates the 21-gene assay into the clinical decision-making process and is designed to refine the utility of the assay in clinical practice and to provide a resource for evaluating additional molecular markers as they are developed in the future. {\textcopyright} 2008 by American Society of Clinical Oncology.},
author = {Sparano, Joseph A. and Paik, Soonmyung},
doi = {10.1200/JCO.2007.15.1068},
file = {::},
issn = {0732183X},
journal = {Journal of Clinical Oncology},
number = {5},
pages = {721--728},
pmid = {18258979},
title = {{Development of the 21-gene assay and its application in clinical practice and clinical trials}},
volume = {26},
year = {2008}
}
@article{Stallard2022,
abstract = {A popular design for clinical trials assessing targeted therapies is the two-stage adaptive enrichment design with recruitment in stage 2 limited to a biomarker-defined subgroup chosen based on data from stage 1. The data-dependent selection leads to statistical challenges if data from both stages are used to draw inference on treatment effects in the selected subgroup. If subgroups considered are nested, as when defined by a continuous biomarker, treatment effect estimates in different subgroups follow the same distribution as estimates in a group-sequential trial. This result is used to obtain tests controlling the familywise type I error rate (FWER) for six simple subgroup selection rules, one of which also controls the FWER for any selection rule. Two approaches are proposed: one based on multivariate normal distributions suitable if the number of possible subgroups, k, is small, and one based on Brownian motion approximations suitable for large k. The methods, applicable in the wide range of settings with asymptotically normal test statistics, are illustrated using survival data from a breast cancer trial.},
author = {Stallard, Nigel},
doi = {10.1111/biom.13644},
file = {::},
issn = {15410420},
journal = {Biometrics},
keywords = {multiple cut-points,sequential analysis,stratified medicine clinical trial design,subgroup selection},
number = {April 2021},
pages = {1--11},
title = {{Adaptive enrichment designs with a continuous biomarker}},
year = {2022}
}
@article{Rosenberger2019,
abstract = {“{\ldots}The customary test for an observed difference{\ldots}is based on an enumeration of the probabilities, on the initial hypothesis that two treatments do not differ in their effects,{\ldots}of all the various results which would occur if the trial were repeated indefinitely with different random samples of the same size as those actually used.” –Peter Armitage (“Sequential tests in prophylactic and therapeutic trials” in Quarterly Journal of Medicine, 1954;23(91):255-274). Randomization has been the hallmark of the clinical trial since Sir Bradford Hill adopted it in the 1946 streptomycin trial. An exploration of the early literature yields three rationales, ie, (i) the incorporation of randomization provides unpredictability in treatment assignments, thereby mitigating selection bias; (ii) randomization tends to ensure similarity in the treatment groups on known and unknown confounders (at least asymptotically); and (iii) the act of randomization itself provides a basis for inference when random sampling is not conducted from a population model. Of these three, rationale (iii) is often forgotten, ignored, or left untaught. Today, randomization is a rote exercise, scarcely considered in protocols or medical journal articles. Yet, the literature of the last century is rich with statistical articles on randomization methods and their consequences, authored by some of the pioneers of the biostatistics and statistics world. In this paper, we review some of this literature and describe very simple methods to rectify some of the oversight. We describe how randomization-based inference can be used for virtually any outcome of interest in a clinical trial. Special mention is made of nonstandard clinical trials situations.},
author = {Rosenberger, William F. and Uschner, Diane and Wang, Yanying},
doi = {10.1002/sim.7901},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Rosenberger, Uschner, Wang - 2019 - Randomization The forgotten component of the randomized clinical trial.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {history of randomization,randomization as a basis for inference,randomization tests},
number = {1},
pages = {1--12},
pmid = {30047159},
title = {{Randomization: The forgotten component of the randomized clinical trial}},
volume = {38},
year = {2019}
}
@article{Williamson2014,
author = {Williamson, Elizabeth J and White, Ian R},
doi = {10.1002/sim.5991},
file = {::;::},
keywords = {baseline adjustment,variance estimation},
number = {September 2013},
title = {{Variance reduction in randomised trials by inverse probability weighting using the propensity score}},
year = {2014}
}
@article{steingrimsson2017improving,
author = {Steingrimsson, Jon Arni and Hanley, Daniel F and Rosenblum, Michael},
file = {::},
journal = {Contemporary clinical trials},
pages = {18--24},
publisher = {Elsevier},
title = {{Improving precision by adjusting for prognostic baseline variables in randomized trials with binary outcomes, without regression model assumptions}},
volume = {54},
year = {2017}
}
@article{Gil2019,
author = {Gil, Karen M and Pugh, Stephanie L and Klopp, Ann H and Yeung, Anamaria R and Wenzel, Lari and Westin, Shannon N and Gaffney, David K and Small, William and Thompson, Spencer and Doncals, Desiree E and Cantuaria, Guilherme H C and Yaremko, Brian P and Chang, Amy and Kundapur, Vijayananda and Mohan, Dasarahally S and Haas, Michael L and Bae, Yong and Ferguson, Catherine L and Deshmukh, Snehal and Kachnic, Lisa A and Bruner, Deborah W},
doi = {10.1016/j.ygyno.2019.04.682},
file = {::},
issn = {0090-8258},
journal = {Gynecologic Oncology},
keywords = {Bowel and urinary toxicity,Cervical and endometrial cancer,Patient reported outcomes,Pelvic radiation,bowel and urinary toxicity},
number = {1},
pages = {183--188},
publisher = {Elsevier Inc.},
title = {{Gynecologic Oncology Expanded validation of the EPIC bowel and urinary domains for use in women with gynecologic cancer undergoing postoperative radiotherapy ☆}},
url = {https://doi.org/10.1016/j.ygyno.2019.04.682},
volume = {154},
year = {2019}
}
@article{Rosenbaum2002a,
abstract = {By slightly reframing the concept of covariance adjustment in randomized experiments, a method of exact permutation inference is derived that is entirely free of distributional assumptions and uses the random assignment of treatments as the "reasoned basis for inference." This method of exact permutation inference may be used with many forms of covariance adjustment, including robust regression and locally weighted smoothers. The method is then generalized to observational studies where treatments were not randomly assigned, so that sensitivity to hidden biases must be examined. Adjustments using an instrumental variable are also discussed. The methods are illustrated using data from two observational studies.},
author = {Rosenbaum, Paul R.},
doi = {10.1214/ss/1042727942},
file = {::},
issn = {08834237},
journal = {Statistical Science},
keywords = {Covariance adjustment,Matching,Observational studies,Permutation inference,Propensity score,Randomization inference,Sensitivity analysis},
number = {3},
pages = {286--327},
title = {{Covariance adjustment in randomized experiments and observational studies}},
volume = {17},
year = {2002}
}
@article{Liu2015,
abstract = {Our increasing knowledge of biomedicine and genomics for human malignancies has placed us within reach of achieving personalized cancer medicine. The Biomarker-integrated Approaches of Targeted Therapy for Lung Cancer Elimination (BATTLE)-1 trial was the first completed, prospective biopsy-mandated, biomarker-based, adaptive randomized clinical trial for patients with advanced non-small cell lung cancer (NSCLC). The ongoing BATTLE-2 trial continues to search for effective targeted therapies by further refining the clinical trial design. The BATTLE program has demonstrated the feasibility and promise of novel biomarker-based clinical trial platforms, which has moved us one step closer to personalized medicine. In this paper, we describe the design and conduct of the BATTLE trials, summarize the main findings, and report the experiences and lessons learned from our pursuit of developing targeted therapies in cancer.},
author = {Liu, Suyu and Lee, J. Jack},
doi = {10.3978/j.issn.2304-3865.2015.06.07},
file = {::},
issn = {23043873},
journal = {Chinese Clinical Oncology},
keywords = {Bayesian adaptive designs,Personalized medicine,Predictive biomarkers,Targeted therapies},
number = {3},
pages = {1--13},
pmid = {26408300},
title = {{An overview of the design and conduct of the BATTLE trials}},
volume = {4},
year = {2015}
}
@article{Sparano2018,
abstract = {BACKGROUND The recurrence score based on the 21-gene breast cancer assay predicts chemotherapy benefit if it is high and a low risk of recurrence in the absence of chemotherapy if it is low; however, there is uncertainty about the benefit of chemotherapy for most patients, who have a midrange score. METHODS We performed a prospective trial involving 10,273 women with hormone-receptor-positive, human epidermal growth factor receptor 2 (HER2)-negative, axillary node-negative breast cancer. Of the 9719 eligible patients with follow-up information, 6711 (69{\%}) had a midrange recurrence score of 11 to 25 and were randomly assigned to receive either chemoendocrine therapy or endocrine therapy alone. The trial was designed to show noninferiority of endocrine therapy alone for invasive disease-free survival (defined as freedom from invasive disease recurrence, second primary cancer, or death). RESULTS Endocrine therapy was noninferior to chemoendocrine therapy in the analysis of invasive disease-free survival (hazard ratio for invasive disease recurrence, second primary cancer, or death [endocrine vs. chemoendocrine therapy], 1.08; 95{\%} confidence interval, 0.94 to 1.24; P=0.26). At 9 years, the two treatment groups had similar rates of invasive disease-free survival (83.3{\%} in the endocrine-therapy group and 84.3{\%} in the chemoendocrine-therapy group), freedom from disease recurrence at a distant site (94.5{\%} and 95.0{\%}) or at a distant or local-regional site (92.2{\%} and 92.9{\%}), and overall survival (93.9{\%} and 93.8{\%}). The chemotherapy benefit for invasive disease-free survival varied with the combination of recurrence score and age (P=0.004), with some benefit of chemotherapy found in women 50 years of age or younger with a recurrence score of 16 to 25. CONCLUSIONS Adjuvant endocrine therapy and chemoendocrine therapy had similar efficacy in women with hormone-receptor-positive, HER2-negative, axillary node-negative breast cancer who had a midrange 21-gene recurrence score, although some benefit of chemotherapy was found in some women 50 years of age or younger. (Funded by the National Cancer Institute and others; TAILORx ClinicalTrials.gov number, NCT00310180 .).},
author = {Sparano, Joseph A. and Gray, Robert J. and Makower, Della F. and Pritchard, Kathleen I. and Albain, Kathy S. and Hayes, Daniel F. and Geyer, Charles E. and Dees, Elizabeth C. and Goetz, Matthew P. and Olson, John A. and Lively, Tracy and Badve, Sunil S. and Saphner, Thomas J. and Wagner, Lynne I. and Whelan, Timothy J. and Ellis, Matthew J. and Paik, Soonmyung and Wood, William C. and Ravdin, Peter M. and Keane, Maccon M. and {Gomez Moreno}, Henry L. and Reddy, Pavan S. and Goggins, Timothy F. and Mayer, Ingrid A. and Brufsky, Adam M. and Toppmeyer, Deborah L. and Kaklamani, Virginia G. and Berenberg, Jeffrey L. and Abrams, Jeffrey and Sledge, George W.},
doi = {10.1056/nejmoa1804710},
file = {::},
issn = {0028-4793},
journal = {New England Journal of Medicine},
number = {2},
pages = {111--121},
pmid = {29860917},
title = {{Adjuvant Chemotherapy Guided by a 21-Gene Expression Assay in Breast Cancer}},
volume = {379},
year = {2018}
}
@article{Paik2006,
abstract = {Purpose: The 21-gene recurrence score (RS) assay quantifies the likelihood of distant recurrence in women with estrogen receptor-positive, lymph node-negative breast cancer treated with adjuvant tamoxifen. The relationship between the RS and chemotherapy benefit is not known. Methods: The RS was measured in tumors from the tamoxifen-treated and tamoxifen plus chemotherapy-treated patients in the National Surgical Adjuvant Breast and Bowel Project (NSABP) B20 trial. Cox proportional hazards models were utilized to test for interaction between chemotherapy treatment and the RS. Results: A total of 651 patients were assessable (227 randomly assigned to tamoxifen and 424 randomly assigned to tamoxifen plus chemotherapy). The test for interaction between chemotherapy treatment and RS was statistically significant (P = .038). Patients with high-RS (≥ 31) tumors (ie, high risk of recurrence) had a large benefit from chemotherapy (relative risk, 0.26; 95{\%} CI, 0.13 to 0.53; absolute decrease in 10-year distant recurrence rate: mean, 27.6{\%}; SE, 8.0{\%}). Patients with low-RS ({\textless} 18) tumors derived minimal, if any, benefit from chemotherapy treatment (relative risk, 1.31; 95{\%} CI, 0.46 to 3.78; absolute decrease in distant recurrence rate at 10 years: mean, -1.1 {\%}; SE, 2.2{\%}). Patients with intermediate-RS tumors did not appear to have a large benefit, but the uncertainty in the estimate can not exclude a clinically important benefit. Conclusion: The RS assay not only quantifies the likelihood of breast cancer recurrence in women with node-negative, estrogen receptor-positive breast cancer, but also predicts the magnitude of chemotherapy benefit. {\textcopyright} 2006 by American Society of Clinical Oncology.},
author = {Paik, Soonmyung and Tang, Gong and Shak, Steven and Kim, Chungyeul and Baker, Joffre and Kim, Wanseop and Cronin, Maureen and Baehner, Frederick L. and Watson, Drew and Bryant, John and Costantino, Joseph P. and Geyer, Charles E. and Wickerham, D. Lawrence and Wolmark, Norman},
doi = {10.1200/JCO.2005.04.7985},
file = {::},
issn = {0732183X},
journal = {Journal of Clinical Oncology},
number = {23},
pages = {3726--3734},
pmid = {16720680},
title = {{Gene expression and benefit of chemotherapy in women with node-negative, estrogen receptor-positive breast cancer}},
volume = {24},
year = {2006}
}
@article{dancey2010guidelines,
author = {Dancey, Janet E and Dobbin, Kevin K and Groshen, Susan and Jessup, J Milburn and Hruszkewycz, Andrew H and Koehler, Maria and Parchment, Ralph and Ratain, Mark J and Shankar, Lalitha K and Stadler, Walter M and Others},
file = {::},
journal = {Clinical cancer research},
number = {6},
pages = {1745--1755},
publisher = {AACR},
title = {{Guidelines for the development and incorporation of biomarker studies in early clinical trials of novel agents}},
volume = {16},
year = {2010}
}
@article{Woodcock2017,
abstract = {Master protocols come in different sizes and shapes but share many commonalities. All require increased planning efforts and coordination to satisfy the objectives of different stakeholders. Innovative design elements help ensure that maximum information is obtained from the research effort, and the infrastructure required for implementation increases data quality and trial efficiencies, as compared with those in stand-alone trials. If designed correctly, master protocols can last many years, even decades, with innovations from the laboratory translating quickly to clinical evaluation. As the targets for new drugs become more and more precise, there is no alternative but to move forward with these coordinated research efforts.},
author = {Woodcock, Janet and LaVange, Lisa M.},
doi = {10.1056/nejmra1510062},
file = {::},
issn = {0028-4793},
journal = {New England Journal of Medicine},
number = {1},
pages = {62--70},
pmid = {28679092},
title = {{Master Protocols to Study Multiple Therapies, Multiple Diseases, or Both}},
volume = {377},
year = {2017}
}
@article{FoodandDrugAdministration2021,
author = {{Food and Drug Administration}},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Food and Drug Administration - 2021 - E9(R1) Statistical Principles for Clinical Trials Addendum Estimands and Sensitivity Analysis in C.pdf:pdf},
journal = {Federal Register},
number = {May},
pages = {26047--26048},
title = {{E9(R1) Statistical Principles for Clinical Trials: Addendum: Estimands and Sensitivity Analysis in Clinical Trials. International Council for Harmonisation. Guidance for Industry.}},
volume = {86 FR 2604},
year = {2021}
}
@article{hu2019biomarker,
author = {Hu, Chen and Dignam, James J},
file = {::},
journal = {JCO Precision Oncology},
pages = {1--12},
publisher = {American Society of Clinical Oncology},
title = {{Biomarker-driven oncology clinical trials: Key design elements, types, features, and practical considerations}},
volume = {1},
year = {2019}
}
@article{Sparano2015,
abstract = {{\textcopyright} 2015 Massachusetts Medical Society. All rights reserved. Background Prior studies with the use of a prospective-retrospective design including archival tumor samples have shown that gene-expression assays provide clinically useful prognostic information. However, a prospectively conducted study in a uniformly treated population provides the highest level of evidence supporting the clinical validity and usefulness of a biomarker. Methods We performed a prospective trial involving women with hormone-receptor-positive, human epidermal growth factor receptor type 2 (HER2)-negative, axillary node-negative breast cancer with tumors of 1.1 to 5.0 cm in the greatest dimension (or 0.6 to 1.0 cm in the greatest dimension and intermediate or high tumor grade) who met established guidelines for the consideration of adjuvant chemotherapy on the basis of clinicopathologic features. A reverse-transcriptase-polymerase-chain-reaction assay of 21 genes was performed on the paraffin-embedded tumor tissue, and the results were used to calculate a score indicating the risk of breast-cancer recurrence; patients were assigned to receive endocrine therapy without chemotherapy if they had a recurrence score of 0 to 10, indicating a very low risk of recurrence (on a scale of 0 to 100, with higher scores indicating a greater risk of recurrence). Results Of the 10,253 eligible women enrolled, 1626 women (15.9{\%}) who had a recurrence score of 0 to 10 were assigned to receive endocrine therapy alone without chemotherapy. At 5 years, in this patient population, the rate of invasive disease-free survival was 93.8{\%} (95{\%} confidence interval [CI], 92.4 to 94.9), the rate of freedom from recurrence of breast cancer at a distant site was 99.3{\%} (95{\%} CI, 98.7 to 99.6), the rate of freedom from recurrence of breast cancer at a distant or local-regional site was 98.7{\%} (95{\%} CI, 97.9 to 99.2), and the rate of overall survival was 98.0{\%} (95{\%} CI, 97.1 to 98.6). Conclusions Among patients with hormone-receptor-positive, HER2-negative, axillary node-negative breast cancer who met established guidelines for the recommendation of adjuvant chemotherapy on the basis of clinicopathologic features, those with tumors that had a favorable gene-expression profile had very low rates of recurrence at 5 years with endocrine therapy alone.},
author = {Sparano, Joseph A. and Gray, Robert J. and Makower, Della F. and Pritchard, Kathleen I. and Albain, Kathy S. and Hayes, Daniel F. and Geyer, Charles E. and Dees, Elizabeth C. and Perez, Edith A. and Olson, John A. and Zujewski, JoAnne and Lively, Tracy and Badve, Sunil S. and Saphner, Thomas J. and Wagner, Lynne I. and Whelan, Timothy J. and Ellis, Matthew J. and Paik, Soonmyung and Wood, William C. and Ravdin, Peter and Keane, Maccon M. and {Gomez Moreno}, Henry L. and Reddy, Pavan S. and Goggins, Timothy F. and Mayer, Ingrid A. and Brufsky, Adam M. and Toppmeyer, Deborah L. and Kaklamani, Virginia G. and Atkins, James N. and Berenberg, Jeffrey L. and Sledge, George W.},
doi = {10.1056/nejmoa1510764},
file = {::},
issn = {0028-4793},
journal = {New England Journal of Medicine},
number = {21},
pages = {2005--2014},
pmid = {26412349},
title = {{Prospective Validation of a 21-Gene Expression Assay in Breast Cancer}},
volume = {373},
year = {2015}
}
@article{stuart2008estimating,
author = {Stuart, Elizabeth A and Perry, Deborah F and Le, Huynh-Nhu and Ialongo, Nicholas S},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Stuart et al. - 2008 - Estimating intervention effects of prevention programs Accounting for noncompliance.pdf:pdf},
journal = {Prevention Science},
pages = {288--298},
publisher = {Springer},
title = {{Estimating intervention effects of prevention programs: Accounting for noncompliance}},
volume = {9},
year = {2008}
}
@article{lavange2019statistics,
author = {LaVange, Lisa M},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/LaVange - 2019 - Statistics at FDA Reflections on the past six years(2).pdf:pdf},
journal = {Statistics in Biopharmaceutical Research},
number = {1},
pages = {1--12},
publisher = {Taylor {\&} Francis},
title = {{Statistics at FDA: Reflections on the past six years}},
volume = {11},
year = {2019}
}
@article{demets1994interim,
author = {Demets, David L and Lan, K K Gordon},
file = {::},
journal = {Statistics in medicine},
number = {13-14},
pages = {1341--1352},
publisher = {Wiley Online Library},
title = {{Interim analysis: the alpha spending function approach}},
volume = {13},
year = {1994}
}
@article{lan1993sequential,
author = {Lan, K K Gordon and Zucker, David M},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Lan, Zucker - 1993 - Sequential monitoring of clinical trials the role of information and Brownian motion(2).pdf:pdf},
journal = {Statistics in Medicine},
number = {8},
pages = {753--765},
publisher = {Wiley Online Library},
title = {{Sequential monitoring of clinical trials: the role of information and Brownian motion}},
volume = {12},
year = {1993}
}
@article{scharfstein1997semiparametric,
author = {Scharfstein, Daniel O and Tsiatis, Anastasios A and Robins, James M},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Scharfstein, Tsiatis, Robins - 1997 - Semiparametric efficiency and its implication on the design and analysis of group-sequential st(2).pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {440},
pages = {1342--1350},
publisher = {Taylor {\&} Francis},
title = {{Semiparametric efficiency and its implication on the design and analysis of group-sequential studies}},
volume = {92},
year = {1997}
}
@article{pocock1977group,
author = {Pocock, Stuart J},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Pocock - 1977 - Group sequential methods in the design and analysis of clinical trials(2).pdf:pdf},
journal = {Biometrika},
number = {2},
pages = {191--199},
publisher = {Oxford University Press},
title = {{Group sequential methods in the design and analysis of clinical trials}},
volume = {64},
year = {1977}
}
@article{armitage1969repeated,
author = {Armitage, Peter and McPherson, C K and Rowe, B C},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Armitage, McPherson, Rowe - 1969 - Repeated significance tests on accumulating data(2).pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series A (General)},
number = {2},
pages = {235--244},
publisher = {Wiley Online Library},
title = {{Repeated significance tests on accumulating data}},
volume = {132},
year = {1969}
}
@article{gordon1983discrete,
author = {{Gordon Lan}, K K and DeMets, David L},
file = {::},
journal = {Biometrika},
number = {3},
pages = {659--663},
publisher = {Oxford University Press},
title = {{Discrete sequential boundaries for clinical trials}},
volume = {70},
year = {1983}
}
@article{Wang2023,
abstract = {Two commonly used methods for improving precision and power in clinical trials are stratified randomization and covariate adjustment. However, many trials do not fully capitalize on the combined precision gains from these two methods, which can lead to wasted resources in terms of sample size and trial duration. We derive consistency and asymptotic normality of model-robust estimators that combine these two methods, and show that these estimators can lead to substantial gains in precision and power. Our theorems cover a class of estimators that handle continuous, binary, and time-to-event outcomes; missing outcomes under the missing at random assumption are handled as well. For each estimator, we give a formula for a consistent variance estimator that is model-robust and that fully captures variance reductions from stratified randomization and covariate adjustment. Also, we give the first proof (to the best of our knowledge) of consistency and asymptotic normality of the Kaplan–Meier estimator under stratified randomization, and we derive its asymptotic variance. The above results also hold for the biased-coin covariate-adaptive design. We demonstrate our results using data from three trials of substance use disorder treatments, where the variance reduction due to stratified randomization and covariate adjustment ranges from 1{\%} to 36{\%}. Supplementary materials for this article, including a standardized description of the materials available for reproducing the work, are available as an online supplement.},
archivePrefix = {arXiv},
arxivId = {1910.13954},
author = {Wang, Bingkai and Susukida, Ryoko and Mojtabai, Ramin and Amin-Esmaeili, Masoumeh and Rosenblum, Michael},
doi = {10.1080/01621459.2021.1981338},
eprint = {1910.13954},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Wang et al. - 2023 - Model-Robust Inference for Clinical Trials that Improve Precision by Stratified Randomization and Covariate Adju(3).pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Covariate-adaptive randomization,Generalized linear model,Robustness},
number = {542},
pages = {1152--1163},
publisher = {Taylor {\&} Francis},
title = {{Model-Robust Inference for Clinical Trials that Improve Precision by Stratified Randomization and Covariate Adjustment}},
url = {https://doi.org/10.1080/01621459.2021.1981338},
volume = {118},
year = {2023}
}
@article{tsiatis2008covariate,
author = {Tsiatis, Anastasios A and Davidian, Marie and Zhang, Min and Lu, Xiaomin},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/Tsiatis et al. - 2008 - Covariate adjustment for two-sample treatment comparisons in randomized clinical trials a principled yet flexibl.pdf:pdf},
journal = {Statistics in medicine},
number = {23},
pages = {4658--4677},
publisher = {Wiley Online Library},
title = {{Covariate adjustment for two-sample treatment comparisons in randomized clinical trials: a principled yet flexible approach}},
volume = {27},
year = {2008}
}
@article{o1979multiple,
author = {O'Brien, Peter C and Fleming, Thomas R},
file = {:Users/jonathanchipman/Dropbox/statistics/papers/mendeley/O'Brien, Fleming - 1979 - A multiple testing procedure for clinical trials(2).pdf:pdf},
journal = {Biometrics},
pages = {549--556},
publisher = {JSTOR},
title = {{A multiple testing procedure for clinical trials}},
year = {1979}
}
@article{rubin1984bayesianly,
author = {Rubin, Donald B},
file = {::},
journal = {The Annals of Statistics},
pages = {1151--1172},
publisher = {JSTOR},
title = {{Bayesianly justifiable and relevant frequency calculations for the applied statistician}},
year = {1984}
}
@article{berger2021roadmap,
abstract = {Background: Randomization is the foundation of any clinical trial involving treatment comparison. It helps mitigate selection bias, promotes similarity of treatment groups with respect to important known and unknown confounders, and contributes to the validity of statistical tests. Various restricted randomization procedures with different probabilistic structures and different statistical properties are available. The goal of this paper is to present a systematic roadmap for the choice and application of a restricted randomization procedure in a clinical trial. Methods: We survey available restricted randomization procedures for sequential allocation of subjects in a randomized, comparative, parallel group clinical trial with equal (1:1) allocation. We explore statistical properties of these procedures, including balance/randomness tradeoff, type I error rate and power. We perform head-to-head comparisons of different procedures through simulation under various experimental scenarios, including cases when common model assumptions are violated. We also provide some real-life clinical trial examples to illustrate the thinking process for selecting a randomization procedure for implementation in practice. Results: Restricted randomization procedures targeting 1:1 allocation vary in the degree of balance/randomness they induce, and more importantly, they vary in terms of validity and efficiency of statistical inference when common model assumptions are violated (e.g. when outcomes are affected by a linear time trend; measurement error distribution is misspecified; or selection bias is introduced in the experiment). Some procedures are more robust than others. Covariate-adjusted analysis may be essential to ensure validity of the results. Special considerations are required when selecting a randomization procedure for a clinical trial with very small sample size. Conclusions: The choice of randomization design, data analytic technique (parametric or nonparametric), and analysis strategy (randomization-based or population model-based) are all very important considerations. Randomization-based tests are robust and valid alternatives to likelihood-based tests and should be considered more frequently by clinical investigators.},
author = {Berger, Vance W. and Bour, Louis Joseph and Carter, Kerstine and Chipman, Jonathan J. and Everett, Colin C. and Heussen, Nicole and Hewitt, Catherine and Hilgers, Ralf Dieter and Luo, Yuqun Abigail and Renteria, Jone and Ryeznik, Yevgen and Sverdlov, Oleksandr and Uschner, Diane and Beckman, Robert A.},
doi = {10.1186/s12874-021-01303-z},
file = {::},
issn = {14712288},
journal = {BMC Medical Research Methodology},
keywords = {Balance,Randomization-based test,Restricted randomization design,Validity},
number = {1},
pmid = {34399696},
title = {{A roadmap to using randomization in clinical trials}},
volume = {21},
year = {2021}
}
@article{TheChurchofJesusChristofLatter-daySaints2020,
annote = {These instructions can invite revelation if they are used to provide an understanding of principles, policies, and procedures to apply while seeking the guidance of the Spirit.},
author = {{The Church of Jesus Christ of Latter-day Saints}},
file = {::},
number = {August},
title = {{General Handbook:  Serving in The Church of Jesus Christ of Latter-day Saints}},
year = {2020}
}
@misc{us2010guidance,
author = {{US Food and Drug Administration}},
booktitle = {Maryland: US Food and Drug Administration},
file = {::},
title = {{Guidance for the use of Bayesian statistics in medical device clinical trials}},
year = {2010}
}
@article{Hilgers2017,
abstract = {Background: Randomization is considered to be a key feature to protect against bias in randomized clinical trials. Randomization induces comparability with respect to known and unknown covariates, mitigates selection bias, and provides a basis for inference. Although various randomization procedures have been proposed, no single procedure performs uniformly best. In the design phase of a clinical trial, the scientist has to decide which randomization procedure to use, taking into account the practical setting of the trial with respect to the potential of bias. Less emphasis has been placed on this important design decision than on analysis, and less support has been available to guide the scientist in making this decision. Methods: We propose a framework that weights the properties of the randomization procedure with respect to practical needs of the research question to be answered by the clinical trial. In particular, the framework assesses the impact of chronological and selection bias on the probability of a type I error. The framework is applied to a case study with a 2-Arm parallel group, single center randomized clinical trial with continuous endpoint, with no-interim analysis, 1:1 allocation and no adaptation in the randomization process. Results: In so doing, we derive scientific arguments for the selection of an appropriate randomization procedure and develop a template which is illustrated in parallel by a case study. Possible extensions are discussed. Conclusion: The proposed ERDO framework guides the investigator through a template for the choice of a randomization procedure, and provides easy to use tools for the assessment. The barriers for the thorough reporting and assessment of randomization procedures could be further reduced in the future when regulators and pharmaceutical companies employ similar, standardized frameworks for the choice of a randomization procedure.},
author = {Hilgers, Ralf Dieter and Uschner, Diane and Rosenberger, William F. and Heussen, Nicole},
doi = {10.1186/s12874-017-0428-z},
file = {::},
issn = {14712288},
journal = {BMC Medical Research Methodology},
keywords = {Chronological bias,Design,Restricted randomization,Selection bias,Type I error probability},
number = {1},
pages = {1--12},
pmid = {29202708},
publisher = {BMC Medical Research Methodology},
title = {{ERDO-a framework to select an appropriate randomization procedure for clinical trials}},
volume = {17},
year = {2017}
}
